Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 1 GPUs...
Setting up training stages...
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 369, in training_loop
    logger = init_logger(run_dir, log)                                                        # Initialize logs
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 263, in init_logger
    import torch.utils.tensorboard as tensorboard
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py", line 4, in <module>
    LooseVersion = distutils.version.LooseVersion
AttributeError: module 'distutils' has no attribute 'version'
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 1 GPUs...
Setting up training stages...
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 369, in training_loop
    logger = init_logger(run_dir, log)                                                        # Initialize logs
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 263, in init_logger
    import torch.utils.tensorboard as tensorboard
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py", line 7, in <module>
    del distutils
NameError: name 'distutils' is not defined
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 1 GPUs...
Setting up training stages...
Training for 25000 kimg...
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 435, in training_loop
    dataset_args, num_gpus, rank, device, log, logger, run_dir)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 227, in evaluate
    progress = metric_utils.ProgressMonitor(verbose = log))
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/metric_main.py", line 39, in compute_metric
    results = _metric_dict[metric](opts)
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/metric_main.py", line 97, in _fid
    fid = frechet_inception_distance.compute_fid(opts)
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/frechet_inception_distance.py", line 14, in compute_fid
    rel_lo = 0, rel_hi = 0, capture_mean_cov = True).get_mean_cov()
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/metric_utils.py", line 208, in compute_feature_stats_for_dataset
    features = detector(images.to(opts.device), **detector_kwargs)
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
RuntimeError: MALFORMED INPUT: lanes dont match
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Resuming from results/exp-000/network-snapshot-000000.pkl
Setting up PyTorch plugin "bias_act_plugin"... Failed!
Setting up PyTorch plugin "upfirdn2d_plugin"... Failed!
Failed to build CUDA kernels for upfirdn2d. Make sure your PyTorch CUDA is configured. Details:

Traceback (most recent call last):
  File "/home/quoniam/Work/gansformer/pytorch_version/torch_utils/ops/upfirdn2d.py", line 24, in _init
    _plugin = custom_ops.get_plugin('upfirdn2d_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])
  File "/home/quoniam/Work/gansformer/pytorch_version/torch_utils/custom_ops.py", line 102, in get_plugin
    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/site-packages/torch/utils/cpp_extension.py", line 1091, in load
    keep_intermediates=keep_intermediates)
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/site-packages/torch/utils/cpp_extension.py", line 1317, in _jit_compile
    return _import_module_from_library(name, build_directory, is_python_module)
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/site-packages/torch/utils/cpp_extension.py", line 1703, in _import_module_from_library
    return imp.load_module(module_name, file, path, description)  # type: ignore
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/imp.py", line 242, in load_module
    return load_dynamic(name, filename, file)
  File "/home/quoniam/miniconda/envs/3.7/lib/python3.7/imp.py", line 342, in load_dynamic
    return _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 670, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 583, in module_from_spec
  File "<frozen importlib._bootstrap_external>", line 1043, in create_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
ImportError: /home/quoniam/.cache/torch_extensions/upfirdn2d_plugin/upfirdn2d_plugin.so: undefined symbol: _ZNK3c106IValue23reportToTensorTypeErrorEv

Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Resuming from results/exp-000/network-snapshot-000000.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 1 GPUs...
Setting up training stages...
Skipping tfevents export: No module named 'tensorboard'
Training for 25000 kimg...
Evaluation: computing dataset features items 999  /999 (100.00%) time 7s           ms/item 7.22Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 34.79Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 11s       ms/item 34.99Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.34Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.39Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.39Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.80Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 435, in training_loop
    dataset_args, num_gpus, rank, device, log, logger, run_dir)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 227, in evaluate
    progress = metric_utils.ProgressMonitor(verbose = log))
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/metric_main.py", line 39, in compute_metric
    results = _metric_dict[metric](opts)
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/metric_main.py", line 97, in _fid
    fid = frechet_inception_distance.compute_fid(opts)
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/frechet_inception_distance.py", line 18, in compute_fid
    rel_lo = 0, rel_hi = 1, capture_mean_cov = True).get_mean_cov()
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/metric_utils.py", line 255, in compute_feature_stats_for_generator
    images.append(run_generator(z, c))
  File "/home/quoniam/Work/gansformer/pytorch_version/metrics/metric_utils.py", line 233, in run_generator
    img = G(z = z, c = c)[0]
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/networks.py", line 1314, in forward
    ws = self.mapping(z, c, pos = self.pos, mask = mask, truncation_psi = truncation_psi, truncation_cutoff = truncation_cutoff)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/networks.py", line 915, in forward
    p = self.mlp(z, pos = pos if self.use_pos else None, mask = mask)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/networks.py", line 213, in forward
    x = layer(x, _x)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/networks.py", line 164, in forward
    x = self.fc1(x)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/networks.py", line 143, in forward
    x = torch.addmm(b.unsqueeze(0), x, w.t())
KeyboardInterrupt
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Resuming from results/exp-000/network-snapshot-000000.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 1 GPUs...
Setting up training stages...
Skipping tfevents export: No module named 'tensorboard'
Training for 25000 kimg...
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 386, in training_loop
    run_training_stage(loss, stage, device, real_img, real_c, gen_z, gen_c, batch_size, batch_gpu, num_gpus)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 193, in run_training_stage
    gen_z = z, gen_c = cz, sync = sync, gain = stage.interval)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/loss.py", line 86, in accumulate_gradients
    loss_G_main.mean().mul(gain).backward()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Resuming from results/exp-000/network-snapshot-000000.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 1 GPUs...
Setting up training stages...
Training for 25000 kimg...
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.47Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.63Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.09Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.81Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.84Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.23Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 35.78Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 36.37Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 35.84Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 35.98Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.01Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 22s       ms/item 36.03Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 59s       ms/item 35.99Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 36s       ms/item 36.14Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 13s       ms/item 35.99Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 50s       ms/item 35.79Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 35.85Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 03s      ms/item 35.99Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 41s      ms/item 36.43Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 18s      ms/item 35.97Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 55s      ms/item 36.21Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 31s      ms/item 35.95Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 08s      ms/item 35.83Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 45s      ms/item 36.20Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 22s      ms/item 36.42Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 59s      ms/item 36.02Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 37s      ms/item 36.36Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 13s      ms/item 35.80Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 51s      ms/item 36.40Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 28s      ms/item 36.15Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 04s      ms/item 36.09Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 41s      ms/item 35.79Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 19s      ms/item 36.57Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 55s      ms/item 35.67Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 32s      ms/item 36.10Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 09s      ms/item 35.88Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 46s      ms/item 36.37Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 23s      ms/item 35.82Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 00s      ms/item 36.18Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 37s      ms/item 36.34Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 14s      ms/item 35.71Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 51s      ms/item 36.14Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 27s      ms/item 36.04Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 04s      ms/item 36.07Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 41s      ms/item 35.91Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 18s      ms/item 35.99Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 55s      ms/item 35.68Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 32s      ms/item 36.54Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 04s      ms/item 37.96                                                                                                    
network-snapshot-000000        time 30m 11s      fid50k   309.7495
tick 1     kimg 8.0       loss/reg: G (16.281 -1.000) D ( 1.246  0.000)  time 1h 01m 49s   sec/kimg 234.55  mem: GPU 2.87   CPU 7.62   exp
tick 2     kimg 16.0      loss/reg: G ( 6.366 -1.000) D ( 0.533  0.018)  time 1h 33m 07s   sec/kimg 234.76  mem: GPU 2.87   CPU 6.30   exp
tick 3     kimg 24.0      loss/reg: G ( 2.081 -1.000) D ( 0.829  0.020)  time 2h 04m 22s   sec/kimg 234.47  mem: GPU 2.87   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.37Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.25Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.64Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.50Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.26Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.42Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.33Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.42Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.39Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 02s       ms/item 35.38Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.44Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 35.37Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.44Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 27s       ms/item 35.23Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 04s       ms/item 35.55Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 40s       ms/item 35.39Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 16s      ms/item 35.42Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 52s      ms/item 35.21Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 29s      ms/item 35.66Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 05s      ms/item 35.33Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 41s      ms/item 35.39Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 18s      ms/item 35.44Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 54s      ms/item 35.36Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 30s      ms/item 35.23Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 06s      ms/item 35.61Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 42s      ms/item 35.19Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 19s      ms/item 35.40Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 55s      ms/item 35.27Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 31s      ms/item 35.55Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 07s      ms/item 35.36Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 43s      ms/item 35.23Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 20s      ms/item 35.40Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 56s      ms/item 35.43Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 32s      ms/item 35.38Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 08s      ms/item 35.38Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 44s      ms/item 35.26Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 21s      ms/item 35.38Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 57s      ms/item 35.34Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 33s      ms/item 35.25Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 09s      ms/item 35.43Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 46s      ms/item 35.55Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 22s      ms/item 35.21Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 58s      ms/item 35.42Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 34s      ms/item 35.37Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 10s      ms/item 35.36Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 47s      ms/item 35.32Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 23s      ms/item 35.34Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 59s      ms/item 35.46Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 31s      ms/item 37.39                                                                                                    
network-snapshot-000024        time 29m 37s      fid50k   324.0089
tick 4     kimg 32.0      loss/reg: G ( 2.129 -1.000) D ( 0.709  0.046)  time 3h 05m 19s   sec/kimg 234.84  mem: GPU 2.89   CPU 6.30   exp
tick 5     kimg 40.0      loss/reg: G ( 1.735 -1.000) D ( 0.906  0.033)  time 3h 36m 39s   sec/kimg 234.88  mem: GPU 2.89   CPU 6.30   exp
tick 6     kimg 48.0      loss/reg: G ( 1.321 -1.000) D ( 1.100  0.024)  time 4h 07m 55s   sec/kimg 234.50  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.31Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.97Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.15Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.53Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 35.74Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 35.97Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.17Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.02Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.33Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.22Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 35.98Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 36.03Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.31Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 38s       ms/item 36.34Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 15s       ms/item 36.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 52s       ms/item 35.81Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 29s      ms/item 36.38Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 06s      ms/item 36.39Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 43s      ms/item 35.99Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 20s      ms/item 36.14Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 57s      ms/item 36.13Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 35s      ms/item 36.41Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 12s      ms/item 36.16Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 49s      ms/item 36.25Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 26s      ms/item 35.97Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 03s      ms/item 36.17Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 40s      ms/item 36.55Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 17s      ms/item 36.30Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 55s      ms/item 36.50Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 31s      ms/item 35.90Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 09s      ms/item 36.33Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 45s      ms/item 35.87Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 23s      ms/item 36.37Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 00s      ms/item 36.55Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 37s      ms/item 36.05Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 14s      ms/item 36.41Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 51s      ms/item 36.20Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 28s      ms/item 36.21Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 05s      ms/item 36.32Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 43s      ms/item 36.23Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 20s      ms/item 36.35Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 57s      ms/item 36.14Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 34s      ms/item 36.11Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 11s      ms/item 36.20Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 48s      ms/item 35.99Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 25s      ms/item 36.49Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 02s      ms/item 36.13Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 39s      ms/item 36.25Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 12s      ms/item 38.55                                                                                                    
network-snapshot-000048        time 30m 19s      fid50k   270.6619
tick 7     kimg 56.0      loss/reg: G ( 1.399 -1.000) D ( 1.035  0.030)  time 5h 09m 33s   sec/kimg 234.83  mem: GPU 2.88   CPU 6.30   exp
tick 8     kimg 64.0      loss/reg: G ( 1.586 -1.000) D ( 0.979  0.040)  time 5h 40m 51s   sec/kimg 234.76  mem: GPU 2.88   CPU 6.30   exp
tick 9     kimg 72.0      loss/reg: G ( 1.536 -1.000) D ( 0.989  0.048)  time 6h 12m 08s   sec/kimg 234.61  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.32Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.27Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.55Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.27Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.39Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.36Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.22Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.38Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.19Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 02s       ms/item 35.60Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 38s       ms/item 35.43Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 14s       ms/item 35.22Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.50Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 27s       ms/item 35.26Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 03s       ms/item 35.66Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 40s       ms/item 35.37Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 16s      ms/item 35.69Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 52s      ms/item 35.32Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 29s      ms/item 35.39Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 05s      ms/item 35.35Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 41s      ms/item 35.39Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 17s      ms/item 35.47Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 53s      ms/item 35.35Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 30s      ms/item 35.38Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 06s      ms/item 35.46Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 42s      ms/item 35.21Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 18s      ms/item 35.35Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 55s      ms/item 35.39Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 31s      ms/item 35.41Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 07s      ms/item 35.61Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 43s      ms/item 35.37Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 20s      ms/item 35.41Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 56s      ms/item 35.37Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 32s      ms/item 35.36Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 08s      ms/item 35.31Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 45s      ms/item 35.38Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 21s      ms/item 35.43Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 57s      ms/item 35.32Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 33s      ms/item 35.41Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 10s      ms/item 35.43Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 46s      ms/item 35.59Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 22s      ms/item 35.38Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 59s      ms/item 35.44Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 35s      ms/item 35.39Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 11s      ms/item 35.35Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 47s      ms/item 35.41Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 23s      ms/item 35.22Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 00s      ms/item 35.43Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 31s      ms/item 37.42                                                                                                    
network-snapshot-000072        time 29m 38s      fid50k   208.4478
tick 10    kimg 80.0      loss/reg: G ( 1.571 -1.000) D ( 0.970  0.056)  time 7h 13m 05s   sec/kimg 234.74  mem: GPU 2.87   CPU 6.30   exp
tick 11    kimg 88.0      loss/reg: G ( 1.723 -1.000) D ( 0.897  0.067)  time 7h 44m 20s   sec/kimg 234.40  mem: GPU 2.87   CPU 6.30   exp
tick 12    kimg 96.0      loss/reg: G ( 2.051 -1.000) D ( 0.784  0.091)  time 8h 15m 37s   sec/kimg 234.60  mem: GPU 2.87   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.11Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.23Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.35Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.17Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.01Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.02Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.19Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.33Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.20Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.09Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.43Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.29Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.07Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 39s       ms/item 36.00Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 16s       ms/item 36.13Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 53s       ms/item 36.28Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 30s      ms/item 36.22Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 07s      ms/item 36.18Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 44s      ms/item 36.12Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 21s      ms/item 36.12Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 58s      ms/item 36.37Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 35s      ms/item 36.22Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 12s      ms/item 36.11Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 49s      ms/item 36.07Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 26s      ms/item 36.27Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 03s      ms/item 35.98Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 40s      ms/item 36.18Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 17s      ms/item 36.16Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 54s      ms/item 36.20Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 31s      ms/item 36.24Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 08s      ms/item 36.19Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 45s      ms/item 36.00Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 22s      ms/item 36.03Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 59s      ms/item 36.13Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 36s      ms/item 36.02Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 13s      ms/item 36.36Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 50s      ms/item 36.02Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 27s      ms/item 36.21Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 05s      ms/item 36.62Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 42s      ms/item 36.39Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 19s      ms/item 36.37Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 56s      ms/item 36.22Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 34s      ms/item 36.50Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 11s      ms/item 36.07Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 48s      ms/item 36.41Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 25s      ms/item 36.57Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 02s      ms/item 36.18Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 39s      ms/item 36.14Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 12s      ms/item 38.30                                                                                                    
network-snapshot-000096        time 30m 19s      fid50k   198.1250
tick 13    kimg 104.0     loss/reg: G ( 2.159 -1.000) D ( 0.725  0.097)  time 9h 17m 15s   sec/kimg 234.77  mem: GPU 2.88   CPU 6.30   exp
tick 14    kimg 112.0     loss/reg: G ( 2.239 -1.000) D ( 0.658  0.114)  time 9h 48m 30s   sec/kimg 234.47  mem: GPU 2.88   CPU 6.30   exp
tick 15    kimg 120.0     loss/reg: G ( 2.411 -1.000) D ( 0.604  0.122)  time 10h 19m 49s  sec/kimg 234.89  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.45Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.25Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.13Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.25Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.21Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.41Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.33Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.29Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.39Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 02s       ms/item 35.34Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 38s       ms/item 35.22Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 14s       ms/item 35.42Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 50s       ms/item 35.31Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 26s       ms/item 35.53Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 03s       ms/item 35.31Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 39s       ms/item 35.37Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 15s      ms/item 35.23Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 51s      ms/item 35.23Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 27s      ms/item 35.37Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 03s      ms/item 35.42Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 40s      ms/item 35.55Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 16s      ms/item 35.22Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 52s      ms/item 35.25Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 28s      ms/item 35.44Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 05s      ms/item 35.38Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 41s      ms/item 35.34Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 17s      ms/item 35.41Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 53s      ms/item 35.22Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 29s      ms/item 35.54Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 06s      ms/item 35.26Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 42s      ms/item 35.40Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 18s      ms/item 35.24Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 54s      ms/item 35.56Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 30s      ms/item 35.26Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 07s      ms/item 35.40Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 43s      ms/item 35.41Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 19s      ms/item 35.18Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 55s      ms/item 35.25Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 31s      ms/item 35.30Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 07s      ms/item 35.35Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 43s      ms/item 35.25Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 20s      ms/item 35.31Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 56s      ms/item 35.28Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 32s      ms/item 35.26Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 08s      ms/item 35.38Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 44s      ms/item 35.24Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 20s      ms/item 35.35Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 56s      ms/item 35.24Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 28s      ms/item 37.22                                                                                                    
network-snapshot-000120        time 29m 35s      fid50k   180.3973
tick 16    kimg 128.0     loss/reg: G ( 2.563 -1.000) D ( 0.544  0.127)  time 11h 20m 44s  sec/kimg 234.89  mem: GPU 2.86   CPU 6.30   exp
tick 17    kimg 136.0     loss/reg: G ( 2.585 -1.000) D ( 0.541  0.133)  time 11h 52m 02s  sec/kimg 234.72  mem: GPU 2.86   CPU 6.30   exp
tick 18    kimg 144.0     loss/reg: G ( 2.623 -1.000) D ( 0.517  0.124)  time 12h 23m 22s  sec/kimg 234.94  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.08Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.01Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.15Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.05Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.09Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.07Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.03Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.17Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.18Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.08Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.45Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 36.02Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.25Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 38s       ms/item 36.12Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 15s       ms/item 35.92Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 52s       ms/item 36.29Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 29s      ms/item 36.10Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 06s      ms/item 36.09Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 43s      ms/item 36.50Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 20s      ms/item 36.15Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 57s      ms/item 36.35Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 35s      ms/item 36.31Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 12s      ms/item 36.23Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 49s      ms/item 36.01Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 26s      ms/item 36.24Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 03s      ms/item 36.29Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 40s      ms/item 35.88Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 17s      ms/item 36.14Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 54s      ms/item 36.12Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 30s      ms/item 36.09Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 07s      ms/item 36.08Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 45s      ms/item 36.30Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 22s      ms/item 36.12Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 59s      ms/item 36.11Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 36s      ms/item 36.46Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 13s      ms/item 36.00Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 50s      ms/item 36.03Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 27s      ms/item 36.33Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 04s      ms/item 36.02Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 41s      ms/item 36.16Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 18s      ms/item 36.08Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 55s      ms/item 36.33Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 32s      ms/item 36.06Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 09s      ms/item 36.20Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 47s      ms/item 36.74Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 24s      ms/item 36.33Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 01s      ms/item 36.07Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 38s      ms/item 36.24Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 10s      ms/item 38.12                                                                                                    
network-snapshot-000144        time 30m 17s      fid50k   166.0073
tick 19    kimg 152.0     loss/reg: G ( 2.738 -1.000) D ( 0.469  0.140)  time 13h 24m 57s  sec/kimg 234.73  mem: GPU 2.88   CPU 6.30   exp
tick 20    kimg 160.0     loss/reg: G ( 2.788 -1.000) D ( 0.479  0.135)  time 13h 56m 16s  sec/kimg 234.88  mem: GPU 2.88   CPU 6.30   exp
tick 21    kimg 168.0     loss/reg: G ( 2.955 -1.000) D ( 0.400  0.132)  time 14h 27m 35s  sec/kimg 234.79  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.39Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.26Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.45Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.34Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.44Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.32Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.30Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.54Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.40Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 02s       ms/item 35.26Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 38s       ms/item 35.36Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 35.41Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.40Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 27s       ms/item 35.39Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 03s       ms/item 35.37Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 40s       ms/item 35.43Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 16s      ms/item 35.67Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 52s      ms/item 35.34Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 29s      ms/item 35.38Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 05s      ms/item 35.43Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 41s      ms/item 35.40Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 17s      ms/item 35.45Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 54s      ms/item 35.74Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 30s      ms/item 35.23Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 07s      ms/item 35.78Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 43s      ms/item 35.25Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 19s      ms/item 35.36Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 55s      ms/item 35.40Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 32s      ms/item 35.54Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 08s      ms/item 35.24Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 44s      ms/item 35.64Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 20s      ms/item 35.36Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 57s      ms/item 35.45Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 33s      ms/item 35.33Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 09s      ms/item 35.45Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 45s      ms/item 35.38Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 22s      ms/item 35.37Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 58s      ms/item 35.26Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 34s      ms/item 35.41Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 10s      ms/item 35.33Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 46s      ms/item 35.42Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 23s      ms/item 35.40Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 59s      ms/item 35.45Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 36s      ms/item 35.72Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 12s      ms/item 35.26Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 48s      ms/item 35.40Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 24s      ms/item 35.39Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 00s      ms/item 35.27Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 32s      ms/item 37.57                                                                                                    
network-snapshot-000168        time 29m 39s      fid50k   165.4641
tick 22    kimg 176.0     loss/reg: G ( 2.921 -1.000) D ( 0.408  0.130)  time 15h 28m 30s  sec/kimg 234.49  mem: GPU 2.89   CPU 6.30   exp
tick 23    kimg 184.0     loss/reg: G ( 3.062 -1.000) D ( 0.359  0.137)  time 15h 59m 48s  sec/kimg 234.73  mem: GPU 2.89   CPU 6.30   exp
tick 24    kimg 192.0     loss/reg: G ( 3.059 -1.000) D ( 0.388  0.134)  time 16h 31m 06s  sec/kimg 234.67  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.11Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.16Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.99Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 35.86Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.15Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.37Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 35.90Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.29Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.13Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 35.98Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.13Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.02Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.19Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.01Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 15s       ms/item 36.38Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 35.91Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 35.90Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 05s      ms/item 36.07Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 42s      ms/item 36.33Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 36.02Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 56s      ms/item 36.12Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 33s      ms/item 36.10Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 10s      ms/item 36.03Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 47s      ms/item 36.23Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 24s      ms/item 35.78Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 01s      ms/item 36.35Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 38s      ms/item 35.83Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 15s      ms/item 36.09Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 52s      ms/item 36.29Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 29s      ms/item 35.85Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 06s      ms/item 36.34Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 43s      ms/item 36.36Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 20s      ms/item 36.36Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 57s      ms/item 36.10Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 34s      ms/item 35.97Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 11s      ms/item 36.14Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 48s      ms/item 36.16Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 25s      ms/item 35.93Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 02s      ms/item 36.06Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 39s      ms/item 36.03Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 16s      ms/item 36.45Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 53s      ms/item 36.07Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 30s      ms/item 36.15Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 07s      ms/item 36.19Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 44s      ms/item 36.03Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 21s      ms/item 36.33Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 58s      ms/item 35.91Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 35s      ms/item 36.01Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 07s      ms/item 38.35                                                                                                    
network-snapshot-000192        time 30m 14s      fid50k   163.2424
tick 25    kimg 200.0     loss/reg: G ( 3.221 -1.000) D ( 0.325  0.133)  time 17h 32m 37s  sec/kimg 234.60  mem: GPU 2.88   CPU 6.30   exp
tick 26    kimg 208.0     loss/reg: G ( 3.136 -1.000) D ( 0.363  0.136)  time 18h 03m 56s  sec/kimg 234.81  mem: GPU 2.88   CPU 6.30   exp
tick 27    kimg 216.0     loss/reg: G ( 3.193 -1.000) D ( 0.354  0.121)  time 18h 35m 12s  sec/kimg 234.55  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.57Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.25Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.36Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.55Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.28Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.37Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.24Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.38Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.54Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 02s       ms/item 35.25Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 38s       ms/item 35.28Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 35.29Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.47Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 27s       ms/item 35.22Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 03s       ms/item 35.37Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 39s       ms/item 35.35Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 16s      ms/item 35.40Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 52s      ms/item 35.27Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 28s      ms/item 35.36Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 04s      ms/item 35.55Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 40s      ms/item 35.24Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 17s      ms/item 35.40Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 53s      ms/item 35.25Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 29s      ms/item 35.41Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 05s      ms/item 35.49Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 41s      ms/item 35.28Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 18s      ms/item 35.41Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 54s      ms/item 35.41Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 30s      ms/item 35.30Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 06s      ms/item 35.45Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 43s      ms/item 35.22Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 19s      ms/item 35.36Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 55s      ms/item 35.40Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 31s      ms/item 35.26Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 07s      ms/item 35.52Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 44s      ms/item 35.31Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 20s      ms/item 35.37Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 56s      ms/item 35.42Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 32s      ms/item 35.32Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 08s      ms/item 35.28Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 45s      ms/item 35.34Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 21s      ms/item 35.42Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 57s      ms/item 35.39Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 33s      ms/item 35.18Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 09s      ms/item 35.44Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 46s      ms/item 35.37Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 22s      ms/item 35.40Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 58s      ms/item 35.59Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 30s      ms/item 37.15                                                                                                    
network-snapshot-000216        time 29m 36s      fid50k   161.5261
tick 28    kimg 224.0     loss/reg: G ( 3.227 -1.000) D ( 0.308  0.135)  time 19h 36m 08s  sec/kimg 234.76  mem: GPU 2.89   CPU 6.30   exp
tick 29    kimg 232.0     loss/reg: G ( 3.268 -1.000) D ( 0.317  0.125)  time 20h 07m 27s  sec/kimg 234.85  mem: GPU 2.89   CPU 6.30   exp
tick 30    kimg 240.0     loss/reg: G ( 3.429 -1.000) D ( 0.275  0.126)  time 20h 38m 44s  sec/kimg 234.68  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.07Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.98Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.16Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.28Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 35.79Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.32Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.27Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.21Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.02Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.17Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.24Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 35.91Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.24Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 38s       ms/item 35.96Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 15s       ms/item 35.89Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 52s       ms/item 36.33Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 29s      ms/item 36.35Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 06s      ms/item 35.82Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 43s      ms/item 36.32Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 20s      ms/item 36.21Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 57s      ms/item 36.15Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 34s      ms/item 36.52Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 12s      ms/item 36.51Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 49s      ms/item 36.12Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 26s      ms/item 36.11Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 03s      ms/item 36.24Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 40s      ms/item 36.17Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 17s      ms/item 36.37Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 54s      ms/item 36.30Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 31s      ms/item 36.08Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 08s      ms/item 36.24Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 45s      ms/item 36.07Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 22s      ms/item 36.31Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 59s      ms/item 36.16Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 37s      ms/item 36.35Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 14s      ms/item 36.06Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 51s      ms/item 36.38Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 28s      ms/item 36.16Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 05s      ms/item 36.21Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 42s      ms/item 36.19Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 19s      ms/item 36.05Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 56s      ms/item 36.39Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 33s      ms/item 36.28Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 10s      ms/item 36.14Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 47s      ms/item 36.22Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 25s      ms/item 36.33Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 02s      ms/item 36.22Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 39s      ms/item 36.14Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 11s      ms/item 38.26                                                                                                    
network-snapshot-000240        time 30m 18s      fid50k   154.1695
tick 31    kimg 248.0     loss/reg: G ( 3.256 -1.000) D ( 0.329  0.123)  time 21h 40m 26s  sec/kimg 235.37  mem: GPU 2.89   CPU 6.30   exp
tick 32    kimg 256.0     loss/reg: G ( 3.322 -1.000) D ( 0.294  0.122)  time 22h 11m 49s  sec/kimg 235.42  mem: GPU 2.89   CPU 6.30   exp
tick 33    kimg 264.0     loss/reg: G ( 3.355 -1.000) D ( 0.312  0.117)  time 22h 43m 10s  sec/kimg 235.12  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.45Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.32Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.41Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.45Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.59Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.41Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.39Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.59Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.57Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.49Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.51Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 16s       ms/item 35.42Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 36.01Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.17Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 05s       ms/item 35.67Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.63Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 18s      ms/item 35.56Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.53Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.78Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 08s      ms/item 35.69Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.39Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 20s      ms/item 35.53Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 57s      ms/item 35.61Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 33s      ms/item 35.45Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 10s      ms/item 35.61Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 46s      ms/item 35.58Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 22s      ms/item 35.61Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 59s      ms/item 35.45Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 35s      ms/item 35.75Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 12s      ms/item 35.42Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 48s      ms/item 35.89Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 25s      ms/item 35.50Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 01s      ms/item 35.56Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 38s      ms/item 35.65Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 14s      ms/item 35.60Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 51s      ms/item 35.59Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 27s      ms/item 35.78Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 04s      ms/item 35.60Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 40s      ms/item 35.60Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 17s      ms/item 35.75Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 53s      ms/item 35.63Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 29s      ms/item 35.38Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 06s      ms/item 35.45Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 42s      ms/item 35.58Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 19s      ms/item 35.59Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 55s      ms/item 35.60Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 31s      ms/item 35.43Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 08s      ms/item 35.60Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 40s      ms/item 37.69                                                                                                    
network-snapshot-000264        time 29m 46s      fid50k   157.6326
tick 34    kimg 272.0     loss/reg: G ( 3.328 -1.000) D ( 0.309  0.121)  time 23h 44m 20s  sec/kimg 235.30  mem: GPU 2.89   CPU 6.30   exp
tick 35    kimg 280.0     loss/reg: G ( 3.356 -1.000) D ( 0.291  0.120)  time 86400d 00h 15m sec/kimg 235.49  mem: GPU 2.89   CPU 6.30   exp
tick 36    kimg 288.0     loss/reg: G ( 3.446 -1.000) D ( 0.274  0.124)  time 86400d 00h 47m sec/kimg 235.55  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.43Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.17Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 52s       ms/item 36.29Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.62Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.29Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.19Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.11Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.21Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.31Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 12s       ms/item 36.33Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 49s       ms/item 36.50Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 26s       ms/item 36.24Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 03s       ms/item 36.29Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.29Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 18s       ms/item 36.36Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 55s       ms/item 36.43Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 32s      ms/item 36.23Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 10s      ms/item 36.52Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 47s      ms/item 36.18Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 24s      ms/item 36.44Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 01s      ms/item 36.38Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 38s      ms/item 36.09Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 15s      ms/item 36.21Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 53s      ms/item 36.52Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 30s      ms/item 36.21Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 07s      ms/item 36.33Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 44s      ms/item 36.41Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 21s      ms/item 36.06Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 58s      ms/item 36.25Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 35s      ms/item 36.40Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 13s      ms/item 36.41Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 50s      ms/item 36.37Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 27s      ms/item 36.22Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 04s      ms/item 36.17Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 41s      ms/item 36.23Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 19s      ms/item 36.56Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 56s      ms/item 36.68Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 33s      ms/item 36.13Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 10s      ms/item 36.32Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 47s      ms/item 36.19Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 25s      ms/item 36.31Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 02s      ms/item 36.35Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 39s      ms/item 36.41Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 16s      ms/item 36.45Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 54s      ms/item 36.36Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 31s      ms/item 36.21Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 08s      ms/item 36.21Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 45s      ms/item 36.09Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 18s      ms/item 38.57                                                                                                    
network-snapshot-000288        time 30m 24s      fid50k   156.9798
tick 37    kimg 296.0     loss/reg: G ( 3.381 -1.000) D ( 0.266  0.109)  time 86400d 01h 48m sec/kimg 235.40  mem: GPU 2.88   CPU 6.30   exp
tick 38    kimg 304.0     loss/reg: G ( 3.462 -1.000) D ( 0.280  0.118)  time 86400d 02h 20m sec/kimg 235.31  mem: GPU 2.88   CPU 6.30   exp
tick 39    kimg 312.0     loss/reg: G ( 3.611 -1.000) D ( 0.239  0.114)  time 86400d 02h 51m sec/kimg 235.47  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.43Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.41Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.34Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.60Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.41Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.43Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.41Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.60Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.39Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.78Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.59Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 16s       ms/item 35.56Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 52s       ms/item 35.45Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.61Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 05s       ms/item 35.46Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.52Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 18s      ms/item 35.45Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.71Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.45Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 07s      ms/item 35.63Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.63Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 20s      ms/item 35.60Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 57s      ms/item 35.72Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 33s      ms/item 35.53Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 10s      ms/item 35.49Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 46s      ms/item 35.41Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 22s      ms/item 35.60Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 59s      ms/item 35.59Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 35s      ms/item 35.47Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 12s      ms/item 35.65Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 48s      ms/item 35.47Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 24s      ms/item 35.63Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 01s      ms/item 35.45Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 37s      ms/item 35.45Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 13s      ms/item 35.55Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 50s      ms/item 35.78Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 26s      ms/item 35.56Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 03s      ms/item 35.40Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 39s      ms/item 35.19Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 15s      ms/item 35.30Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 52s      ms/item 35.90Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 28s      ms/item 35.42Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 04s      ms/item 35.47Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 41s      ms/item 35.50Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 17s      ms/item 35.46Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 53s      ms/item 35.59Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 30s      ms/item 35.64Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 06s      ms/item 35.50Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 38s      ms/item 37.48                                                                                                    
network-snapshot-000312        time 29m 45s      fid50k   159.5387
tick 40    kimg 320.0     loss/reg: G ( 3.549 -1.000) D ( 0.263  0.109)  time 86400d 03h 52m sec/kimg 235.54  mem: GPU 2.87   CPU 6.30   exp
tick 41    kimg 328.0     loss/reg: G ( 3.553 -1.000) D ( 0.248  0.116)  time 86400d 04h 24m sec/kimg 235.22  mem: GPU 2.87   CPU 6.30   exp
tick 42    kimg 336.0     loss/reg: G ( 3.514 -1.000) D ( 0.258  0.114)  time 86400d 04h 55m sec/kimg 235.55  mem: GPU 2.87   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.40Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.21Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.21Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.18Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.22Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.25Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.34Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.22Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.60Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 35.85Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.33Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 26s       ms/item 36.31Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 03s       ms/item 36.29Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.25Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.36Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.27Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.20Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 09s      ms/item 36.41Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 46s      ms/item 36.21Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 23s      ms/item 36.19Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 00s      ms/item 36.54Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 38s      ms/item 36.60Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 35.86Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.16Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 29s      ms/item 36.45Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 06s      ms/item 36.16Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 43s      ms/item 36.19Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 20s      ms/item 36.26Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.31Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 34s      ms/item 36.06Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 11s      ms/item 36.22Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 36.22Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 25s      ms/item 36.40Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 03s      ms/item 36.24Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 40s      ms/item 36.23Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 17s      ms/item 36.08Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 54s      ms/item 36.20Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.16Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 08s      ms/item 36.06Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.15Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.57Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 00s      ms/item 36.62Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 36s      ms/item 35.88Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 13s      ms/item 36.22Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 51s      ms/item 36.33Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 28s      ms/item 36.28Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 05s      ms/item 36.27Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 42s      ms/item 36.26Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.13                                                                                                    
network-snapshot-000336        time 30m 21s      fid50k   157.1179
tick 43    kimg 344.0     loss/reg: G ( 3.551 -1.000) D ( 0.244  0.112)  time 86400d 05h 57m sec/kimg 235.20  mem: GPU 2.86   CPU 6.30   exp
tick 44    kimg 352.0     loss/reg: G ( 3.637 -1.000) D ( 0.243  0.108)  time 86400d 06h 28m sec/kimg 235.67  mem: GPU 2.86   CPU 6.30   exp
tick 45    kimg 360.0     loss/reg: G ( 3.591 -1.000) D ( 0.233  0.106)  time 86400d 07h 00m sec/kimg 235.54  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.48Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.58Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.42Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.39Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.79Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.58Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 15s       ms/item 35.64Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.43Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 28s       ms/item 35.55Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 04s       ms/item 35.38Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.81Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 17s       ms/item 35.23Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.58Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.58Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 06s       ms/item 35.61Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.45Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 19s      ms/item 35.60Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.55Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.47Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 08s      ms/item 35.62Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.71Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 21s      ms/item 35.66Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 57s      ms/item 35.42Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 34s      ms/item 35.77Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 10s      ms/item 35.73Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 47s      ms/item 35.44Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 23s      ms/item 35.79Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 59s      ms/item 35.21Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 36s      ms/item 35.67Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 12s      ms/item 35.73Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 49s      ms/item 35.60Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 25s      ms/item 35.58Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 02s      ms/item 35.39Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 38s      ms/item 35.56Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 15s      ms/item 35.68Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 51s      ms/item 35.22Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 27s      ms/item 35.78Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 04s      ms/item 35.43Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 40s      ms/item 35.62Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 17s      ms/item 35.69Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 53s      ms/item 35.64Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 29s      ms/item 35.50Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 06s      ms/item 35.72Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 42s      ms/item 35.41Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 19s      ms/item 35.56Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 55s      ms/item 35.48Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 32s      ms/item 35.75Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 08s      ms/item 35.44Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 40s      ms/item 37.60                                                                                                    
network-snapshot-000360        time 29m 46s      fid50k   156.1439
tick 46    kimg 368.0     loss/reg: G ( 3.590 -1.000) D ( 0.247  0.106)  time 86400d 08h 01m sec/kimg 235.06  mem: GPU 2.89   CPU 6.30   exp
tick 47    kimg 376.0     loss/reg: G ( 3.707 -1.000) D ( 0.209  0.107)  time 86400d 08h 32m sec/kimg 235.34  mem: GPU 2.89   CPU 6.30   exp
tick 48    kimg 384.0     loss/reg: G ( 3.632 -1.000) D ( 0.238  0.110)  time 86400d 09h 04m sec/kimg 235.45  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.19Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.27Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.05Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.36Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.38Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.17Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.24Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.18Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.42Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.34Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.08Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 26s       ms/item 36.40Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 03s       ms/item 36.23Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.34Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.23Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.21Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.17Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.51Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.20Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 23s      ms/item 36.14Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 00s      ms/item 36.22Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.33Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.40Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.32Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 28s      ms/item 36.10Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 05s      ms/item 36.33Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 43s      ms/item 36.22Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 20s      ms/item 36.24Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.17Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 34s      ms/item 36.41Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 11s      ms/item 36.15Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 36.21Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 25s      ms/item 36.37Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 02s      ms/item 36.00Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 39s      ms/item 36.26Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 16s      ms/item 36.05Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 53s      ms/item 36.33Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.25Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 07s      ms/item 36.02Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.35Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.38Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 59s      ms/item 36.07Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 36s      ms/item 36.64Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 14s      ms/item 36.46Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 51s      ms/item 36.04Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 28s      ms/item 36.24Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 05s      ms/item 36.40Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 42s      ms/item 36.07Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.30                                                                                                    
network-snapshot-000384        time 30m 21s      fid50k   159.8037
tick 49    kimg 392.0     loss/reg: G ( 3.729 -1.000) D ( 0.208  0.107)  time 86400d 10h 05m sec/kimg 235.21  mem: GPU 2.88   CPU 6.30   exp
tick 50    kimg 400.0     loss/reg: G ( 3.696 -1.000) D ( 0.212  0.106)  time 86400d 10h 37m sec/kimg 235.45  mem: GPU 2.88   CPU 6.30   exp
tick 51    kimg 408.0     loss/reg: G ( 3.838 -1.000) D ( 0.197  0.105)  time 86400d 11h 08m sec/kimg 234.70  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.48Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.35Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.40Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.43Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.35Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.24Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.58Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.42Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.80Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.20Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.41Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 16s       ms/item 35.88Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 52s       ms/item 35.28Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 28s       ms/item 35.58Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 04s       ms/item 35.29Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 41s       ms/item 35.70Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 17s      ms/item 35.23Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 53s      ms/item 35.47Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 30s      ms/item 35.35Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 06s      ms/item 35.42Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 42s      ms/item 35.58Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 18s      ms/item 35.24Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 55s      ms/item 35.57Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 31s      ms/item 35.37Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 07s      ms/item 35.42Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 44s      ms/item 35.41Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 20s      ms/item 35.61Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 56s      ms/item 35.43Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 33s      ms/item 35.36Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 09s      ms/item 35.59Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 45s      ms/item 35.41Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 22s      ms/item 35.44Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 58s      ms/item 35.55Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 34s      ms/item 35.41Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 10s      ms/item 35.44Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 47s      ms/item 35.39Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 23s      ms/item 35.54Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 59s      ms/item 35.47Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 36s      ms/item 35.35Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 12s      ms/item 35.47Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 48s      ms/item 35.59Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 25s      ms/item 35.36Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 01s      ms/item 35.39Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 37s      ms/item 35.52Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 13s      ms/item 35.31Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 50s      ms/item 35.58Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 26s      ms/item 35.38Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 02s      ms/item 35.48Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 34s      ms/item 37.60                                                                                                    
network-snapshot-000408        time 29m 41s      fid50k   155.6287
tick 52    kimg 416.0     loss/reg: G ( 3.515 -1.000) D ( 0.246  0.100)  time 86400d 12h 09m sec/kimg 235.12  mem: GPU 2.90   CPU 6.30   exp
tick 53    kimg 424.0     loss/reg: G ( 3.788 -1.000) D ( 0.190  0.108)  time 86400d 12h 40m sec/kimg 234.83  mem: GPU 2.90   CPU 6.30   exp
tick 54    kimg 432.0     loss/reg: G ( 3.630 -1.000) D ( 0.221  0.103)  time 86400d 13h 12m sec/kimg 235.03  mem: GPU 2.90   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.18Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.35Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.92Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.04Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.18Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.25Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.24Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.28Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.36Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.03Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.37Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.21Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.60Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 39s       ms/item 36.26Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 16s       ms/item 36.14Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 53s       ms/item 36.15Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.41Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.22Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.29Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.35Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 36.40Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.15Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.42Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.05Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 28s      ms/item 36.31Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 05s      ms/item 36.08Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 42s      ms/item 36.24Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 19s      ms/item 36.32Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.49Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 34s      ms/item 36.33Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 11s      ms/item 36.05Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 36.41Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 25s      ms/item 35.93Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 02s      ms/item 36.26Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 39s      ms/item 36.41Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 16s      ms/item 36.29Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 53s      ms/item 36.10Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.43Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 08s      ms/item 36.11Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.43Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.36Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 59s      ms/item 36.24Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 36s      ms/item 36.18Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 13s      ms/item 36.16Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 50s      ms/item 36.01Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 27s      ms/item 36.26Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 04s      ms/item 36.32Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 41s      ms/item 36.16Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.32                                                                                                    
network-snapshot-000432        time 30m 21s      fid50k   159.3114
tick 55    kimg 440.0     loss/reg: G ( 3.631 -1.000) D ( 0.208  0.103)  time 86400d 14h 14m sec/kimg 235.52  mem: GPU 2.86   CPU 6.30   exp
tick 56    kimg 448.0     loss/reg: G ( 3.663 -1.000) D ( 0.235  0.097)  time 86400d 14h 45m sec/kimg 235.47  mem: GPU 2.86   CPU 6.30   exp
tick 57    kimg 456.0     loss/reg: G ( 3.658 -1.000) D ( 0.222  0.098)  time 86400d 15h 16m sec/kimg 235.26  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.58Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.46Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.53Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.38Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.62Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.46Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.51Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.56Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.58Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 04s       ms/item 35.69Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.32Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 17s       ms/item 35.76Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.46Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 30s       ms/item 35.72Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 06s       ms/item 35.45Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.59Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 19s      ms/item 35.59Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.61Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 32s      ms/item 35.61Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 08s      ms/item 35.57Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 45s      ms/item 35.55Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 21s      ms/item 35.58Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 57s      ms/item 35.56Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 34s      ms/item 35.47Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 10s      ms/item 35.63Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 47s      ms/item 35.55Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 23s      ms/item 35.52Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 59s      ms/item 35.54Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 36s      ms/item 35.64Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 13s      ms/item 35.91Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 49s      ms/item 35.61Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 25s      ms/item 35.43Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 02s      ms/item 35.62Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 38s      ms/item 35.74Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 15s      ms/item 35.43Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 51s      ms/item 35.78Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 28s      ms/item 35.46Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 04s      ms/item 35.62Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 41s      ms/item 35.60Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 17s      ms/item 35.53Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 53s      ms/item 35.59Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 30s      ms/item 35.58Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 06s      ms/item 35.61Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 43s      ms/item 35.67Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 19s      ms/item 35.69Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 56s      ms/item 35.46Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 32s      ms/item 35.61Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 09s      ms/item 35.58Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 41s      ms/item 37.60                                                                                                    
network-snapshot-000456        time 29m 47s      fid50k   156.5656
tick 58    kimg 464.0     loss/reg: G ( 3.767 -1.000) D ( 0.213  0.104)  time 86400d 16h 17m sec/kimg 235.49  mem: GPU 2.86   CPU 6.30   exp
tick 59    kimg 472.0     loss/reg: G ( 3.716 -1.000) D ( 0.214  0.094)  time 86400d 16h 49m sec/kimg 235.24  mem: GPU 2.86   CPU 6.30   exp
tick 60    kimg 480.0     loss/reg: G ( 3.736 -1.000) D ( 0.191  0.101)  time 86400d 17h 20m sec/kimg 235.62  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.60Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 15s       ms/item 36.33Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 52s       ms/item 36.17Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.18Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.80Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.12Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.11Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 58s       ms/item 36.54Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 35s       ms/item 36.36Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 12s       ms/item 36.13Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 49s       ms/item 36.26Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 27s       ms/item 36.50Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 04s       ms/item 36.24Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 41s       ms/item 36.40Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 18s       ms/item 36.16Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 55s       ms/item 36.49Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 32s      ms/item 36.11Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 10s      ms/item 36.32Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 47s      ms/item 36.26Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 24s      ms/item 36.22Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 01s      ms/item 36.33Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 38s      ms/item 36.21Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 15s      ms/item 36.36Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 53s      ms/item 36.47Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 30s      ms/item 36.33Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 07s      ms/item 36.25Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 44s      ms/item 36.34Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 21s      ms/item 36.15Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 58s      ms/item 36.30Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 36s      ms/item 36.44Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 13s      ms/item 36.39Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 50s      ms/item 36.41Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 27s      ms/item 36.22Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 05s      ms/item 36.39Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 42s      ms/item 36.37Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 19s      ms/item 36.09Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 56s      ms/item 36.53Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 33s      ms/item 36.21Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 10s      ms/item 36.40Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 48s      ms/item 36.65Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 25s      ms/item 36.23Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 02s      ms/item 36.48Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 40s      ms/item 36.26Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 17s      ms/item 36.36Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 54s      ms/item 36.27Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 31s      ms/item 36.22Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 08s      ms/item 36.47Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 46s      ms/item 36.24Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 18s      ms/item 38.39                                                                                                    
network-snapshot-000480        time 30m 25s      fid50k   158.7503
tick 61    kimg 488.0     loss/reg: G ( 3.823 -1.000) D ( 0.187  0.099)  time 86400d 18h 22m sec/kimg 235.68  mem: GPU 2.88   CPU 6.30   exp
tick 62    kimg 496.0     loss/reg: G ( 3.843 -1.000) D ( 0.197  0.101)  time 86400d 18h 53m sec/kimg 235.16  mem: GPU 2.88   CPU 6.30   exp
tick 63    kimg 504.0     loss/reg: G ( 3.943 -1.000) D ( 0.169  0.096)  time 86400d 19h 25m sec/kimg 235.29  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.61Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.40Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.37Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.42Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.61Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.40Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.46Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.53Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.46Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.37Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.43Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 16s       ms/item 35.57Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 52s       ms/item 35.45Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.52Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 05s       ms/item 35.45Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 41s       ms/item 35.55Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 17s      ms/item 35.40Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 54s      ms/item 35.49Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 30s      ms/item 35.36Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 06s      ms/item 35.43Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 43s      ms/item 35.42Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 19s      ms/item 35.37Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 55s      ms/item 35.56Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 32s      ms/item 35.48Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 08s      ms/item 35.52Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 44s      ms/item 35.44Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 21s      ms/item 35.61Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 57s      ms/item 35.52Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 33s      ms/item 35.53Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 10s      ms/item 35.50Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 46s      ms/item 35.39Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 22s      ms/item 35.60Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 59s      ms/item 35.74Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 35s      ms/item 35.31Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 12s      ms/item 35.71Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 48s      ms/item 35.70Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 25s      ms/item 35.56Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 01s      ms/item 35.44Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 37s      ms/item 35.58Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 14s      ms/item 35.42Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 50s      ms/item 35.39Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 27s      ms/item 35.73Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 03s      ms/item 35.62Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 40s      ms/item 35.60Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 16s      ms/item 35.44Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 52s      ms/item 35.44Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 28s      ms/item 35.53Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 05s      ms/item 35.47Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 37s      ms/item 37.68                                                                                                    
network-snapshot-000504        time 29m 44s      fid50k   158.7144
tick 64    kimg 512.0     loss/reg: G ( 3.760 -1.000) D ( 0.224  0.090)  time 86400d 20h 26m sec/kimg 235.14  mem: GPU 2.86   CPU 6.30   exp
tick 65    kimg 520.0     loss/reg: G ( 3.873 -1.000) D ( 0.173  0.097)  time 86400d 20h 57m sec/kimg 235.00  mem: GPU 2.86   CPU 6.30   exp
tick 66    kimg 528.0     loss/reg: G ( 3.740 -1.000) D ( 0.201  0.099)  time 86400d 21h 29m sec/kimg 234.96  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.19Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.56Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 52s       ms/item 36.28Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 35.86Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.20Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.20Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.22Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.21Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.33Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.27Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.16Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.44Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.24Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.25Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.10Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.42Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.15Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.39Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.25Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 00s      ms/item 36.36Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.21Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.31Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.41Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 28s      ms/item 36.07Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 06s      ms/item 36.65Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 43s      ms/item 36.12Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 20s      ms/item 36.48Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.05Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 34s      ms/item 36.44Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 11s      ms/item 36.03Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 36.26Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 25s      ms/item 36.41Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 03s      ms/item 36.21Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 40s      ms/item 36.19Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 17s      ms/item 36.19Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 54s      ms/item 36.23Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.21Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 08s      ms/item 36.29Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.64Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 23s      ms/item 36.20Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 00s      ms/item 36.45Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 37s      ms/item 36.21Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 14s      ms/item 36.19Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 51s      ms/item 36.47Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 28s      ms/item 36.15Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 05s      ms/item 36.17Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 43s      ms/item 36.39Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 15s      ms/item 38.17                                                                                                    
network-snapshot-000528        time 30m 22s      fid50k   153.2963
tick 67    kimg 536.0     loss/reg: G ( 3.907 -1.000) D ( 0.169  0.091)  time 86400d 22h 30m sec/kimg 235.04  mem: GPU 2.88   CPU 6.30   exp
tick 68    kimg 544.0     loss/reg: G ( 3.831 -1.000) D ( 0.181  0.098)  time 86400d 23h 02m sec/kimg 235.35  mem: GPU 2.88   CPU 6.30   exp
tick 69    kimg 552.0     loss/reg: G ( 3.920 -1.000) D ( 0.180  0.089)  time 86400d 23h 33m sec/kimg 235.27  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.32Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.58Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.41Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.43Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.39Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.49Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.52Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.45Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.51Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.45Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.56Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 16s       ms/item 35.28Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 52s       ms/item 35.57Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 28s       ms/item 35.60Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 05s       ms/item 35.35Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 41s       ms/item 35.60Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 17s      ms/item 35.45Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 54s      ms/item 35.44Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 30s      ms/item 35.83Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 07s      ms/item 35.48Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 43s      ms/item 35.39Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 19s      ms/item 35.37Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 56s      ms/item 35.45Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 32s      ms/item 35.44Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 08s      ms/item 35.50Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 44s      ms/item 35.34Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 21s      ms/item 35.57Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 57s      ms/item 35.55Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 33s      ms/item 35.42Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 10s      ms/item 35.58Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 46s      ms/item 35.40Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 22s      ms/item 35.40Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 59s      ms/item 35.44Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 35s      ms/item 35.62Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 12s      ms/item 35.77Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 48s      ms/item 35.41Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 24s      ms/item 35.42Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 01s      ms/item 35.38Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 37s      ms/item 35.45Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 13s      ms/item 35.52Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 49s      ms/item 35.40Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 26s      ms/item 35.64Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 02s      ms/item 35.39Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 38s      ms/item 35.19Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 15s      ms/item 35.60Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 51s      ms/item 35.56Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 27s      ms/item 35.47Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 04s      ms/item 35.49Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 36s      ms/item 37.46                                                                                                    
network-snapshot-000552        time 29m 42s      fid50k   152.6196
tick 70    kimg 560.0     loss/reg: G ( 3.895 -1.000) D ( 0.176  0.094)  time 86400d 00h 34m sec/kimg 234.77  mem: GPU 2.88   CPU 6.30   exp
tick 71    kimg 568.0     loss/reg: G ( 3.904 -1.000) D ( 0.169  0.089)  time 86400d 01h 05m sec/kimg 235.30  mem: GPU 2.88   CPU 6.30   exp
tick 72    kimg 576.0     loss/reg: G ( 4.006 -1.000) D ( 0.150  0.088)  time 86400d 01h 37m sec/kimg 235.06  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.56Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 15s       ms/item 36.34Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.92Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.41Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.12Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.21Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.22Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.10Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.19Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.20Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.31Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.37Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.07Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 39s       ms/item 36.20Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 16s       ms/item 36.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 53s       ms/item 36.17Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.65Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.03Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.24Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.13Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 36.28Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 36s      ms/item 36.09Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 13s      ms/item 36.35Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 50s      ms/item 36.05Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 27s      ms/item 36.36Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 04s      ms/item 36.08Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 42s      ms/item 36.35Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 19s      ms/item 36.27Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 56s      ms/item 36.58Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 33s      ms/item 36.15Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 10s      ms/item 36.08Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 36.45Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 24s      ms/item 36.06Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 01s      ms/item 36.09Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 39s      ms/item 36.36Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 16s      ms/item 36.39Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 53s      ms/item 36.15Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 30s      ms/item 36.15Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 07s      ms/item 36.32Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 44s      ms/item 36.43Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 21s      ms/item 35.92Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 58s      ms/item 36.27Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 36s      ms/item 36.48Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 13s      ms/item 35.99Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 50s      ms/item 36.08Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 27s      ms/item 36.48Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 04s      ms/item 36.33Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 41s      ms/item 36.09Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.26                                                                                                    
network-snapshot-000576        time 30m 20s      fid50k   153.2303
tick 73    kimg 584.0     loss/reg: G ( 3.881 -1.000) D ( 0.182  0.093)  time 86400d 02h 38m sec/kimg 234.94  mem: GPU 2.86   CPU 6.30   exp
tick 74    kimg 592.0     loss/reg: G ( 3.942 -1.000) D ( 0.172  0.092)  time 86400d 03h 10m sec/kimg 235.17  mem: GPU 2.86   CPU 6.30   exp
tick 75    kimg 600.0     loss/reg: G ( 3.926 -1.000) D ( 0.163  0.093)  time 86400d 03h 41m sec/kimg 234.80  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.62Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.34Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.43Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.43Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.32Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.69Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.33Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.31Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.38Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.40Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.53Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 35.25Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.39Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 28s       ms/item 35.57Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 04s       ms/item 35.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 40s       ms/item 35.59Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 17s      ms/item 35.40Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 53s      ms/item 35.62Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 29s      ms/item 35.39Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 06s      ms/item 35.44Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 42s      ms/item 35.35Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 18s      ms/item 35.44Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 54s      ms/item 35.41Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 31s      ms/item 35.56Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 07s      ms/item 35.39Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 43s      ms/item 35.26Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 19s      ms/item 35.42Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 56s      ms/item 35.57Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 32s      ms/item 35.42Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 09s      ms/item 35.62Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 45s      ms/item 35.63Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 21s      ms/item 35.32Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 57s      ms/item 35.39Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 34s      ms/item 35.45Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 10s      ms/item 35.50Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 47s      ms/item 35.87Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 23s      ms/item 35.51Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 59s      ms/item 35.34Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 36s      ms/item 35.72Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 12s      ms/item 35.40Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 49s      ms/item 35.46Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 25s      ms/item 35.54Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 01s      ms/item 35.41Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 37s      ms/item 35.39Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 14s      ms/item 35.59Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 50s      ms/item 35.49Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 27s      ms/item 35.51Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 03s      ms/item 35.46Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 35s      ms/item 37.42                                                                                                    
network-snapshot-000600        time 29m 41s      fid50k   150.7981
tick 76    kimg 608.0     loss/reg: G ( 4.078 -1.000) D ( 0.128  0.089)  time 86400d 04h 42m sec/kimg 235.25  mem: GPU 2.89   CPU 6.30   exp
tick 77    kimg 616.0     loss/reg: G ( 3.814 -1.000) D ( 0.201  0.087)  time 86400d 05h 14m sec/kimg 235.22  mem: GPU 2.89   CPU 6.30   exp
tick 78    kimg 624.0     loss/reg: G ( 3.995 -1.000) D ( 0.154  0.087)  time 86400d 05h 45m sec/kimg 234.85  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.26Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.20Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.23Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.00Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.54Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.22Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.50Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.07Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.04Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.40Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.33Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.05Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.23Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 39s       ms/item 36.20Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 16s       ms/item 36.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.25Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.22Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.17Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.20Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.17Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 35.97Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 36s      ms/item 36.37Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 13s      ms/item 36.33Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 50s      ms/item 36.33Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 27s      ms/item 36.20Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 04s      ms/item 36.07Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 42s      ms/item 36.35Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 19s      ms/item 36.55Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 56s      ms/item 36.05Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 33s      ms/item 36.38Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 10s      ms/item 36.08Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 47s      ms/item 36.49Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 25s      ms/item 36.44Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 02s      ms/item 36.23Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 39s      ms/item 36.35Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 17s      ms/item 36.57Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 53s      ms/item 36.05Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.20Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 08s      ms/item 36.24Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.38Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.21Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 59s      ms/item 36.33Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 36s      ms/item 36.11Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 13s      ms/item 36.27Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 50s      ms/item 36.32Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 27s      ms/item 36.13Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 05s      ms/item 36.20Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 41s      ms/item 36.05Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.64                                                                                                    
network-snapshot-000624        time 30m 21s      fid50k   147.9588
tick 79    kimg 632.0     loss/reg: G ( 3.880 -1.000) D ( 0.188  0.088)  time 86400d 06h 47m sec/kimg 235.08  mem: GPU 2.88   CPU 6.30   exp
tick 80    kimg 640.0     loss/reg: G ( 4.006 -1.000) D ( 0.142  0.092)  time 86400d 07h 18m sec/kimg 235.12  mem: GPU 2.88   CPU 6.30   exp
tick 81    kimg 648.0     loss/reg: G ( 3.978 -1.000) D ( 0.153  0.087)  time 86400d 07h 49m sec/kimg 235.13  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.55Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.52Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.43Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 26s       ms/item 35.64Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.33Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.42Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.63Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.52Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.46Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.38Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.63Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 17s       ms/item 35.78Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.40Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.59Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 05s       ms/item 35.44Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.55Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 18s      ms/item 35.41Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.60Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.40Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 07s      ms/item 35.63Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.37Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 20s      ms/item 35.65Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 56s      ms/item 35.56Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 33s      ms/item 35.41Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 09s      ms/item 35.38Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 45s      ms/item 35.65Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 22s      ms/item 35.53Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 58s      ms/item 35.25Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 35s      ms/item 35.82Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 11s      ms/item 35.34Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 47s      ms/item 35.65Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 24s      ms/item 35.62Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 00s      ms/item 35.35Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 36s      ms/item 35.56Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 13s      ms/item 35.64Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 50s      ms/item 35.78Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 26s      ms/item 35.46Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 02s      ms/item 35.59Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 39s      ms/item 35.53Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 15s      ms/item 35.62Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 52s      ms/item 35.46Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 28s      ms/item 35.36Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 04s      ms/item 35.86Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 41s      ms/item 35.54Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 17s      ms/item 35.37Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 54s      ms/item 35.62Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 30s      ms/item 35.40Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 06s      ms/item 35.59Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 38s      ms/item 37.57                                                                                                    
network-snapshot-000648        time 29m 45s      fid50k   146.3226
tick 82    kimg 656.0     loss/reg: G ( 4.044 -1.000) D ( 0.168  0.089)  time 86400d 08h 50m sec/kimg 235.28  mem: GPU 2.87   CPU 6.30   exp
tick 83    kimg 664.0     loss/reg: G ( 3.885 -1.000) D ( 0.159  0.086)  time 86400d 09h 22m sec/kimg 235.02  mem: GPU 2.87   CPU 6.30   exp
tick 84    kimg 672.0     loss/reg: G ( 3.980 -1.000) D ( 0.145  0.091)  time 86400d 09h 53m sec/kimg 235.34  mem: GPU 2.87   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.15Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 15s       ms/item 36.61Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.06Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.38Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.24Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 35.98Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.33Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.39Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.21Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.09Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.29Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.21Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.25Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.21Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.22Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.23Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.36Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.33Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 46s      ms/item 36.45Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.05Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 36.20Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.35Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.27Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.38Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 28s      ms/item 36.21Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 05s      ms/item 36.38Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 42s      ms/item 36.02Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 19s      ms/item 36.17Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.42Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 34s      ms/item 36.33Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 11s      ms/item 36.08Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 36.47Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 25s      ms/item 36.36Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 02s      ms/item 36.13Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 40s      ms/item 36.37Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 17s      ms/item 36.11Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 54s      ms/item 36.30Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.26Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 08s      ms/item 36.50Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.12Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.32Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 00s      ms/item 36.23Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 37s      ms/item 36.58Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 14s      ms/item 36.21Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 51s      ms/item 36.21Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 28s      ms/item 36.24Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 06s      ms/item 36.53Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 43s      ms/item 36.16Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 15s      ms/item 38.16                                                                                                    
network-snapshot-000672        time 30m 22s      fid50k   143.3860
tick 85    kimg 680.0     loss/reg: G ( 4.109 -1.000) D ( 0.142  0.085)  time 86400d 10h 55m sec/kimg 235.20  mem: GPU 2.88   CPU 6.30   exp
tick 86    kimg 688.0     loss/reg: G ( 4.024 -1.000) D ( 0.157  0.083)  time 86400d 11h 26m sec/kimg 234.98  mem: GPU 2.88   CPU 6.30   exp
tick 87    kimg 696.0     loss/reg: G ( 3.900 -1.000) D ( 0.187  0.081)  time 86400d 11h 58m sec/kimg 235.32  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.33Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.38Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.37Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.38Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.54Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.24Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.43Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.27Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.73Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.37Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.20Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 35.42Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.46Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 28s       ms/item 35.54Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 04s       ms/item 35.27Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 40s       ms/item 35.59Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 16s      ms/item 35.33Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 53s      ms/item 35.41Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 29s      ms/item 35.42Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 05s      ms/item 35.46Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 41s      ms/item 35.33Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 18s      ms/item 35.46Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 54s      ms/item 35.59Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 30s      ms/item 35.46Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 07s      ms/item 35.28Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 43s      ms/item 35.47Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 19s      ms/item 35.42Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 55s      ms/item 35.52Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 32s      ms/item 35.55Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 08s      ms/item 35.43Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 44s      ms/item 35.45Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 21s      ms/item 35.43Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 57s      ms/item 35.42Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 33s      ms/item 35.55Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 10s      ms/item 35.58Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 46s      ms/item 35.38Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 22s      ms/item 35.40Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 59s      ms/item 35.39Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 35s      ms/item 35.44Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 11s      ms/item 35.45Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 48s      ms/item 35.64Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 24s      ms/item 35.50Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 00s      ms/item 35.39Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 36s      ms/item 35.39Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 13s      ms/item 35.46Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 49s      ms/item 35.42Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 25s      ms/item 35.48Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 02s      ms/item 35.48Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 33s      ms/item 37.42                                                                                                    
network-snapshot-000696        time 29m 40s      fid50k   143.7942
tick 88    kimg 704.0     loss/reg: G ( 4.120 -1.000) D ( 0.149  0.085)  time 86400d 12h 59m sec/kimg 235.15  mem: GPU 2.86   CPU 6.30   exp
tick 89    kimg 712.0     loss/reg: G ( 4.086 -1.000) D ( 0.137  0.082)  time 86400d 13h 30m sec/kimg 235.13  mem: GPU 2.86   CPU 6.30   exp
tick 90    kimg 720.0     loss/reg: G ( 4.080 -1.000) D ( 0.132  0.086)  time 86400d 14h 01m sec/kimg 235.37  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.43Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.03Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 52s       ms/item 36.48Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.33Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.23Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.39Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 21s       ms/item 36.63Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 58s       ms/item 36.13Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 35s       ms/item 36.21Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 12s       ms/item 36.36Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 49s       ms/item 36.11Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 26s       ms/item 36.37Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 03s       ms/item 36.20Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.18Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.21Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 55s       ms/item 36.65Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 32s      ms/item 36.19Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 09s      ms/item 36.58Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 46s      ms/item 36.18Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 24s      ms/item 36.39Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 01s      ms/item 36.37Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 38s      ms/item 36.60Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 16s      ms/item 36.24Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 53s      ms/item 36.20Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 30s      ms/item 36.23Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 07s      ms/item 36.29Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 44s      ms/item 36.11Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 21s      ms/item 36.74Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 58s      ms/item 36.10Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 36s      ms/item 36.28Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 13s      ms/item 36.42Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 50s      ms/item 36.07Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 27s      ms/item 36.21Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 04s      ms/item 36.40Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 41s      ms/item 36.41Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 19s      ms/item 36.33Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 56s      ms/item 36.06Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 33s      ms/item 36.56Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 10s      ms/item 36.17Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 47s      ms/item 36.44Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 25s      ms/item 36.42Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 02s      ms/item 36.02Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 39s      ms/item 36.14Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 16s      ms/item 36.41Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 53s      ms/item 36.35Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 30s      ms/item 36.05Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 07s      ms/item 36.24Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 44s      ms/item 36.24Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 17s      ms/item 38.29                                                                                                    
network-snapshot-000720        time 30m 23s      fid50k   142.9257
tick 91    kimg 728.0     loss/reg: G ( 4.152 -1.000) D ( 0.122  0.086)  time 86400d 15h 03m sec/kimg 234.94  mem: GPU 2.88   CPU 6.30   exp
tick 92    kimg 736.0     loss/reg: G ( 4.036 -1.000) D ( 0.149  0.085)  time 86400d 15h 34m sec/kimg 235.27  mem: GPU 2.88   CPU 6.30   exp
tick 93    kimg 744.0     loss/reg: G ( 4.029 -1.000) D ( 0.162  0.079)  time 86400d 16h 06m sec/kimg 235.19  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.41Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.66Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.49Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.53Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.54Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.45Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.38Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.60Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.59Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 04s       ms/item 35.59Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.58Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 17s       ms/item 35.58Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.50Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.54Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 06s       ms/item 35.56Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.64Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 19s      ms/item 35.38Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.58Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.42Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 08s      ms/item 35.60Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.42Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 21s      ms/item 35.78Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 57s      ms/item 35.67Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 33s      ms/item 35.34Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 10s      ms/item 35.40Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 46s      ms/item 35.64Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 22s      ms/item 35.52Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 59s      ms/item 35.29Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 35s      ms/item 35.56Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 11s      ms/item 35.51Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 48s      ms/item 35.54Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 24s      ms/item 35.53Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 00s      ms/item 35.56Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 37s      ms/item 35.52Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 13s      ms/item 35.63Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 50s      ms/item 35.71Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 26s      ms/item 35.42Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 02s      ms/item 35.26Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 39s      ms/item 35.61Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 15s      ms/item 35.62Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 52s      ms/item 35.71Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 28s      ms/item 35.39Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 04s      ms/item 35.40Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 41s      ms/item 35.61Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 17s      ms/item 35.60Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 53s      ms/item 35.40Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 30s      ms/item 35.45Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 06s      ms/item 35.60Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 38s      ms/item 37.76                                                                                                    
network-snapshot-000744        time 29m 45s      fid50k   141.1702
tick 94    kimg 752.0     loss/reg: G ( 4.266 -1.000) D ( 0.117  0.080)  time 86400d 17h 07m sec/kimg 234.98  mem: GPU 2.86   CPU 6.30   exp
tick 95    kimg 760.0     loss/reg: G ( 4.022 -1.000) D ( 0.168  0.078)  time 86400d 17h 38m sec/kimg 235.27  mem: GPU 2.86   CPU 6.30   exp
tick 96    kimg 768.0     loss/reg: G ( 4.125 -1.000) D ( 0.122  0.082)  time 86400d 18h 10m sec/kimg 235.25  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 38s          ms/item 36.70Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 15s       ms/item 36.33Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 52s       ms/item 36.05Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.01Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.05Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.22Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.38Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.20Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.15Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.25Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.13Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.21Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.33Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.56Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.04Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.65Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.09Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.17Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.24Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.01Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 36.40Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 36s      ms/item 36.17Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.37Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.21Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 28s      ms/item 36.02Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 05s      ms/item 36.32Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 42s      ms/item 36.09Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 19s      ms/item 36.23Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 56s      ms/item 36.36Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 33s      ms/item 36.00Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 10s      ms/item 36.24Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 47s      ms/item 36.35Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 24s      ms/item 36.25Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 01s      ms/item 36.14Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 38s      ms/item 36.16Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 16s      ms/item 36.51Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 53s      ms/item 36.35Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 30s      ms/item 36.18Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 07s      ms/item 36.25Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.39Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.46Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 59s      ms/item 36.15Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 36s      ms/item 36.27Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 13s      ms/item 36.08Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 50s      ms/item 36.26Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 27s      ms/item 36.44Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 04s      ms/item 36.04Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 41s      ms/item 36.27Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.44                                                                                                    
network-snapshot-000768        time 30m 20s      fid50k   136.0143
tick 97    kimg 776.0     loss/reg: G ( 4.073 -1.000) D ( 0.134  0.080)  time 86400d 19h 11m sec/kimg 235.16  mem: GPU 2.89   CPU 6.30   exp
tick 98    kimg 784.0     loss/reg: G ( 4.078 -1.000) D ( 0.141  0.079)  time 86400d 19h 43m sec/kimg 235.42  mem: GPU 2.89   CPU 6.30   exp
tick 99    kimg 792.0     loss/reg: G ( 4.235 -1.000) D ( 0.101  0.084)  time 86400d 20h 14m sec/kimg 235.21  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.57Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.67Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.39Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 26s       ms/item 35.60Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.40Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.64Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 15s       ms/item 35.38Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.38Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.62Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 04s       ms/item 35.42Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.40Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 16s       ms/item 35.43Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.66Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.70Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 05s       ms/item 35.40Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.42Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 18s      ms/item 35.56Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 54s      ms/item 35.30Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.73Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 07s      ms/item 35.55Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.46Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 20s      ms/item 35.62Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 56s      ms/item 35.43Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 33s      ms/item 35.56Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 09s      ms/item 35.59Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 46s      ms/item 35.63Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 22s      ms/item 35.56Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 58s      ms/item 35.40Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 35s      ms/item 35.38Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 11s      ms/item 35.69Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 47s      ms/item 35.40Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 24s      ms/item 35.62Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 00s      ms/item 35.57Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 37s      ms/item 35.43Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 13s      ms/item 35.36Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 49s      ms/item 35.79Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 26s      ms/item 35.58Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 02s      ms/item 35.37Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 38s      ms/item 35.50Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 15s      ms/item 35.68Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 51s      ms/item 35.39Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 28s      ms/item 35.51Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 04s      ms/item 35.57Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 40s      ms/item 35.48Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 17s      ms/item 35.51Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 53s      ms/item 35.63Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 29s      ms/item 35.46Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 06s      ms/item 35.69Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 38s      ms/item 37.43                                                                                                    
network-snapshot-000792        time 29m 44s      fid50k   137.6925
tick 100   kimg 800.0     loss/reg: G ( 4.138 -1.000) D ( 0.133  0.083)  time 86400d 21h 15m sec/kimg 235.28  mem: GPU 2.86   CPU 6.30   exp
tick 101   kimg 808.0     loss/reg: G ( 4.124 -1.000) D ( 0.136  0.077)  time 86400d 21h 47m sec/kimg 235.34  mem: GPU 2.86   CPU 6.30   exp
tick 102   kimg 816.0     loss/reg: G ( 4.137 -1.000) D ( 0.138  0.077)  time 86400d 22h 18m sec/kimg 235.00  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.29Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.45Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.88Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.04Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.26Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.13Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.09Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.21Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.29Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.25Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.36Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.33Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.32Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 39s       ms/item 36.17Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.46Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.07Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.24Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.20Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.23Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.20Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 36.25Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 36s      ms/item 36.33Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 13s      ms/item 36.20Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 50s      ms/item 36.14Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 27s      ms/item 36.08Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 04s      ms/item 36.19Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 41s      ms/item 36.21Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 19s      ms/item 36.62Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 56s      ms/item 36.01Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 33s      ms/item 36.15Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 10s      ms/item 36.24Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 47s      ms/item 36.30Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 24s      ms/item 36.08Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 01s      ms/item 36.17Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 38s      ms/item 36.41Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 16s      ms/item 36.43Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 53s      ms/item 36.23Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 30s      ms/item 36.35Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 07s      ms/item 36.53Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 44s      ms/item 36.05Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.55Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 59s      ms/item 36.25Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 36s      ms/item 36.25Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 13s      ms/item 36.34Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 50s      ms/item 36.48Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 28s      ms/item 36.20Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 05s      ms/item 36.25Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 42s      ms/item 36.26Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.33                                                                                                    
network-snapshot-000816        time 30m 21s      fid50k   138.3344
tick 103   kimg 824.0     loss/reg: G ( 4.163 -1.000) D ( 0.122  0.082)  time 86400d 23h 20m sec/kimg 235.48  mem: GPU 2.86   CPU 6.30   exp
tick 104   kimg 832.0     loss/reg: G ( 4.254 -1.000) D ( 0.117  0.080)  time 86400d 23h 51m sec/kimg 235.29  mem: GPU 2.86   CPU 6.30   exp
tick 105   kimg 840.0     loss/reg: G ( 4.114 -1.000) D ( 0.146  0.079)  time 86400d 00h 22m sec/kimg 235.19  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.62Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.56Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.64Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 26s       ms/item 35.43Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.54Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.41Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 15s       ms/item 35.59Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.46Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 28s       ms/item 35.75Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 04s       ms/item 35.49Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.55Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 17s       ms/item 35.56Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.59Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 30s       ms/item 35.56Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 06s       ms/item 35.60Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.28Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 19s      ms/item 35.61Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.71Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 32s      ms/item 35.50Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 08s      ms/item 35.57Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 45s      ms/item 35.64Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 21s      ms/item 35.44Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 58s      ms/item 35.84Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 34s      ms/item 35.33Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 10s      ms/item 35.36Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 46s      ms/item 35.65Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 23s      ms/item 35.58Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 59s      ms/item 35.35Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 36s      ms/item 35.57Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 12s      ms/item 35.37Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 48s      ms/item 35.66Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 25s      ms/item 35.46Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 01s      ms/item 35.77Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 37s      ms/item 35.43Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 14s      ms/item 35.78Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 50s      ms/item 35.42Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 27s      ms/item 35.55Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 03s      ms/item 35.47Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 39s      ms/item 35.55Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 16s      ms/item 35.47Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 52s      ms/item 35.51Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 28s      ms/item 35.40Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 05s      ms/item 35.54Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 41s      ms/item 35.47Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 18s      ms/item 35.65Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 54s      ms/item 35.42Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 30s      ms/item 35.56Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 07s      ms/item 35.63Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 39s      ms/item 37.40                                                                                                    
network-snapshot-000840        time 29m 45s      fid50k   138.1771
tick 106   kimg 848.0     loss/reg: G ( 4.142 -1.000) D ( 0.152  0.079)  time 86400d 01h 24m sec/kimg 235.34  mem: GPU 2.86   CPU 6.30   exp
tick 107   kimg 856.0     loss/reg: G ( 4.085 -1.000) D ( 0.125  0.072)  time 86400d 01h 55m sec/kimg 235.11  mem: GPU 2.86   CPU 6.30   exp
tick 108   kimg 864.0     loss/reg: G ( 4.290 -1.000) D ( 0.113  0.078)  time 86400d 02h 26m sec/kimg 235.42  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.28Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.35Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.26Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.10Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.21Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 35.99Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.28Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.43Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.20Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.35Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.18Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.17Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.22Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.32Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 16s       ms/item 36.08Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.37Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.29Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.23Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.24Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.51Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 36.12Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.34Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.28Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.30Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 28s      ms/item 36.19Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 05s      ms/item 36.19Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 42s      ms/item 36.36Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 20s      ms/item 36.46Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.18Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 34s      ms/item 36.33Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 11s      ms/item 36.30Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 36.37Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 26s      ms/item 36.49Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 03s      ms/item 36.18Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 40s      ms/item 36.27Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 17s      ms/item 36.41Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 54s      ms/item 36.16Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.11Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 09s      ms/item 36.55Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 35.99Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 23s      ms/item 36.23Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 00s      ms/item 36.24Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 37s      ms/item 36.40Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 14s      ms/item 36.40Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 51s      ms/item 36.16Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 29s      ms/item 36.64Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 06s      ms/item 36.37Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 43s      ms/item 36.18Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 16s      ms/item 38.36                                                                                                    
network-snapshot-000864        time 30m 22s      fid50k   135.2665
tick 109   kimg 872.0     loss/reg: G ( 4.104 -1.000) D ( 0.134  0.077)  time 86400d 03h 28m sec/kimg 235.48  mem: GPU 2.86   CPU 6.30   exp
tick 110   kimg 880.0     loss/reg: G ( 4.266 -1.000) D ( 0.109  0.076)  time 86400d 04h 00m sec/kimg 235.12  mem: GPU 2.86   CPU 6.30   exp
tick 111   kimg 888.0     loss/reg: G ( 4.232 -1.000) D ( 0.124  0.080)  time 86400d 04h 31m sec/kimg 235.41  mem: GPU 2.86   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.53Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.65Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.40Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 26s       ms/item 35.61Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.61Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.46Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 15s       ms/item 35.51Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.61Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 28s       ms/item 35.53Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 04s       ms/item 35.50Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.55Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 17s       ms/item 35.44Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.34Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.62Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 06s       ms/item 35.93Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.22Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 19s      ms/item 35.56Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.69Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.50Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 08s      ms/item 35.54Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.41Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 20s      ms/item 35.51Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 57s      ms/item 35.63Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 33s      ms/item 35.48Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 10s      ms/item 35.65Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 46s      ms/item 35.67Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 23s      ms/item 35.54Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 59s      ms/item 35.47Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 35s      ms/item 35.42Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 12s      ms/item 35.45Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 48s      ms/item 35.58Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 24s      ms/item 35.56Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 01s      ms/item 35.42Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 37s      ms/item 35.57Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 13s      ms/item 35.43Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 50s      ms/item 35.56Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 26s      ms/item 35.47Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 02s      ms/item 35.38Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 39s      ms/item 35.55Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 15s      ms/item 35.66Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 52s      ms/item 35.55Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 28s      ms/item 35.54Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 04s      ms/item 35.34Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 41s      ms/item 35.55Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 17s      ms/item 35.38Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 53s      ms/item 35.57Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 30s      ms/item 35.41Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 06s      ms/item 35.46Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 38s      ms/item 37.63                                                                                                    
network-snapshot-000888        time 29m 44s      fid50k   133.8241
tick 112   kimg 896.0     loss/reg: G ( 4.002 -1.000) D ( 0.169  0.069)  time 86400d 05h 32m sec/kimg 235.55  mem: GPU 2.89   CPU 6.30   exp
tick 113   kimg 904.0     loss/reg: G ( 4.078 -1.000) D ( 0.140  0.074)  time 86400d 06h 03m sec/kimg 235.05  mem: GPU 2.89   CPU 6.30   exp
tick 114   kimg 912.0     loss/reg: G ( 4.305 -1.000) D ( 0.097  0.080)  time 86400d 06h 35m sec/kimg 235.28  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.21Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.07Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.09Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.42Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.19Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.29Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.60Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.56Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.04Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.31Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 49s       ms/item 36.48Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 26s       ms/item 36.28Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 03s       ms/item 36.34Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.33Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 18s       ms/item 36.41Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 55s       ms/item 36.12Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 32s      ms/item 36.13Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 09s      ms/item 36.36Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 46s      ms/item 36.18Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 23s      ms/item 36.20Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 00s      ms/item 36.44Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.24Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 15s      ms/item 36.23Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 52s      ms/item 36.34Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 29s      ms/item 36.24Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 06s      ms/item 36.44Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 43s      ms/item 36.26Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 20s      ms/item 36.15Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.19Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 35s      ms/item 36.27Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 12s      ms/item 36.25Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 49s      ms/item 36.59Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 26s      ms/item 36.37Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 04s      ms/item 36.48Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 41s      ms/item 35.99Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 18s      ms/item 36.38Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 55s      ms/item 36.24Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 32s      ms/item 36.31Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 09s      ms/item 36.23Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 46s      ms/item 36.09Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 23s      ms/item 36.38Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 01s      ms/item 36.30Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 38s      ms/item 36.24Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 15s      ms/item 36.36Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 52s      ms/item 35.99Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 29s      ms/item 36.55Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 06s      ms/item 36.15Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 43s      ms/item 36.20Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 16s      ms/item 38.33                                                                                                    
network-snapshot-000912        time 30m 22s      fid50k   132.3870
tick 115   kimg 920.0     loss/reg: G ( 4.076 -1.000) D ( 0.145  0.075)  time 86400d 07h 37m sec/kimg 235.23  mem: GPU 2.89   CPU 6.30   exp
tick 116   kimg 928.0     loss/reg: G ( 4.334 -1.000) D ( 0.096  0.078)  time 86400d 08h 08m sec/kimg 235.56  mem: GPU 2.89   CPU 6.30   exp
tick 117   kimg 936.0     loss/reg: G ( 4.117 -1.000) D ( 0.118  0.078)  time 86400d 08h 39m sec/kimg 235.32  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.64Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.43Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.32Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.43Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.86Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.31Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.44Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.43Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 27s       ms/item 35.38Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.60Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 40s       ms/item 35.48Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 16s       ms/item 35.44Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 53s       ms/item 35.70Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 29s       ms/item 35.56Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 05s       ms/item 35.63Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 42s       ms/item 35.38Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 18s      ms/item 35.48Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 55s      ms/item 35.76Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 31s      ms/item 35.43Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 07s      ms/item 35.56Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 44s      ms/item 35.41Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 20s      ms/item 35.46Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 56s      ms/item 35.59Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 33s      ms/item 35.48Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 09s      ms/item 35.44Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 45s      ms/item 35.40Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 22s      ms/item 35.83Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 58s      ms/item 35.59Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 34s      ms/item 35.25Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 11s      ms/item 35.43Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 47s      ms/item 35.56Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 23s      ms/item 35.39Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 00s      ms/item 35.52Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 36s      ms/item 35.44Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 12s      ms/item 35.52Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 49s      ms/item 35.51Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 25s      ms/item 35.35Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 01s      ms/item 35.46Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 38s      ms/item 35.58Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 14s      ms/item 35.20Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 50s      ms/item 35.68Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 26s      ms/item 35.32Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 03s      ms/item 35.61Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 39s      ms/item 35.42Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 16s      ms/item 35.56Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 52s      ms/item 35.46Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 28s      ms/item 35.55Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 05s      ms/item 35.60Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 36s      ms/item 37.38                                                                                                    
network-snapshot-000936        time 29m 43s      fid50k   133.3581
tick 118   kimg 944.0     loss/reg: G ( 4.271 -1.000) D ( 0.104  0.079)  time 86400d 09h 40m sec/kimg 234.95  mem: GPU 2.89   CPU 6.30   exp
tick 119   kimg 952.0     loss/reg: G ( 4.165 -1.000) D ( 0.117  0.073)  time 86400d 10h 12m sec/kimg 235.19  mem: GPU 2.89   CPU 6.30   exp
tick 120   kimg 960.0     loss/reg: G ( 4.216 -1.000) D ( 0.120  0.076)  time 86400d 10h 43m sec/kimg 235.29  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 38s          ms/item 36.67Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 15s       ms/item 36.42Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 52s       ms/item 36.15Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.25Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.59Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.11Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 21s       ms/item 36.32Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 58s       ms/item 36.33Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 35s       ms/item 36.02Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 12s       ms/item 36.35Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 49s       ms/item 36.43Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 27s       ms/item 36.43Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 04s       ms/item 36.20Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 41s       ms/item 36.18Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 18s       ms/item 36.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 55s       ms/item 36.43Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 32s      ms/item 36.18Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 09s      ms/item 36.39Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 46s      ms/item 36.00Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 23s      ms/item 36.38Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 01s      ms/item 36.21Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 38s      ms/item 36.19Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 15s      ms/item 36.41Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 52s      ms/item 36.25Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 29s      ms/item 36.18Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 06s      ms/item 36.41Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 44s      ms/item 36.55Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 21s      ms/item 36.23Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 58s      ms/item 36.01Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 35s      ms/item 36.21Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 12s      ms/item 36.17Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 49s      ms/item 36.18Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 26s      ms/item 36.40Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 03s      ms/item 36.42Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 40s      ms/item 36.16Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 18s      ms/item 36.24Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 55s      ms/item 36.49Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 32s      ms/item 36.27Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 09s      ms/item 36.24Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 47s      ms/item 36.40Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 24s      ms/item 36.37Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 01s      ms/item 36.17Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 38s      ms/item 36.48Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 15s      ms/item 36.32Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 52s      ms/item 35.97Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 29s      ms/item 36.27Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 06s      ms/item 36.24Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 44s      ms/item 36.59Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 16s      ms/item 37.90                                                                                                    
network-snapshot-000960        time 30m 23s      fid50k   132.8025
tick 121   kimg 968.0     loss/reg: G ( 4.310 -1.000) D ( 0.115  0.073)  time 86400d 11h 45m sec/kimg 234.91  mem: GPU 2.88   CPU 6.30   exp
tick 122   kimg 976.0     loss/reg: G ( 4.079 -1.000) D ( 0.137  0.070)  time 86400d 12h 16m sec/kimg 235.24  mem: GPU 2.88   CPU 6.30   exp
tick 123   kimg 984.0     loss/reg: G ( 4.173 -1.000) D ( 0.145  0.072)  time 86400d 12h 48m sec/kimg 234.80  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.53Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.30Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.49Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.69Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.34Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.45Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.34Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.40Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.25Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.39Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.42Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 35.57Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 52s       ms/item 35.38Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 28s       ms/item 35.38Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 04s       ms/item 35.47Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 41s       ms/item 35.57Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 17s      ms/item 35.39Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 53s      ms/item 35.45Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 29s      ms/item 35.42Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 06s      ms/item 35.52Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 42s      ms/item 35.43Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 19s      ms/item 35.61Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 55s      ms/item 35.43Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 31s      ms/item 35.39Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 07s      ms/item 35.39Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 44s      ms/item 35.58Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 20s      ms/item 35.43Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 56s      ms/item 35.58Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 33s      ms/item 35.39Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 09s      ms/item 35.57Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 45s      ms/item 35.44Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 22s      ms/item 35.41Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 58s      ms/item 35.53Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 34s      ms/item 35.44Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 11s      ms/item 35.62Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 47s      ms/item 35.37Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 23s      ms/item 35.41Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 00s      ms/item 35.41Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 36s      ms/item 35.56Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 12s      ms/item 35.39Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 49s      ms/item 35.49Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 25s      ms/item 35.77Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 01s      ms/item 35.35Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 38s      ms/item 35.41Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 14s      ms/item 35.44Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 50s      ms/item 35.38Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 26s      ms/item 35.38Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 03s      ms/item 35.67Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 35s      ms/item 37.36                                                                                                    
network-snapshot-000984        time 29m 41s      fid50k   132.9263
tick 124   kimg 992.0     loss/reg: G ( 4.377 -1.000) D ( 0.093  0.076)  time 86400d 13h 49m sec/kimg 235.23  mem: GPU 2.89   CPU 6.30   exp
tick 125   kimg 1000.0    loss/reg: G ( 4.336 -1.000) D ( 0.100  0.073)  time 86400d 14h 20m sec/kimg 235.16  mem: GPU 2.89   CPU 6.30   exp
tick 126   kimg 1008.0    loss/reg: G ( 4.329 -1.000) D ( 0.107  0.073)  time 86400d 14h 51m sec/kimg 234.89  mem: GPU 2.89   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.13Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.52Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 52s       ms/item 36.36Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.02Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.31Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.80Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.08Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.26Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.17Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 12s       ms/item 36.21Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 49s       ms/item 36.23Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 26s       ms/item 36.35Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 03s       ms/item 36.11Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.49Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.18Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 55s       ms/item 36.41Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 32s      ms/item 36.09Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 09s      ms/item 36.13Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 46s      ms/item 36.19Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 23s      ms/item 36.34Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 00s      ms/item 36.08Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.40Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.39Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.27Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 29s      ms/item 36.23Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 06s      ms/item 36.35Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 43s      ms/item 36.29Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 20s      ms/item 36.11Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 57s      ms/item 36.17Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 34s      ms/item 36.33Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 11s      ms/item 36.15Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 48s      ms/item 35.99Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 25s      ms/item 36.20Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 02s      ms/item 36.46Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 39s      ms/item 36.23Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 16s      ms/item 36.07Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 54s      ms/item 36.36Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 31s      ms/item 36.22Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 08s      ms/item 36.24Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 45s      ms/item 36.38Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 22s      ms/item 36.36Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 59s      ms/item 36.26Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 37s      ms/item 36.22Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 14s      ms/item 36.32Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 51s      ms/item 36.40Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 28s      ms/item 36.04Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 05s      ms/item 36.20Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 42s      ms/item 36.45Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 15s      ms/item 38.11                                                                                                    
network-snapshot-001008        time 30m 21s      fid50k   131.3652
tick 127   kimg 1016.0    loss/reg: G ( 4.252 -1.000) D ( 0.127  0.070)  time 86400d 15h 53m sec/kimg 235.16  mem: GPU 2.88   CPU 6.30   exp
tick 128   kimg 1024.0    loss/reg: G ( 4.274 -1.000) D ( 0.110  0.075)  time 86400d 16h 24m sec/kimg 235.15  mem: GPU 2.88   CPU 6.30   exp
tick 129   kimg 1032.0    loss/reg: G ( 4.145 -1.000) D ( 0.142  0.071)  time 86400d 16h 56m sec/kimg 234.93  mem: GPU 2.88   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.41Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.43Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.32Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.32Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.50Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.23Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.43Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.36Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.47Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 03s       ms/item 35.55Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 39s       ms/item 35.21Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 35.60Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.56Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 28s       ms/item 35.39Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 04s       ms/item 35.41Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 40s       ms/item 35.39Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 16s      ms/item 35.43Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 53s      ms/item 35.36Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 29s      ms/item 35.44Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 05s      ms/item 35.61Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 42s      ms/item 35.37Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 18s      ms/item 35.41Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 54s      ms/item 35.43Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 31s      ms/item 35.60Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 07s      ms/item 35.36Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 43s      ms/item 35.45Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 19s      ms/item 35.47Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 56s      ms/item 35.49Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 32s      ms/item 35.66Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 09s      ms/item 35.40Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 45s      ms/item 35.55Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 21s      ms/item 35.40Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 58s      ms/item 35.48Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 34s      ms/item 35.53Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 10s      ms/item 35.59Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 47s      ms/item 35.38Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 23s      ms/item 35.49Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 00s      ms/item 35.75Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 36s      ms/item 35.36Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 12s      ms/item 35.60Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 48s      ms/item 35.28Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 25s      ms/item 35.53Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 01s      ms/item 35.45Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 37s      ms/item 35.36Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 14s      ms/item 35.43Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 50s      ms/item 35.35Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 26s      ms/item 35.59Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 03s      ms/item 35.48Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 34s      ms/item 37.36                                                                                                    
network-snapshot-001032        time 29m 41s      fid50k   133.8283
tick 130   kimg 1040.0    loss/reg: G ( 4.345 -1.000) D ( 0.104  0.069)  time 86400d 17h 57m sec/kimg 235.17  mem: GPU 2.87   CPU 6.30   exp
tick 131   kimg 1048.0    loss/reg: G ( 4.282 -1.000) D ( 0.117  0.070)  time 86400d 18h 28m sec/kimg 234.99  mem: GPU 2.87   CPU 6.30   exp
tick 132   kimg 1056.0    loss/reg: G ( 4.154 -1.000) D ( 0.133  0.066)  time 86400d 18h 59m sec/kimg 235.21  mem: GPU 2.87   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.39Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.09Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.35Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 29s       ms/item 36.21Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 06s       ms/item 36.37Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 43s       ms/item 36.07Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 20s       ms/item 36.21Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 57s       ms/item 36.21Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 34s       ms/item 36.14Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 11s       ms/item 36.59Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 48s       ms/item 36.05Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.16Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.23Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 40s       ms/item 36.34Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 17s       ms/item 36.43Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.04Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 31s      ms/item 36.34Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 08s      ms/item 36.27Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 45s      ms/item 36.17Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 22s      ms/item 36.23Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 59s      ms/item 36.24Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 37s      ms/item 36.29Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 14s      ms/item 36.13Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 51s      ms/item 36.32Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 28s      ms/item 36.02Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 05s      ms/item 36.09Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 42s      ms/item 36.33Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 19s      ms/item 36.41Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 56s      ms/item 36.03Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 33s      ms/item 36.32Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 10s      ms/item 36.02Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 47s      ms/item 36.41Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 24s      ms/item 36.11Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 01s      ms/item 36.26Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 38s      ms/item 35.98Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 15s      ms/item 36.24Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 52s      ms/item 36.17Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 30s      ms/item 36.56Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 07s      ms/item 36.05Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 44s      ms/item 36.08Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 21s      ms/item 36.34Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 58s      ms/item 36.44Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 35s      ms/item 36.18Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 12s      ms/item 36.26Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 50s      ms/item 36.29Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 27s      ms/item 36.20Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 04s      ms/item 36.32Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 41s      ms/item 36.57Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 14s      ms/item 38.09                                                                                                    
network-snapshot-001056        time 30m 20s      fid50k   130.1365
tick 133   kimg 1064.0    loss/reg: G ( 4.459 -1.000) D ( 0.098  0.069)  time 86400d 20h 01m sec/kimg 235.26  mem: GPU 2.88   CPU 6.30   exp
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 386, in training_loop
    run_training_stage(loss, stage, device, real_img, real_c, gen_z, gen_c, batch_size, batch_gpu, num_gpus)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/training_loop.py", line 193, in run_training_stage
    gen_z = z, gen_c = cz, sync = sync, gain = stage.interval)
  File "/home/quoniam/Work/gansformer/pytorch_version/training/loss.py", line 86, in accumulate_gradients
    loss_G_main.mean().mul(gain).backward()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
Loading training set...
Error: Dataset folder datasets/iznik+/256 doesn't exists. Follow data preparation instructions using the prepare_data.py script.
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Resuming from results/exp-000/network-snapshot-001056.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 2 GPUs...
Setting up training stages...
Training for 25000 kimg...
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Resuming from results/exp-000/network-snapshot-001056.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 2 GPUs...
Setting up training stages...
Training for 25000 kimg...
Evaluation: computing generator features items 1024 /50000 (2.05%) time 22s          ms/item 21.61Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Process SpawnProcess-2:
Traceback (most recent call last):
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/home/quoniam/Work/TileGAN/gan/run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 350, in training_loop
    nets = construct_nets(cG, cD, dataset, device, log) if train else None        # Construct networks
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 73, in construct_nets
    G = dnnlib.util.construct_class_by_name(**cG, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nnnet
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 66, in _wrap
    sys.exit(1)
SystemExit: 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 300, in _bootstrap
    util._exit_function()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 140, in join
    res = self._popen.wait(timeout)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/popen_fork.py", line 48, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 7131) is killed by signal: Terminated. 
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Process SpawnProcess-2:
Traceback (most recent call last):
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/home/quoniam/Work/TileGAN/gan/run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 350, in training_loop
    nets = construct_nets(cG, cD, dataset, device, log) if train else None        # Construct networks
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 73, in construct_nets
    G = dnnlib.util.construct_class_by_name(**cG, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nnnet
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 66, in _wrap
    sys.exit(1)
SystemExit: 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 300, in _bootstrap
    util._exit_function()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/process.py", line 140, in join
    res = self._popen.wait(timeout)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/popen_fork.py", line 48, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 7363) is killed by signal: Terminated. 
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Constructing networks...
Resuming from results/exp-000/network-snapshot-001056.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Distributing across 1 GPUs...
Setting up training stages...
Training for 25000 kimg...
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.26Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 34.83Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.33Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.51Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.68Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 38s       ms/item 35.35Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 14s       ms/item 35.55Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 51s       ms/item 35.76Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 28s       ms/item 35.67Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 04s       ms/item 35.81Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 41s       ms/item 35.62Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 17s       ms/item 35.75Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 54s       ms/item 35.77Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 30s       ms/item 35.57Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 07s       ms/item 36.07Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 44s       ms/item 35.75Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 21s      ms/item 35.85Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 57s      ms/item 35.74Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 34s      ms/item 35.87Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 11s      ms/item 35.90Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 48s      ms/item 35.91Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 24s      ms/item 35.75Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 01s      ms/item 35.91Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 38s      ms/item 35.92Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 14s      ms/item 35.83Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 51s      ms/item 36.17Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 28s      ms/item 35.73Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 05s      ms/item 35.61Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 41s      ms/item 35.73Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 18s      ms/item 35.94Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 55s      ms/item 35.78Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 31s      ms/item 35.83Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 08s      ms/item 36.14Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 45s      ms/item 35.73Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 22s      ms/item 36.02Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 58s      ms/item 35.83Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 35s      ms/item 36.08Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 13s      ms/item 36.32Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 49s      ms/item 35.65Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 26s      ms/item 35.84Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 02s      ms/item 35.80Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 39s      ms/item 35.96Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 16s      ms/item 35.85Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 53s      ms/item 36.11Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 30s      ms/item 35.85Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 06s      ms/item 35.63Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 43s      ms/item 36.17Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 20s      ms/item 35.74Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 52s      ms/item 38.27                                                                                                    
network-snapshot-001056        time 29m 59s      fid50k   130.4968
tick 1     kimg 1064.0    loss/reg: G ( 3.832 -1.000) D ( 0.067  0.054)  time 1h 01m 45s   sec/kimg 235.07  mem: GPU 3.06   CPU 7.62   exp
tick 2     kimg 1072.0    loss/reg: G ( 4.283 -1.000) D ( 0.108  0.070)  time 1h 33m 09s   sec/kimg 235.42  mem: GPU 3.06   CPU 6.30   exp
tick 3     kimg 1080.0    loss/reg: G ( 4.403 -1.000) D ( 0.093  0.070)  time 2h 04m 31s   sec/kimg 235.21  mem: GPU 3.06   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.29Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.39Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.56Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.48Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.21Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.25Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.35Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 50s       ms/item 35.20Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 26s       ms/item 35.18Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 02s       ms/item 35.17Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 38s       ms/item 35.21Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 14s       ms/item 35.22Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 50s       ms/item 35.23Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 26s       ms/item 35.41Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 02s       ms/item 35.26Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 38s       ms/item 35.40Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 14s      ms/item 35.25Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 51s      ms/item 35.33Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 27s      ms/item 35.21Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 03s      ms/item 35.36Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 39s      ms/item 35.37Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 15s      ms/item 35.25Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 51s      ms/item 35.22Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 27s      ms/item 35.33Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 04s      ms/item 35.28Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 40s      ms/item 35.16Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 16s      ms/item 35.36Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 52s      ms/item 35.37Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 28s      ms/item 35.28Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 04s      ms/item 35.10Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 40s      ms/item 35.21Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 16s      ms/item 35.44Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 52s      ms/item 35.18Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 29s      ms/item 35.41Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 05s      ms/item 35.37Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 41s      ms/item 35.29Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 17s      ms/item 35.17Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 53s      ms/item 35.20Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 29s      ms/item 35.27Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 05s      ms/item 35.37Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 41s      ms/item 35.18Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 18s      ms/item 35.40Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 54s      ms/item 35.17Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 30s      ms/item 35.26Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 06s      ms/item 35.35Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 42s      ms/item 35.24Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 18s      ms/item 35.17Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 54s      ms/item 35.35Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 26s      ms/item 37.23                                                                                                    
network-snapshot-001080        time 29m 33s      fid50k   129.1227
tick 4     kimg 1088.0    loss/reg: G ( 4.272 -1.000) D ( 0.120  0.071)  time 3h 05m 26s   sec/kimg 235.27  mem: GPU 3.03   CPU 6.30   exp
tick 5     kimg 1096.0    loss/reg: G ( 4.184 -1.000) D ( 0.145  0.065)  time 3h 36m 48s   sec/kimg 235.21  mem: GPU 3.03   CPU 6.30   exp
tick 6     kimg 1104.0    loss/reg: G ( 4.355 -1.000) D ( 0.097  0.070)  time 4h 08m 07s   sec/kimg 234.87  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.15Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.22Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.16Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.10Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.21Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.22Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.04Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.23Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.06Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.16Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.37Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 36.39Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 35.83Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 39s       ms/item 36.41Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 16s       ms/item 36.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 53s       ms/item 36.15Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 30s      ms/item 36.17Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 07s      ms/item 36.07Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 44s      ms/item 36.28Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 21s      ms/item 36.14Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 58s      ms/item 36.00Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 35s      ms/item 36.05Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 12s      ms/item 36.47Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 49s      ms/item 36.17Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 26s      ms/item 36.29Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 03s      ms/item 36.14Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 41s      ms/item 36.42Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 18s      ms/item 36.16Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 55s      ms/item 36.06Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 32s      ms/item 36.24Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 09s      ms/item 36.41Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 46s      ms/item 36.11Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 23s      ms/item 36.06Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 00s      ms/item 36.17Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 37s      ms/item 36.25Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 14s      ms/item 36.36Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 51s      ms/item 36.22Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 28s      ms/item 36.17Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 05s      ms/item 36.21Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 42s      ms/item 36.19Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 19s      ms/item 36.17Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 57s      ms/item 36.25Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 34s      ms/item 36.05Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 11s      ms/item 36.16Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 48s      ms/item 36.19Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 25s      ms/item 36.42Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 02s      ms/item 35.99Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 39s      ms/item 35.93Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 11s      ms/item 38.26                                                                                                    
network-snapshot-001104        time 30m 17s      fid50k   129.0984
tick 7     kimg 1112.0    loss/reg: G ( 4.365 -1.000) D ( 0.103  0.069)  time 5h 09m 49s   sec/kimg 235.40  mem: GPU 3.04   CPU 6.30   exp
tick 8     kimg 1120.0    loss/reg: G ( 4.413 -1.000) D ( 0.103  0.069)  time 5h 41m 13s   sec/kimg 235.49  mem: GPU 3.04   CPU 6.30   exp
tick 9     kimg 1128.0    loss/reg: G ( 4.395 -1.000) D ( 0.096  0.069)  time 6h 12m 33s   sec/kimg 235.04  mem: GPU 3.04   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.35Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.18Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.21Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 35.56Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.19Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.22Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.20Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.23Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.23Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.38Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.10Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.46Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 50s       ms/item 35.25Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 26s       ms/item 35.34Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 02s       ms/item 35.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 38s       ms/item 35.16Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 14s      ms/item 35.20Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 50s      ms/item 35.64Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 26s      ms/item 35.18Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 02s      ms/item 35.26Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 39s      ms/item 35.25Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 15s      ms/item 35.25Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 51s      ms/item 35.25Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 27s      ms/item 35.19Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 03s      ms/item 35.21Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 39s      ms/item 35.39Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 15s      ms/item 35.43Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 51s      ms/item 35.13Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 27s      ms/item 35.26Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 04s      ms/item 35.36Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 40s      ms/item 35.24Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 16s      ms/item 35.19Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 52s      ms/item 35.36Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 28s      ms/item 35.26Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 04s      ms/item 35.27Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 40s      ms/item 35.33Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 16s      ms/item 35.24Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 53s      ms/item 35.34Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 29s      ms/item 35.46Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 05s      ms/item 35.16Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 41s      ms/item 35.17Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 17s      ms/item 35.19Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 53s      ms/item 35.33Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 29s      ms/item 35.31Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 05s      ms/item 35.23Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 42s      ms/item 35.23Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 18s      ms/item 35.14Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 54s      ms/item 35.25Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 25s      ms/item 37.43                                                                                                    
network-snapshot-001128        time 29m 32s      fid50k   128.0129
tick 10    kimg 1136.0    loss/reg: G ( 4.270 -1.000) D ( 0.116  0.067)  time 7h 13m 27s   sec/kimg 235.11  mem: GPU 3.03   CPU 6.30   exp
tick 11    kimg 1144.0    loss/reg: G ( 4.413 -1.000) D ( 0.091  0.070)  time 7h 44m 46s   sec/kimg 234.94  mem: GPU 3.03   CPU 6.30   exp
tick 12    kimg 1152.0    loss/reg: G ( 4.317 -1.000) D ( 0.111  0.063)  time 8h 16m 07s   sec/kimg 235.10  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.20Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.64Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 36.01Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 36.04Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.96Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.28Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 36.10Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 35.84Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 36.28Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 35.80Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.10Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.25Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 36.02Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 35.98Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 13s       ms/item 35.92Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 50s       ms/item 35.87Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 36.10Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 04s      ms/item 35.87Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 41s      ms/item 35.83Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 17s      ms/item 36.13Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 54s      ms/item 36.07Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 31s      ms/item 36.15Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 08s      ms/item 36.03Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 45s      ms/item 35.81Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 22s      ms/item 35.82Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 58s      ms/item 35.79Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 35s      ms/item 35.95Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 12s      ms/item 36.22Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 49s      ms/item 36.03Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 26s      ms/item 36.41Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 03s      ms/item 36.02Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 40s      ms/item 35.92Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 17s      ms/item 35.81Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 54s      ms/item 36.02Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 30s      ms/item 35.96Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 08s      ms/item 36.21Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 44s      ms/item 35.97Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 21s      ms/item 35.96Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 58s      ms/item 36.07Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 35s      ms/item 36.03Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 12s      ms/item 36.03Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 49s      ms/item 36.13Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 26s      ms/item 36.29Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 03s      ms/item 35.69Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 40s      ms/item 36.43Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 16s      ms/item 35.64Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 53s      ms/item 36.15Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 30s      ms/item 35.89Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 03s      ms/item 38.32                                                                                                    
network-snapshot-001152        time 30m 09s      fid50k   128.1077
tick 13    kimg 1160.0    loss/reg: G ( 4.376 -1.000) D ( 0.097  0.070)  time 9h 17m 36s   sec/kimg 234.84  mem: GPU 3.03   CPU 6.30   exp
tick 14    kimg 1168.0    loss/reg: G ( 4.422 -1.000) D ( 0.106  0.068)  time 9h 48m 53s   sec/kimg 234.57  mem: GPU 3.03   CPU 6.30   exp
tick 15    kimg 1176.0    loss/reg: G ( 4.198 -1.000) D ( 0.127  0.067)  time 10h 20m 10s  sec/kimg 234.65  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.33Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.39Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.17Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.20Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.41Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.17Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.40Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.18Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.19Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.19Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.26Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.21Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.20Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 26s       ms/item 35.39Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 02s       ms/item 35.22Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 38s       ms/item 35.20Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 14s      ms/item 35.19Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 50s      ms/item 35.38Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 26s      ms/item 35.20Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 02s      ms/item 35.25Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 38s      ms/item 35.17Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 14s      ms/item 35.36Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 51s      ms/item 35.43Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 27s      ms/item 35.16Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 03s      ms/item 35.20Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 39s      ms/item 35.26Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 15s      ms/item 35.19Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 51s      ms/item 35.20Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 27s      ms/item 35.19Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 03s      ms/item 35.36Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 39s      ms/item 35.47Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 15s      ms/item 35.18Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 51s      ms/item 35.19Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 28s      ms/item 35.37Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 04s      ms/item 35.26Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 40s      ms/item 35.15Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 16s      ms/item 35.45Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 52s      ms/item 35.15Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 28s      ms/item 35.26Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 04s      ms/item 35.44Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 40s      ms/item 35.15Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 17s      ms/item 35.39Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 53s      ms/item 35.15Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 29s      ms/item 35.23Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 05s      ms/item 35.22Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 41s      ms/item 35.19Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 17s      ms/item 35.18Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 53s      ms/item 35.44Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 25s      ms/item 37.15                                                                                                    
network-snapshot-001176        time 29m 31s      fid50k   127.8932
tick 16    kimg 1184.0    loss/reg: G ( 4.418 -1.000) D ( 0.106  0.063)  time 11h 21m 05s  sec/kimg 235.26  mem: GPU 3.03   CPU 6.30   exp
tick 17    kimg 1192.0    loss/reg: G ( 4.385 -1.000) D ( 0.094  0.068)  time 11h 52m 27s  sec/kimg 235.28  mem: GPU 3.03   CPU 6.30   exp
tick 18    kimg 1200.0    loss/reg: G ( 4.278 -1.000) D ( 0.117  0.068)  time 12h 23m 49s  sec/kimg 235.22  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.19Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.93Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.06Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.18Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.05Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 35.98Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.15Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.21Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.24Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.39Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.09Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 36.05Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.07Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 38s       ms/item 36.03Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 15s       ms/item 36.30Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 52s       ms/item 35.75Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 29s      ms/item 36.11Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 06s      ms/item 36.27Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 43s      ms/item 36.28Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 20s      ms/item 36.19Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 57s      ms/item 36.25Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 34s      ms/item 35.98Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 11s      ms/item 36.22Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 48s      ms/item 36.14Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 25s      ms/item 36.12Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 02s      ms/item 36.26Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 39s      ms/item 35.94Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 16s      ms/item 36.30Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 53s      ms/item 36.12Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 30s      ms/item 36.05Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 07s      ms/item 36.12Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 44s      ms/item 36.50Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 21s      ms/item 36.18Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 58s      ms/item 36.23Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 35s      ms/item 36.18Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 13s      ms/item 36.44Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 50s      ms/item 36.06Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 27s      ms/item 36.23Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 04s      ms/item 36.07Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 41s      ms/item 36.27Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 18s      ms/item 36.23Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 55s      ms/item 36.30Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 32s      ms/item 36.26Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 09s      ms/item 36.21Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 46s      ms/item 36.05Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 23s      ms/item 36.16Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 01s      ms/item 36.43Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 38s      ms/item 36.23Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 10s      ms/item 38.27                                                                                                    
network-snapshot-001200        time 30m 17s      fid50k   126.5248
tick 19    kimg 1208.0    loss/reg: G ( 4.380 -1.000) D ( 0.093  0.067)  time 13h 25m 25s  sec/kimg 234.82  mem: GPU 3.03   CPU 6.30   exp
tick 20    kimg 1216.0    loss/reg: G ( 4.491 -1.000) D ( 0.091  0.063)  time 13h 56m 47s  sec/kimg 235.26  mem: GPU 3.03   CPU 6.30   exp
tick 21    kimg 1224.0    loss/reg: G ( 4.352 -1.000) D ( 0.095  0.071)  time 14h 28m 08s  sec/kimg 235.11  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.54Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 36.01Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 35.65Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.92Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 03s       ms/item 35.80Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 40s       ms/item 35.88Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 16s       ms/item 35.57Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 53s       ms/item 36.04Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 30s       ms/item 35.94Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 07s       ms/item 35.64Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 43s       ms/item 35.90Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 20s       ms/item 35.78Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 57s       ms/item 36.07Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 34s       ms/item 35.85Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 10s       ms/item 35.79Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 47s       ms/item 35.76Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 24s      ms/item 36.05Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 01s      ms/item 35.99Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 37s      ms/item 35.82Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 14s      ms/item 35.81Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 51s      ms/item 35.97Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 28s      ms/item 35.84Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 04s      ms/item 35.92Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 41s      ms/item 35.84Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 18s      ms/item 35.96Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 55s      ms/item 36.20Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 31s      ms/item 35.60Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 08s      ms/item 35.87Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 45s      ms/item 36.10Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 22s      ms/item 35.69Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 58s      ms/item 35.92Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 36s      ms/item 36.22Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 12s      ms/item 36.03Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 49s      ms/item 35.62Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 26s      ms/item 35.80Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 03s      ms/item 36.13Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 39s      ms/item 35.88Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 16s      ms/item 35.93Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 53s      ms/item 35.80Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 30s      ms/item 36.01Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 06s      ms/item 35.78Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 43s      ms/item 36.01Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 20s      ms/item 35.89Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 56s      ms/item 35.59Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 33s      ms/item 35.96Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 10s      ms/item 36.17Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 47s      ms/item 35.66Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 24s      ms/item 35.99Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 56s      ms/item 37.96                                                                                                    
network-snapshot-001224        time 30m 02s      fid50k   125.7511
tick 22    kimg 1232.0    loss/reg: G ( 4.419 -1.000) D ( 0.093  0.066)  time 15h 29m 30s  sec/kimg 234.83  mem: GPU 3.03   CPU 6.30   exp
tick 23    kimg 1240.0    loss/reg: G ( 4.294 -1.000) D ( 0.108  0.067)  time 16h 00m 50s  sec/kimg 235.03  mem: GPU 3.03   CPU 6.30   exp
tick 24    kimg 1248.0    loss/reg: G ( 4.452 -1.000) D ( 0.097  0.068)  time 16h 32m 12s  sec/kimg 235.16  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.25Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.93Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.01Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.82Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 36.03Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.12Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 36.00Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 35.79Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 36.03Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 36.19Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.01Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.35Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 35.81Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.20Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.04Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.17Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 36.33Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 04s      ms/item 35.69Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 42s      ms/item 36.42Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 36.16Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 56s      ms/item 36.05Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 32s      ms/item 36.07Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 09s      ms/item 36.03Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 47s      ms/item 36.25Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 24s      ms/item 36.17Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 00s      ms/item 35.85Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 37s      ms/item 36.14Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 14s      ms/item 36.25Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 51s      ms/item 36.20Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 28s      ms/item 36.04Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 05s      ms/item 36.04Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 42s      ms/item 35.97Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 19s      ms/item 36.18Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 56s      ms/item 36.02Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 33s      ms/item 36.21Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 10s      ms/item 35.99Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 47s      ms/item 36.01Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 24s      ms/item 36.08Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 01s      ms/item 36.27Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 38s      ms/item 35.89Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 15s      ms/item 36.27Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 52s      ms/item 35.98Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 28s      ms/item 35.80Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 05s      ms/item 36.28Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 43s      ms/item 36.21Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 20s      ms/item 36.18Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 57s      ms/item 36.25Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 34s      ms/item 36.19Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 06s      ms/item 38.08                                                                                                    
network-snapshot-001248        time 30m 13s      fid50k   126.3225
tick 25    kimg 1256.0    loss/reg: G ( 4.336 -1.000) D ( 0.097  0.066)  time 17h 33m 44s  sec/kimg 234.79  mem: GPU 3.03   CPU 6.30   exp
tick 26    kimg 1264.0    loss/reg: G ( 4.406 -1.000) D ( 0.088  0.068)  time 18h 05m 05s  sec/kimg 235.19  mem: GPU 3.03   CPU 6.30   exp
tick 27    kimg 1272.0    loss/reg: G ( 4.347 -1.000) D ( 0.118  0.064)  time 18h 36m 25s  sec/kimg 235.01  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.26Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.16Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.22Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.19Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.25Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.15Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.41Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.24Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.16Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.26Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.14Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.39Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.29Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.38Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.20Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.14Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.29Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.12Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 26s      ms/item 35.24Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 02s      ms/item 35.18Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 38s      ms/item 35.23Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 14s      ms/item 35.16Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 50s      ms/item 35.20Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 26s      ms/item 35.24Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 02s      ms/item 35.23Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.15Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.25Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.13Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.24Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.18Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.23Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.15Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.23Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.22Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.14Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.22Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.23Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.17Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.22Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 03s      ms/item 35.25Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 39s      ms/item 35.35Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 15s      ms/item 35.19Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 51s      ms/item 35.24Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 27s      ms/item 35.17Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 03s      ms/item 35.16Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 39s      ms/item 35.25Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.28Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.33Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 23s      ms/item 37.16                                                                                                    
network-snapshot-001272        time 29m 29s      fid50k   123.7673
tick 28    kimg 1280.0    loss/reg: G ( 4.427 -1.000) D ( 0.100  0.062)  time 19h 37m 15s  sec/kimg 234.93  mem: GPU 3.03   CPU 6.30   exp
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-001272.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 152, in vis
    return_att = True, return_ws = True)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 21, in run
    outs = [G(z, c, truncation_psi = truncation_psi, **kwargs) for z, c in zip(zs.split(batch_size), cs.split(batch_size))]
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 21, in <listcomp>
    outs = [G(z, c, truncation_psi = truncation_psi, **kwargs) for z, c in zip(zs.split(batch_size), cs.split(batch_size))]
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1319, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1259, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1156, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1029, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 809, in forward
  File "<string>", line 660, in integrate
RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 10.91 GiB total capacity; 2.61 GiB already allocated; 67.44 MiB free; 2.77 GiB reserved in total by PyTorch)
tick 29    kimg 1288.0    loss/reg: G ( 4.395 -1.000) D ( 0.103  0.063)  time 20h 08m 41s  sec/kimg 235.78  mem: GPU 3.03   CPU 6.30   exp
tick 30    kimg 1296.0    loss/reg: G ( 4.469 -1.000) D ( 0.094  0.067)  time 20h 40m 03s  sec/kimg 235.18  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.89Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.09Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.00Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.33Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.83Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.13Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.17Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.22Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.18Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 35.92Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.26Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 25s       ms/item 38.01Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 02s       ms/item 36.02Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 39s       ms/item 35.89Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 16s       ms/item 35.96Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 54s       ms/item 36.74Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 30s      ms/item 35.73Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 07s      ms/item 35.90Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 44s      ms/item 35.86Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 20s      ms/item 36.00Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 57s      ms/item 35.92Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 34s      ms/item 36.23Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 11s      ms/item 35.80Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 48s      ms/item 36.21Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 25s      ms/item 36.11Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 02s      ms/item 35.82Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 39s      ms/item 36.40Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 16s      ms/item 36.18Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 53s      ms/item 35.69Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 30s      ms/item 36.01Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 07s      ms/item 36.15Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 44s      ms/item 36.16Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 20s      ms/item 35.69Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 57s      ms/item 36.38Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 34s      ms/item 35.90Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 11s      ms/item 35.87Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 48s      ms/item 36.05Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 25s      ms/item 36.11Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 01s      ms/item 35.88Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 38s      ms/item 36.02Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 15s      ms/item 36.11Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 52s      ms/item 36.11Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 29s      ms/item 35.74Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 06s      ms/item 36.44Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 43s      ms/item 36.32Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 20s      ms/item 35.83Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 57s      ms/item 35.84Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 34s      ms/item 35.99Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 06s      ms/item 37.85                                                                                                    
network-snapshot-001296        time 30m 12s      fid50k   124.8192
tick 31    kimg 1304.0    loss/reg: G ( 4.364 -1.000) D ( 0.121  0.063)  time 21h 41m 44s  sec/kimg 235.97  mem: GPU 3.03   CPU 6.30   exp
tick 32    kimg 1312.0    loss/reg: G ( 4.477 -1.000) D ( 0.080  0.065)  time 22h 13m 03s  sec/kimg 234.78  mem: GPU 3.03   CPU 6.30   exp
tick 33    kimg 1320.0    loss/reg: G ( 4.469 -1.000) D ( 0.107  0.059)  time 22h 44m 20s  sec/kimg 234.64  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.25Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.21Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.31Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.18Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.11Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.20Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 12s       ms/item 35.19Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 48s       ms/item 35.21Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.25Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.19Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.19Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.18Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.23Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.18Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.25Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.16Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.22Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.16Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.44Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.16Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.22Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.20Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 25s      ms/item 35.18Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 01s      ms/item 35.22Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 37s      ms/item 35.25Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.43Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.13Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.21Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.24Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.24Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.21Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.12Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.21Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.23Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.15Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.23Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.18Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.19Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.20Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.21Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 14s      ms/item 35.23Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 50s      ms/item 35.21Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 27s      ms/item 35.19Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 03s      ms/item 35.20Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 39s      ms/item 35.16Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.20Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.32Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 22s      ms/item 37.14                                                                                                    
network-snapshot-001320        time 29m 29s      fid50k   125.4997
tick 34    kimg 1328.0    loss/reg: G ( 4.522 -1.000) D ( 0.085  0.066)  time 23h 45m 08s  sec/kimg 234.72  mem: GPU 3.03   CPU 6.30   exp
tick 35    kimg 1336.0    loss/reg: G ( 4.551 -1.000) D ( 0.075  0.066)  time 86400d 00h 16m sec/kimg 234.45  mem: GPU 3.03   CPU 6.30   exp
tick 36    kimg 1344.0    loss/reg: G ( 4.402 -1.000) D ( 0.100  0.063)  time 86400d 00h 47m sec/kimg 234.67  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.30Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.86Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.00Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.69Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.71Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.25Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 35.95Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 35.98Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 31s       ms/item 35.84Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 08s       ms/item 35.99Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 45s       ms/item 36.02Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 22s       ms/item 35.96Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 59s       ms/item 35.81Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 36s       ms/item 36.16Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 13s       ms/item 36.26Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 49s       ms/item 35.84Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 26s      ms/item 36.22Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 03s      ms/item 35.99Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 40s      ms/item 36.15Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 17s      ms/item 36.15Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 54s      ms/item 35.91Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 31s      ms/item 36.16Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 08s      ms/item 35.96Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 45s      ms/item 36.16Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 22s      ms/item 36.46Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 59s      ms/item 35.79Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 36s      ms/item 36.18Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 13s      ms/item 36.03Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 50s      ms/item 36.18Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 27s      ms/item 36.31Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 04s      ms/item 35.90Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 41s      ms/item 36.38Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 18s      ms/item 36.05Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 55s      ms/item 35.92Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 32s      ms/item 36.27Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 09s      ms/item 35.99Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 46s      ms/item 36.16Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 23s      ms/item 36.01Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 00s      ms/item 36.24Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 37s      ms/item 35.96Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 14s      ms/item 36.04Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 50s      ms/item 35.93Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 27s      ms/item 36.06Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 04s      ms/item 35.80Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 41s      ms/item 35.84Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 18s      ms/item 35.97Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 55s      ms/item 36.20Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 32s      ms/item 36.28Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 04s      ms/item 37.97                                                                                                    
network-snapshot-001344        time 30m 11s      fid50k   123.0939
tick 37    kimg 1352.0    loss/reg: G ( 4.458 -1.000) D ( 0.108  0.063)  time 86400d 01h 49m sec/kimg 235.02  mem: GPU 3.03   CPU 6.30   exp
tick 38    kimg 1360.0    loss/reg: G ( 4.401 -1.000) D ( 0.108  0.061)  time 86400d 02h 20m sec/kimg 236.57  mem: GPU 3.03   CPU 6.30   exp
tick 39    kimg 1368.0    loss/reg: G ( 4.495 -1.000) D ( 0.094  0.064)  time 86400d 02h 52m sec/kimg 235.11  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.35Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.19Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.25Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.13Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.21Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.24Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.36Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.25Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.19Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.25Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.34Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 15s       ms/item 36.77Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 51s       ms/item 35.30Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 27s       ms/item 35.32Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 03s       ms/item 35.16Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 39s       ms/item 35.48Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 16s      ms/item 35.34Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 52s      ms/item 35.24Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 28s      ms/item 35.21Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 04s      ms/item 35.13Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 40s      ms/item 35.49Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 16s      ms/item 35.20Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 54s      ms/item 36.92Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 30s      ms/item 35.32Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 08s      ms/item 36.87Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 44s      ms/item 35.23Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 20s      ms/item 35.22Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 56s      ms/item 35.17Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 32s      ms/item 35.23Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 08s      ms/item 35.42Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 44s      ms/item 35.16Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 20s      ms/item 35.22Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 56s      ms/item 35.16Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 32s      ms/item 35.21Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 09s      ms/item 35.26Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 45s      ms/item 35.19Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 21s      ms/item 35.35Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 57s      ms/item 35.21Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 33s      ms/item 35.21Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 09s      ms/item 35.22Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 45s      ms/item 35.17Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 21s      ms/item 35.21Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 57s      ms/item 35.18Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 33s      ms/item 35.40Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 09s      ms/item 35.21Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 45s      ms/item 35.22Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 21s      ms/item 35.21Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 57s      ms/item 35.22Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 29s      ms/item 37.14                                                                                                    
network-snapshot-001368        time 29m 35s      fid50k   124.9319
tick 40    kimg 1376.0    loss/reg: G ( 4.503 -1.000) D ( 0.090  0.062)  time 86400d 03h 53m sec/kimg 234.69  mem: GPU 3.03   CPU 6.30   exp
tick 41    kimg 1384.0    loss/reg: G ( 4.433 -1.000) D ( 0.101  0.062)  time 86400d 04h 24m sec/kimg 234.23  mem: GPU 3.03   CPU 6.30   exp
tick 42    kimg 1392.0    loss/reg: G ( 4.420 -1.000) D ( 0.091  0.066)  time 86400d 04h 55m sec/kimg 234.50  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.65Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.78Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 35.59Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 26s       ms/item 35.63Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 03s       ms/item 35.82Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 39s       ms/item 35.84Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 16s       ms/item 35.97Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 53s       ms/item 35.80Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 30s       ms/item 35.80Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 06s       ms/item 35.60Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 43s       ms/item 35.85Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 19s       ms/item 35.78Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 56s       ms/item 36.11Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 33s       ms/item 35.85Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 10s       ms/item 35.94Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 47s       ms/item 35.85Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 23s      ms/item 35.79Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 00s      ms/item 35.84Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 37s      ms/item 36.03Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 14s      ms/item 36.13Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 51s      ms/item 35.83Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 27s      ms/item 35.80Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 04s      ms/item 35.85Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 40s      ms/item 35.73Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 17s      ms/item 36.12Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 54s      ms/item 35.68Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 31s      ms/item 35.79Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 08s      ms/item 36.03Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 44s      ms/item 35.77Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 21s      ms/item 35.88Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 58s      ms/item 36.00Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 34s      ms/item 35.75Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 11s      ms/item 36.07Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 48s      ms/item 35.73Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 25s      ms/item 35.86Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 01s      ms/item 35.68Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 38s      ms/item 35.90Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 15s      ms/item 36.17Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 52s      ms/item 35.79Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 28s      ms/item 35.82Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 05s      ms/item 36.04Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 42s      ms/item 35.71Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 19s      ms/item 35.88Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 55s      ms/item 35.80Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 32s      ms/item 36.01Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 09s      ms/item 35.75Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 45s      ms/item 35.65Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 22s      ms/item 35.82Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 54s      ms/item 37.88                                                                                                    
network-snapshot-001392        time 30m 00s      fid50k   124.5310
tick 43    kimg 1400.0    loss/reg: G ( 4.376 -1.000) D ( 0.125  0.059)  time 86400d 05h 56m sec/kimg 234.48  mem: GPU 3.03   CPU 6.30   exp
tick 44    kimg 1408.0    loss/reg: G ( 4.494 -1.000) D ( 0.081  0.063)  time 86400d 06h 28m sec/kimg 234.78  mem: GPU 3.03   CPU 6.30   exp
tick 45    kimg 1416.0    loss/reg: G ( 4.323 -1.000) D ( 0.114  0.065)  time 86400d 06h 59m sec/kimg 234.76  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.86Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.37Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 35.29Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.85Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 03s       ms/item 35.46Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 40s       ms/item 36.19Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 16s       ms/item 35.45Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 53s       ms/item 35.76Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 30s       ms/item 35.62Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 06s       ms/item 35.79Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 43s       ms/item 35.65Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 19s       ms/item 35.59Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 56s       ms/item 35.69Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 33s       ms/item 36.10Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 09s       ms/item 35.61Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 46s       ms/item 35.92Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 22s      ms/item 35.68Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 59s      ms/item 35.56Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 35s      ms/item 35.62Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 12s      ms/item 35.74Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 49s      ms/item 35.84Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 26s      ms/item 35.98Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 02s      ms/item 35.58Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 38s      ms/item 35.55Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 15s      ms/item 35.90Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 52s      ms/item 35.57Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 28s      ms/item 35.57Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 05s      ms/item 36.06Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 41s      ms/item 35.54Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 18s      ms/item 35.63Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 54s      ms/item 35.61Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 31s      ms/item 35.66Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 07s      ms/item 35.80Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 44s      ms/item 35.61Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 20s      ms/item 35.73Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 57s      ms/item 35.63Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 33s      ms/item 35.63Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 10s      ms/item 35.79Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 47s      ms/item 35.58Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 23s      ms/item 35.79Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 00s      ms/item 35.58Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 36s      ms/item 35.68Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 13s      ms/item 35.75Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 49s      ms/item 35.57Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 26s      ms/item 35.64Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 02s      ms/item 35.83Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 39s      ms/item 35.66Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 16s      ms/item 35.91Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 48s      ms/item 37.90                                                                                                    
network-snapshot-001416        time 29m 54s      fid50k   124.4320
tick 46    kimg 1424.0    loss/reg: G ( 4.500 -1.000) D ( 0.108  0.060)  time 86400d 08h 00m sec/kimg 234.81  mem: GPU 3.03   CPU 6.30   exp
tick 47    kimg 1432.0    loss/reg: G ( 4.423 -1.000) D ( 0.100  0.063)  time 86400d 08h 31m sec/kimg 234.97  mem: GPU 3.03   CPU 6.30   exp
tick 48    kimg 1440.0    loss/reg: G ( 4.402 -1.000) D ( 0.102  0.062)  time 86400d 09h 03m sec/kimg 237.57  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.94Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.18Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.82Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.40Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 35.93Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.04Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 35.86Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 36.17Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 36.35Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 36.04Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.14Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.10Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 36.13Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.04Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.06Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.31Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 36.05Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 05s      ms/item 36.24Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 43s      ms/item 36.31Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 36.04Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 56s      ms/item 36.13Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 34s      ms/item 36.29Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 11s      ms/item 36.12Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 48s      ms/item 36.67Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 25s      ms/item 35.96Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 02s      ms/item 36.05Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 39s      ms/item 36.12Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 16s      ms/item 36.02Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 53s      ms/item 36.26Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 30s      ms/item 36.29Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 07s      ms/item 36.11Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 44s      ms/item 36.14Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 21s      ms/item 36.24Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 58s      ms/item 36.04Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 35s      ms/item 36.38Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 13s      ms/item 36.33Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 49s      ms/item 35.70Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 26s      ms/item 36.11Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 03s      ms/item 35.87Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 40s      ms/item 36.35Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 17s      ms/item 36.23Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 54s      ms/item 36.19Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 31s      ms/item 36.20Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 08s      ms/item 36.19Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 45s      ms/item 36.24Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 22s      ms/item 36.08Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 59s      ms/item 36.00Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 36s      ms/item 36.34Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 09s      ms/item 37.85                                                                                                    
network-snapshot-001440        time 30m 15s      fid50k   122.4650
tick 49    kimg 1448.0    loss/reg: G ( 4.545 -1.000) D ( 0.087  0.063)  time 86400d 10h 05m sec/kimg 234.59  mem: GPU 3.03   CPU 6.30   exp
tick 50    kimg 1456.0    loss/reg: G ( 4.514 -1.000) D ( 0.073  0.065)  time 86400d 10h 36m sec/kimg 234.99  mem: GPU 3.03   CPU 6.30   exp
tick 51    kimg 1464.0    loss/reg: G ( 4.308 -1.000) D ( 0.120  0.062)  time 86400d 11h 07m sec/kimg 234.50  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.21Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.15Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.25Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.19Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.15Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.19Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.52Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.34Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.28Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.09Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.29Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.11Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.25Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.18Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.23Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.23Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.14Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.23Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.17Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.21Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.16Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.29Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.13Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 26s      ms/item 35.23Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 02s      ms/item 35.19Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.17Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.41Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.22Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.23Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.15Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.26Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.20Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.19Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.16Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.24Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.22Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.20Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.16Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.22Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.14Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.24Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 15s      ms/item 35.21Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 51s      ms/item 35.35Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 27s      ms/item 35.27Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 03s      ms/item 35.15Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 39s      ms/item 35.25Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.23Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.12Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 23s      ms/item 37.34                                                                                                    
network-snapshot-001464        time 29m 29s      fid50k   123.3418
tick 52    kimg 1472.0    loss/reg: G ( 4.571 -1.000) D ( 0.086  0.059)  time 86400d 12h 08m sec/kimg 234.77  mem: GPU 3.03   CPU 6.30   exp
tick 53    kimg 1480.0    loss/reg: G ( 4.408 -1.000) D ( 0.103  0.063)  time 86400d 12h 39m sec/kimg 234.85  mem: GPU 3.03   CPU 6.30   exp
tick 54    kimg 1488.0    loss/reg: G ( 4.518 -1.000) D ( 0.085  0.059)  time 86400d 13h 11m sec/kimg 234.65  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.44Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.16Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.67Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 35.87Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.98Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.75Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 35.66Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.19Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.07Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.30Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 35.99Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 36.09Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.17Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.02Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.00Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 52s       ms/item 36.55Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 35.77Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 05s      ms/item 35.98Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 42s      ms/item 36.07Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 36.17Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 56s      ms/item 36.22Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 33s      ms/item 35.95Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 10s      ms/item 36.20Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 47s      ms/item 35.85Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 24s      ms/item 36.09Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 01s      ms/item 36.08Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 38s      ms/item 36.00Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 15s      ms/item 36.04Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 52s      ms/item 36.27Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 28s      ms/item 35.90Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 05s      ms/item 36.02Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 42s      ms/item 36.10Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 19s      ms/item 36.08Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 56s      ms/item 36.03Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 33s      ms/item 36.21Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 10s      ms/item 36.13Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 47s      ms/item 36.06Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 24s      ms/item 36.00Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 01s      ms/item 36.06Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 38s      ms/item 36.15Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 15s      ms/item 35.98Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 52s      ms/item 35.97Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 28s      ms/item 35.86Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 06s      ms/item 36.41Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 43s      ms/item 36.00Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 19s      ms/item 35.98Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 56s      ms/item 35.93Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 33s      ms/item 35.89Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 05s      ms/item 38.41                                                                                                    
network-snapshot-001488        time 30m 12s      fid50k   122.6380
tick 55    kimg 1496.0    loss/reg: G ( 4.529 -1.000) D ( 0.091  0.063)  time 86400d 14h 12m sec/kimg 234.77  mem: GPU 3.03   CPU 6.30   exp
tick 56    kimg 1504.0    loss/reg: G ( 4.417 -1.000) D ( 0.108  0.061)  time 86400d 14h 44m sec/kimg 234.75  mem: GPU 3.03   CPU 6.30   exp
tick 57    kimg 1512.0    loss/reg: G ( 4.430 -1.000) D ( 0.106  0.059)  time 86400d 15h 15m sec/kimg 234.64  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.24Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.17Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.24Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.15Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.21Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.20Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 12s       ms/item 35.25Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 48s       ms/item 35.22Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 24s       ms/item 35.12Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 00s       ms/item 35.21Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.26Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.33Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.23Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.19Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.25Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.18Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.23Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.12Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.23Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.26Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.17Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.22Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.18Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 25s      ms/item 35.22Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 01s      ms/item 35.16Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 37s      ms/item 35.20Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.26Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 49s      ms/item 35.12Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.25Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.27Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.32Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.21Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.21Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.16Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.20Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.24Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.17Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.24Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.14Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.39Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 39s      ms/item 35.29Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 15s      ms/item 35.15Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 51s      ms/item 35.17Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 27s      ms/item 35.24Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 03s      ms/item 35.18Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 39s      ms/item 35.30Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.26Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.28Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 23s      ms/item 37.15                                                                                                    
network-snapshot-001512        time 29m 29s      fid50k   121.6560
tick 58    kimg 1520.0    loss/reg: G ( 4.483 -1.000) D ( 0.089  0.063)  time 86400d 16h 16m sec/kimg 235.06  mem: GPU 3.03   CPU 6.30   exp
tick 59    kimg 1528.0    loss/reg: G ( 4.530 -1.000) D ( 0.083  0.063)  time 86400d 16h 47m sec/kimg 234.57  mem: GPU 3.03   CPU 6.30   exp
tick 60    kimg 1536.0    loss/reg: G ( 4.493 -1.000) D ( 0.094  0.062)  time 86400d 17h 18m sec/kimg 234.83  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.28Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.78Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.09Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.24Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.10Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.00Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.00Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.24Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 35.80Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 36.17Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.18Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.08Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 35.93Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.07Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 35.98Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.04Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 36.11Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 05s      ms/item 36.02Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 42s      ms/item 36.22Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 35.98Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 56s      ms/item 36.20Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 33s      ms/item 36.05Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 10s      ms/item 36.09Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 46s      ms/item 35.85Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 23s      ms/item 36.16Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 00s      ms/item 36.05Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 37s      ms/item 35.99Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 14s      ms/item 36.19Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 51s      ms/item 35.98Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 28s      ms/item 36.07Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 05s      ms/item 36.17Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 42s      ms/item 36.09Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 19s      ms/item 35.99Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 56s      ms/item 36.14Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 33s      ms/item 36.04Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 10s      ms/item 36.02Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 47s      ms/item 36.19Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 24s      ms/item 36.34Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 00s      ms/item 35.82Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 37s      ms/item 36.04Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 14s      ms/item 35.96Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 51s      ms/item 36.16Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 28s      ms/item 36.01Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 05s      ms/item 36.25Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 42s      ms/item 36.11Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 19s      ms/item 35.63Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 56s      ms/item 36.37Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 33s      ms/item 35.85Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 05s      ms/item 38.21                                                                                                    
network-snapshot-001536        time 30m 12s      fid50k   121.4693
tick 61    kimg 1544.0    loss/reg: G ( 4.439 -1.000) D ( 0.124  0.056)  time 86400d 18h 20m sec/kimg 234.90  mem: GPU 3.03   CPU 6.30   exp
tick 62    kimg 1552.0    loss/reg: G ( 4.398 -1.000) D ( 0.111  0.059)  time 86400d 18h 51m sec/kimg 235.99  mem: GPU 3.03   CPU 6.30   exp
tick 63    kimg 1560.0    loss/reg: G ( 4.559 -1.000) D ( 0.095  0.057)  time 86400d 19h 23m sec/kimg 238.28  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.18Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.25Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.20Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.20Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.43Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.12Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.29Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.18Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.16Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.26Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.18Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.41Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.21Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.21Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 02s       ms/item 35.57Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 38s       ms/item 35.21Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 14s      ms/item 35.37Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 50s      ms/item 35.45Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 26s      ms/item 35.14Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 02s      ms/item 35.24Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 38s      ms/item 35.22Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 14s      ms/item 35.16Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 50s      ms/item 35.33Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 27s      ms/item 35.28Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 03s      ms/item 35.14Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 39s      ms/item 35.25Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 15s      ms/item 35.17Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 51s      ms/item 35.21Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 27s      ms/item 35.23Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 03s      ms/item 35.17Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 39s      ms/item 35.23Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 15s      ms/item 35.27Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 51s      ms/item 35.13Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 27s      ms/item 35.63Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 04s      ms/item 35.78Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 40s      ms/item 35.55Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 17s      ms/item 35.67Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 53s      ms/item 35.63Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 30s      ms/item 35.99Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 07s      ms/item 35.56Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 43s      ms/item 35.63Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 20s      ms/item 35.47Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 56s      ms/item 35.79Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 33s      ms/item 35.64Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 09s      ms/item 35.58Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 46s      ms/item 35.72Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 22s      ms/item 35.60Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 59s      ms/item 35.65Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 31s      ms/item 37.66                                                                                                    
network-snapshot-001560        time 29m 40s      fid50k   121.5809
tick 64    kimg 1568.0    loss/reg: G ( 4.571 -1.000) D ( 0.084  0.060)  time 86400d 20h 24m sec/kimg 235.02  mem: GPU 3.03   CPU 6.30   exp
tick 65    kimg 1576.0    loss/reg: G ( 4.475 -1.000) D ( 0.098  0.065)  time 86400d 20h 55m sec/kimg 234.92  mem: GPU 3.03   CPU 6.30   exp
tick 66    kimg 1584.0    loss/reg: G ( 4.254 -1.000) D ( 0.136  0.056)  time 86400d 21h 27m sec/kimg 240.62  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.20Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.04Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.39Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 35.77Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.38Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 35.86Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.27Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.06Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 36.02Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.23Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.08Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 35.92Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.12Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 38s       ms/item 36.05Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.02Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.00Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 29s      ms/item 36.36Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 05s      ms/item 36.07Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 46s      ms/item 39.52Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 23s      ms/item 35.99Evaluation: computing generator features items 21504/50000 (43.01%) time 13m 00s      ms/item 36.32Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 39s      ms/item 37.75Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 18s      ms/item 38.40Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 55s      ms/item 36.28Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 33s      ms/item 36.56Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 10s      ms/item 36.33Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 47s      ms/item 36.04Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 24s      ms/item 36.22Evaluation: computing generator features items 29696/50000 (59.39%) time 18m 01s      ms/item 36.35Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 38s      ms/item 36.03Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 15s      ms/item 36.22Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 52s      ms/item 36.02Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 29s      ms/item 36.17Evaluation: computing generator features items 34816/50000 (69.63%) time 21m 06s      ms/item 36.46Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 43s      ms/item 35.98Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 20s      ms/item 36.25Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 57s      ms/item 36.29Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 34s      ms/item 36.00Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 11s      ms/item 36.09Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 48s      ms/item 36.13Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 25s      ms/item 36.04Evaluation: computing generator features items 43008/50000 (86.02%) time 26m 02s      ms/item 36.35Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 39s      ms/item 36.37Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 16s      ms/item 36.11Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 53s      ms/item 35.97Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 30s      ms/item 36.15Evaluation: computing generator features items 48128/50000 (96.26%) time 29m 07s      ms/item 35.98Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 44s      ms/item 36.08Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 16s      ms/item 38.08                                                                                                    
network-snapshot-001584        time 30m 23s      fid50k   120.6013
tick 67    kimg 1592.0    loss/reg: G ( 4.591 -1.000) D ( 0.083  0.061)  time 86400d 22h 29m sec/kimg 235.12  mem: GPU 3.03   CPU 6.30   exp
tick 68    kimg 1600.0    loss/reg: G ( 4.406 -1.000) D ( 0.114  0.060)  time 86400d 23h 01m sec/kimg 235.62  mem: GPU 3.03   CPU 6.30   exp
tick 69    kimg 1608.0    loss/reg: G ( 4.629 -1.000) D ( 0.072  0.058)  time 86400d 23h 32m sec/kimg 235.58  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.81Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.11Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 35.42Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 36.02Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 03s       ms/item 35.74Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 40s       ms/item 35.65Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 17s       ms/item 35.92Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 54s       ms/item 36.20Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 30s       ms/item 35.80Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 07s       ms/item 35.82Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 44s       ms/item 35.83Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 21s       ms/item 35.96Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 57s       ms/item 35.81Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 34s       ms/item 35.67Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 11s       ms/item 36.13Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 48s       ms/item 35.86Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 24s      ms/item 36.04Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 01s      ms/item 35.72Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 38s      ms/item 35.81Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 15s      ms/item 36.17Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 52s      ms/item 35.99Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 29s      ms/item 36.18Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 05s      ms/item 35.82Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 42s      ms/item 36.01Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 19s      ms/item 35.89Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 56s      ms/item 35.83Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 32s      ms/item 35.75Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 09s      ms/item 36.13Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 46s      ms/item 35.83Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 23s      ms/item 35.84Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 59s      ms/item 35.95Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 36s      ms/item 36.22Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 13s      ms/item 35.63Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 50s      ms/item 36.01Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 27s      ms/item 36.62Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 04s      ms/item 35.64Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 41s      ms/item 36.07Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 18s      ms/item 35.87Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 55s      ms/item 36.40Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 32s      ms/item 36.23Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 09s      ms/item 36.52Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 46s      ms/item 36.25Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 24s      ms/item 36.28Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 00s      ms/item 35.90Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 37s      ms/item 36.18Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 14s      ms/item 35.80Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 51s      ms/item 35.85Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 27s      ms/item 35.77Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 00s      ms/item 38.19                                                                                                    
network-snapshot-001608        time 30m 09s      fid50k   120.5540
tick 70    kimg 1616.0    loss/reg: G ( 4.564 -1.000) D ( 0.090  0.059)  time 86400d 00h 34m sec/kimg 235.92  mem: GPU 3.03   CPU 6.30   exp
tick 71    kimg 1624.0    loss/reg: G ( 4.422 -1.000) D ( 0.108  0.059)  time 86400d 01h 05m sec/kimg 235.02  mem: GPU 3.03   CPU 6.30   exp
tick 72    kimg 1632.0    loss/reg: G ( 4.517 -1.000) D ( 0.094  0.058)  time 86400d 01h 36m sec/kimg 234.92  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.96Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.42Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.93Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.00Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.86Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.15Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 35.92Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 35.73Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 36.21Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 36.13Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.06Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 35.92Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 36.07Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.21Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.18Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.00Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 36.03Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 04s      ms/item 36.02Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 41s      ms/item 36.21Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 18s      ms/item 36.12Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 55s      ms/item 35.86Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 32s      ms/item 36.18Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 09s      ms/item 36.14Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 46s      ms/item 36.22Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 23s      ms/item 35.72Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 00s      ms/item 36.07Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 37s      ms/item 36.16Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 14s      ms/item 36.12Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 51s      ms/item 35.93Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 28s      ms/item 36.23Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 05s      ms/item 36.20Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 42s      ms/item 36.35Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 19s      ms/item 35.82Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 56s      ms/item 36.11Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 33s      ms/item 36.00Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 09s      ms/item 35.91Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 46s      ms/item 36.20Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 23s      ms/item 36.09Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 00s      ms/item 36.27Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 37s      ms/item 35.90Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 14s      ms/item 35.96Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 51s      ms/item 36.23Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 28s      ms/item 36.19Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 05s      ms/item 36.17Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 42s      ms/item 36.01Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 19s      ms/item 36.04Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 56s      ms/item 35.94Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 33s      ms/item 36.22Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 05s      ms/item 38.16                                                                                                    
network-snapshot-001632        time 30m 12s      fid50k   123.1355
tick 73    kimg 1640.0    loss/reg: G ( 4.656 -1.000) D ( 0.077  0.059)  time 86400d 02h 38m sec/kimg 234.85  mem: GPU 3.03   CPU 6.30   exp
tick 74    kimg 1648.0    loss/reg: G ( 4.378 -1.000) D ( 0.107  0.059)  time 86400d 03h 09m sec/kimg 235.19  mem: GPU 3.03   CPU 6.30   exp
tick 75    kimg 1656.0    loss/reg: G ( 4.564 -1.000) D ( 0.081  0.058)  time 86400d 03h 40m sec/kimg 234.93  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.20Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.17Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.31Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.19Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.32Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.16Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 12s       ms/item 35.22Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.24Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.23Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.14Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.22Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.16Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.28Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.38Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.15Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.27Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.18Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.41Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.21Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 02s      ms/item 35.38Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 38s      ms/item 35.15Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 14s      ms/item 35.43Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 50s      ms/item 35.28Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 26s      ms/item 35.30Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 02s      ms/item 35.28Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.16Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.22Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.15Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.17Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 03s      ms/item 35.24Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 39s      ms/item 35.43Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 15s      ms/item 35.27Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 51s      ms/item 35.32Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 27s      ms/item 35.17Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 03s      ms/item 35.19Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 39s      ms/item 35.39Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 15s      ms/item 35.22Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 52s      ms/item 35.40Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 28s      ms/item 35.20Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 04s      ms/item 35.24Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 40s      ms/item 35.17Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 16s      ms/item 35.42Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 52s      ms/item 35.37Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 28s      ms/item 35.25Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 04s      ms/item 35.14Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 41s      ms/item 35.21Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 17s      ms/item 35.19Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 53s      ms/item 35.20Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 24s      ms/item 37.51                                                                                                    
network-snapshot-001656        time 29m 31s      fid50k   119.7209
tick 76    kimg 1664.0    loss/reg: G ( 4.502 -1.000) D ( 0.085  0.060)  time 86400d 04h 41m sec/kimg 235.29  mem: GPU 3.03   CPU 6.30   exp
tick 77    kimg 1672.0    loss/reg: G ( 4.530 -1.000) D ( 0.102  0.057)  time 86400d 05h 13m sec/kimg 235.27  mem: GPU 3.03   CPU 6.30   exp
tick 78    kimg 1680.0    loss/reg: G ( 4.579 -1.000) D ( 0.084  0.059)  time 86400d 05h 44m sec/kimg 234.98  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.17Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.01Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.18Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 35.81Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.02Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.07Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 36.08Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.28Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 36.06Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 35.90Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.02Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.49Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 35.89Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.21Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.15Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.00Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 36.15Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 05s      ms/item 36.02Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 42s      ms/item 35.83Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 36.21Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 56s      ms/item 36.19Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 33s      ms/item 36.06Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 10s      ms/item 36.14Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 47s      ms/item 35.99Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 24s      ms/item 36.11Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 01s      ms/item 35.96Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 38s      ms/item 36.35Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 15s      ms/item 36.48Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 52s      ms/item 35.99Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 29s      ms/item 36.00Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 06s      ms/item 36.01Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 43s      ms/item 36.17Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 20s      ms/item 36.53Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 57s      ms/item 36.17Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 34s      ms/item 36.04Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 11s      ms/item 36.44Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 48s      ms/item 36.01Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 25s      ms/item 36.13Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 02s      ms/item 36.07Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 39s      ms/item 36.07Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 16s      ms/item 36.09Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 53s      ms/item 36.22Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 30s      ms/item 36.04Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 07s      ms/item 36.18Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 44s      ms/item 36.04Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 21s      ms/item 36.13Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 58s      ms/item 36.24Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 35s      ms/item 36.16Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 08s      ms/item 38.14                                                                                                    
network-snapshot-001680        time 30m 14s      fid50k   118.8681
tick 79    kimg 1688.0    loss/reg: G ( 4.509 -1.000) D ( 0.097  0.057)  time 86400d 06h 46m sec/kimg 235.37  mem: GPU 3.03   CPU 6.30   exp
tick 80    kimg 1696.0    loss/reg: G ( 4.438 -1.000) D ( 0.110  0.056)  time 86400d 07h 17m sec/kimg 235.31  mem: GPU 3.03   CPU 6.30   exp
tick 81    kimg 1704.0    loss/reg: G ( 4.558 -1.000) D ( 0.102  0.057)  time 86400d 07h 48m sec/kimg 234.80  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.38Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.23Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.15Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.25Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 01s       ms/item 35.36Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.22Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.22Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.16Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.28Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.18Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.28Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.34Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.37Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.17Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.20Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 38s       ms/item 35.28Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 14s      ms/item 35.19Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 50s      ms/item 35.15Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 26s      ms/item 35.22Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 02s      ms/item 35.15Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 38s      ms/item 35.45Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 14s      ms/item 35.22Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 50s      ms/item 35.23Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 26s      ms/item 35.13Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 02s      ms/item 35.20Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.41Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 15s      ms/item 35.38Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 51s      ms/item 35.39Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 27s      ms/item 35.27Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 03s      ms/item 35.36Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 39s      ms/item 35.21Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 15s      ms/item 35.23Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 52s      ms/item 35.41Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 28s      ms/item 35.15Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 04s      ms/item 35.28Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 40s      ms/item 35.34Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 16s      ms/item 35.23Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 52s      ms/item 35.21Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 28s      ms/item 35.12Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 04s      ms/item 35.43Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 40s      ms/item 35.35Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 17s      ms/item 35.22Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 53s      ms/item 35.22Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 29s      ms/item 35.31Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 05s      ms/item 35.33Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 41s      ms/item 35.52Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 17s      ms/item 35.21Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 53s      ms/item 35.25Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 25s      ms/item 37.12                                                                                                    
network-snapshot-001704        time 29m 32s      fid50k   120.1202
tick 82    kimg 1712.0    loss/reg: G ( 4.615 -1.000) D ( 0.088  0.057)  time 86400d 08h 49m sec/kimg 235.18  mem: GPU 3.03   CPU 6.30   exp
tick 83    kimg 1720.0    loss/reg: G ( 4.516 -1.000) D ( 0.095  0.059)  time 86400d 09h 21m sec/kimg 234.93  mem: GPU 3.03   CPU 6.30   exp
tick 84    kimg 1728.0    loss/reg: G ( 4.400 -1.000) D ( 0.107  0.060)  time 86400d 09h 52m sec/kimg 235.26  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.49Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.65Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.24Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.23Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 35.94Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 36.13Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.03Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 56s       ms/item 36.52Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 33s       ms/item 35.78Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.26Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.23Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 35.96Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 36.06Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 38s       ms/item 36.40Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 15s       ms/item 35.97Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 52s       ms/item 36.05Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 29s      ms/item 36.31Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 06s      ms/item 36.10Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 43s      ms/item 36.15Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 20s      ms/item 36.01Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 57s      ms/item 36.19Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 34s      ms/item 36.17Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 11s      ms/item 36.35Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 48s      ms/item 36.04Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 25s      ms/item 36.04Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 02s      ms/item 36.07Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 39s      ms/item 36.17Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 16s      ms/item 36.17Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 53s      ms/item 36.01Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 30s      ms/item 36.01Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 07s      ms/item 36.16Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 44s      ms/item 36.04Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 21s      ms/item 36.18Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 58s      ms/item 36.05Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 35s      ms/item 36.01Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 11s      ms/item 36.04Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 48s      ms/item 36.15Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 25s      ms/item 35.98Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 02s      ms/item 35.98Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 39s      ms/item 36.16Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 16s      ms/item 36.05Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 53s      ms/item 36.17Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 30s      ms/item 36.05Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 07s      ms/item 35.97Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 44s      ms/item 36.14Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 21s      ms/item 36.09Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 58s      ms/item 36.06Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 35s      ms/item 36.35Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 08s      ms/item 38.44                                                                                                    
network-snapshot-001728        time 30m 14s      fid50k   119.3179
tick 85    kimg 1736.0    loss/reg: G ( 4.621 -1.000) D ( 0.083  0.057)  time 86400d 10h 54m sec/kimg 235.37  mem: GPU 3.04   CPU 6.30   exp
tick 86    kimg 1744.0    loss/reg: G ( 4.479 -1.000) D ( 0.101  0.055)  time 86400d 11h 25m sec/kimg 234.73  mem: GPU 3.04   CPU 6.30   exp
tick 87    kimg 1752.0    loss/reg: G ( 4.713 -1.000) D ( 0.077  0.056)  time 86400d 11h 56m sec/kimg 234.60  mem: GPU 3.04   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.35Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.22Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.24Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.10Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.21Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.17Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 12s       ms/item 35.21Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.23Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.19Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.21Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.29Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.16Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.18Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.18Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.21Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.17Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.21Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.20Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.30Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.13Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.23Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.18Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.19Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 25s      ms/item 35.21Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 01s      ms/item 35.17Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 37s      ms/item 35.23Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 13s      ms/item 35.17Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 49s      ms/item 35.21Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 25s      ms/item 35.24Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.18Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.24Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.31Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.21Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.19Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.22Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.25Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.13Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.23Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.26Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.13Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.19Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 14s      ms/item 35.28Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 50s      ms/item 35.12Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 26s      ms/item 35.20Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 02s      ms/item 35.23Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 38s      ms/item 35.18Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.24Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 50s      ms/item 35.15Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 22s      ms/item 37.29                                                                                                    
network-snapshot-001752        time 29m 29s      fid50k   119.0053
tick 88    kimg 1760.0    loss/reg: G ( 4.456 -1.000) D ( 0.104  0.060)  time 86400d 12h 57m sec/kimg 234.65  mem: GPU 3.03   CPU 6.30   exp
tick 89    kimg 1768.0    loss/reg: G ( 4.578 -1.000) D ( 0.097  0.055)  time 86400d 13h 28m sec/kimg 234.34  mem: GPU 3.03   CPU 6.30   exp
tick 90    kimg 1776.0    loss/reg: G ( 4.534 -1.000) D ( 0.094  0.058)  time 86400d 14h 00m sec/kimg 234.73  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.33Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.97Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.78Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.86Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 36.00Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 35.93Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 36.20Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 36.22Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 35.84Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 36.15Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 35.78Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 22s       ms/item 35.87Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 59s       ms/item 36.12Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 36s       ms/item 36.06Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 13s       ms/item 36.03Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 50s       ms/item 35.97Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 36.01Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 04s      ms/item 35.94Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 41s      ms/item 36.05Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 17s      ms/item 36.01Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 54s      ms/item 36.15Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 31s      ms/item 35.67Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 08s      ms/item 35.99Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 45s      ms/item 36.29Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 21s      ms/item 35.64Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 58s      ms/item 36.08Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 35s      ms/item 35.95Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 12s      ms/item 35.85Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 49s      ms/item 35.90Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 26s      ms/item 36.06Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 03s      ms/item 36.28Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 39s      ms/item 35.67Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 16s      ms/item 36.04Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 53s      ms/item 36.06Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 30s      ms/item 35.98Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 07s      ms/item 36.12Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 44s      ms/item 35.75Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 20s      ms/item 35.82Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 57s      ms/item 35.85Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 34s      ms/item 36.35Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 11s      ms/item 36.05Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 48s      ms/item 35.81Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 25s      ms/item 36.22Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 02s      ms/item 36.01Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 39s      ms/item 35.99Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 15s      ms/item 36.01Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 52s      ms/item 36.02Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 29s      ms/item 35.76Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 01s      ms/item 38.19                                                                                                    
network-snapshot-001776        time 30m 08s      fid50k   119.7776
tick 91    kimg 1784.0    loss/reg: G ( 4.504 -1.000) D ( 0.088  0.057)  time 86400d 15h 01m sec/kimg 234.29  mem: GPU 3.03   CPU 6.30   exp
tick 92    kimg 1792.0    loss/reg: G ( 4.570 -1.000) D ( 0.078  0.060)  time 86400d 15h 32m sec/kimg 234.69  mem: GPU 3.03   CPU 6.30   exp
tick 93    kimg 1800.0    loss/reg: G ( 4.603 -1.000) D ( 0.100  0.058)  time 86400d 16h 04m sec/kimg 234.69  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.92Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.42Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.48Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 26s       ms/item 35.74Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.60Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 39s       ms/item 35.78Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 16s       ms/item 36.05Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 53s       ms/item 35.78Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 29s       ms/item 35.71Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 06s       ms/item 35.67Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 42s       ms/item 35.50Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 18s       ms/item 35.56Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 55s       ms/item 35.88Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 32s       ms/item 35.89Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 08s       ms/item 35.66Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 45s       ms/item 35.53Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 21s      ms/item 35.64Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 58s      ms/item 35.57Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 34s      ms/item 35.55Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 11s      ms/item 35.88Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 48s      ms/item 35.82Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 24s      ms/item 35.77Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 01s      ms/item 35.81Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 37s      ms/item 35.56Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 14s      ms/item 35.63Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 50s      ms/item 35.57Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 27s      ms/item 35.64Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 03s      ms/item 35.55Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 40s      ms/item 35.62Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 17s      ms/item 36.04Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 53s      ms/item 35.71Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 29s      ms/item 35.47Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 06s      ms/item 35.66Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 43s      ms/item 35.77Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 19s      ms/item 35.57Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 56s      ms/item 35.95Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 32s      ms/item 35.46Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 09s      ms/item 35.58Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 45s      ms/item 35.79Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 22s      ms/item 36.02Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 58s      ms/item 35.48Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 35s      ms/item 35.72Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 12s      ms/item 35.72Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 48s      ms/item 35.68Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 25s      ms/item 35.96Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 01s      ms/item 35.43Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 38s      ms/item 35.79Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 14s      ms/item 35.59Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 46s      ms/item 37.66                                                                                                    
network-snapshot-001800        time 29m 53s      fid50k   120.4913
tick 94    kimg 1808.0    loss/reg: G ( 4.518 -1.000) D ( 0.106  0.056)  time 86400d 17h 05m sec/kimg 234.35  mem: GPU 3.03   CPU 6.30   exp
tick 95    kimg 1816.0    loss/reg: G ( 4.811 -1.000) D ( 0.059  0.058)  time 86400d 17h 36m sec/kimg 234.64  mem: GPU 3.03   CPU 6.30   exp
tick 96    kimg 1824.0    loss/reg: G ( 4.497 -1.000) D ( 0.100  0.057)  time 86400d 18h 07m sec/kimg 234.71  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.89Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.93Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 36.06Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.39Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 35.94Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 35.96Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 19s       ms/item 36.39Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 35.52Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 35.98Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 36.33Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.19Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.05Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 35.63Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.25Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 13s       ms/item 35.90Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.41Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 35.84Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 04s      ms/item 35.73Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 41s      ms/item 35.83Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 18s      ms/item 36.11Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 54s      ms/item 35.72Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 31s      ms/item 36.23Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 08s      ms/item 35.75Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 45s      ms/item 35.97Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 21s      ms/item 35.84Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 58s      ms/item 35.95Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 35s      ms/item 35.99Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 12s      ms/item 35.86Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 49s      ms/item 36.24Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 25s      ms/item 35.60Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 02s      ms/item 35.99Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 39s      ms/item 35.99Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 16s      ms/item 36.00Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 53s      ms/item 36.14Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 30s      ms/item 35.82Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 06s      ms/item 35.83Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 43s      ms/item 35.78Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 20s      ms/item 35.97Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 57s      ms/item 36.06Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 34s      ms/item 36.01Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 10s      ms/item 35.75Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 47s      ms/item 35.88Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 24s      ms/item 35.76Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 01s      ms/item 36.04Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 37s      ms/item 35.76Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 14s      ms/item 35.97Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 51s      ms/item 35.87Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 28s      ms/item 35.95Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 00s      ms/item 37.94                                                                                                    
network-snapshot-001824        time 30m 06s      fid50k   120.6845
tick 97    kimg 1832.0    loss/reg: G ( 4.378 -1.000) D ( 0.125  0.055)  time 86400d 19h 09m sec/kimg 234.45  mem: GPU 3.03   CPU 6.30   exp
tick 98    kimg 1840.0    loss/reg: G ( 4.603 -1.000) D ( 0.082  0.057)  time 86400d 19h 40m sec/kimg 234.60  mem: GPU 3.03   CPU 6.30   exp
tick 99    kimg 1848.0    loss/reg: G ( 4.745 -1.000) D ( 0.068  0.057)  time 86400d 20h 11m sec/kimg 234.52  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.51Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.10Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.16Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.23Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.23Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.19Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.20Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.17Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.23Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.18Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.23Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.18Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.18Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.26Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.21Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.17Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.24Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.14Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.19Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.21Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.30Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.11Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.23Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 25s      ms/item 35.22Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 01s      ms/item 35.13Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 37s      ms/item 35.30Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.22Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 49s      ms/item 35.10Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.29Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.13Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.19Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.18Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.19Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.27Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.15Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.39Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.22Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.21Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.21Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.19Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.21Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 14s      ms/item 35.18Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 50s      ms/item 35.21Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 26s      ms/item 35.20Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 03s      ms/item 35.32Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 38s      ms/item 35.07Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.25Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.17Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 22s      ms/item 37.15                                                                                                    
network-snapshot-001848        time 29m 29s      fid50k   120.4796
tick 100   kimg 1856.0    loss/reg: G ( 4.523 -1.000) D ( 0.093  0.056)  time 86400d 21h 12m sec/kimg 234.88  mem: GPU 3.03   CPU 6.30   exp
tick 101   kimg 1864.0    loss/reg: G ( 4.609 -1.000) D ( 0.084  0.057)  time 86400d 21h 43m sec/kimg 234.73  mem: GPU 3.03   CPU 6.30   exp
tick 102   kimg 1872.0    loss/reg: G ( 4.652 -1.000) D ( 0.076  0.057)  time 86400d 22h 15m sec/kimg 234.57  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.11Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.05Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 36.12Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.54Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.94Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.00Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 36.20Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 35.79Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 35.99Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 08s       ms/item 36.07Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 45s       ms/item 36.13Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 22s       ms/item 35.95Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 59s       ms/item 36.01Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.53Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.13Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.21Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 36.11Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 04s      ms/item 35.88Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 42s      ms/item 36.40Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 18s      ms/item 35.93Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 56s      ms/item 36.42Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 32s      ms/item 35.80Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 09s      ms/item 35.84Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 46s      ms/item 36.14Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 23s      ms/item 35.98Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 00s      ms/item 35.82Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 37s      ms/item 36.04Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 13s      ms/item 35.97Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 50s      ms/item 35.91Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 27s      ms/item 36.29Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 04s      ms/item 36.25Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 41s      ms/item 35.62Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 18s      ms/item 36.33Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 55s      ms/item 36.04Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 32s      ms/item 36.15Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 09s      ms/item 35.84Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 46s      ms/item 35.96Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 22s      ms/item 35.90Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 59s      ms/item 36.28Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 36s      ms/item 35.84Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 13s      ms/item 35.93Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 50s      ms/item 35.89Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 27s      ms/item 36.02Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 04s      ms/item 36.40Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 41s      ms/item 36.23Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 18s      ms/item 35.76Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 55s      ms/item 36.20Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 32s      ms/item 36.00Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 04s      ms/item 38.14                                                                                                    
network-snapshot-001872        time 30m 10s      fid50k   122.0894
tick 103   kimg 1880.0    loss/reg: G ( 4.441 -1.000) D ( 0.117  0.054)  time 86400d 23h 16m sec/kimg 234.83  mem: GPU 3.04   CPU 6.30   exp
tick 104   kimg 1888.0    loss/reg: G ( 4.783 -1.000) D ( 0.074  0.055)  time 86400d 23h 47m sec/kimg 234.81  mem: GPU 3.04   CPU 6.30   exp
tick 105   kimg 1896.0    loss/reg: G ( 4.714 -1.000) D ( 0.072  0.055)  time 86400d 00h 19m sec/kimg 234.60  mem: GPU 3.04   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.36Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.16Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.20Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.22Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.23Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.16Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.26Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 48s       ms/item 35.14Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.23Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.21Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.39Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.17Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.21Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.22Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.19Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.18Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.29Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.14Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.23Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.15Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.18Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.27Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.13Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 25s      ms/item 35.21Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 01s      ms/item 35.22Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.16Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.25Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.17Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.20Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.30Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.07Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.21Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.47Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.18Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.20Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.23Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.13Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.22Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.23Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.14Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.21Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 14s      ms/item 35.20Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 51s      ms/item 35.23Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 27s      ms/item 35.22Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 03s      ms/item 35.20Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 39s      ms/item 35.17Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.27Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.12Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 22s      ms/item 37.24                                                                                                    
network-snapshot-001896        time 29m 29s      fid50k   120.5810
tick 106   kimg 1904.0    loss/reg: G ( 4.588 -1.000) D ( 0.093  0.056)  time 86400d 01h 19m sec/kimg 234.88  mem: GPU 3.03   CPU 6.30   exp
tick 107   kimg 1912.0    loss/reg: G ( 4.722 -1.000) D ( 0.076  0.054)  time 86400d 01h 51m sec/kimg 234.57  mem: GPU 3.03   CPU 6.30   exp
tick 108   kimg 1920.0    loss/reg: G ( 4.646 -1.000) D ( 0.103  0.053)  time 86400d 02h 22m sec/kimg 234.86  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.11Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.40Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.74Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 35.86Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.80Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.24Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 35.78Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 35.98Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 36.13Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 35.95Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.06Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.16Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 59s       ms/item 35.73Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 36s       ms/item 35.87Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 13s       ms/item 36.24Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 50s       ms/item 35.87Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 35.92Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 03s      ms/item 35.91Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 40s      ms/item 36.14Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 17s      ms/item 36.00Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 54s      ms/item 35.81Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 31s      ms/item 36.36Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 08s      ms/item 35.77Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 45s      ms/item 36.20Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 22s      ms/item 35.87Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 58s      ms/item 36.01Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 35s      ms/item 36.02Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 12s      ms/item 35.96Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 49s      ms/item 35.98Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 26s      ms/item 36.22Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 03s      ms/item 35.80Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 40s      ms/item 36.33Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 17s      ms/item 35.91Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 54s      ms/item 36.03Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 31s      ms/item 36.12Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 07s      ms/item 35.95Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 44s      ms/item 36.22Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 22s      ms/item 36.21Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 58s      ms/item 36.06Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 35s      ms/item 35.99Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 12s      ms/item 35.86Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 49s      ms/item 36.05Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 26s      ms/item 36.10Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 03s      ms/item 36.19Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 40s      ms/item 36.00Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 17s      ms/item 36.07Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 54s      ms/item 35.94Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 30s      ms/item 35.96Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 03s      ms/item 37.94                                                                                                    
network-snapshot-001920        time 30m 09s      fid50k   119.8578
tick 109   kimg 1928.0    loss/reg: G ( 4.552 -1.000) D ( 0.088  0.055)  time 86400d 03h 24m sec/kimg 234.91  mem: GPU 3.03   CPU 6.30   exp
tick 110   kimg 1936.0    loss/reg: G ( 4.670 -1.000) D ( 0.089  0.053)  time 86400d 03h 55m sec/kimg 234.64  mem: GPU 3.03   CPU 6.30   exp
tick 111   kimg 1944.0    loss/reg: G ( 4.758 -1.000) D ( 0.067  0.059)  time 86400d 04h 26m sec/kimg 234.83  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.44Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.19Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.21Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.20Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.20Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 37s       ms/item 35.21Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.39Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.15Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.26Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.14Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.25Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.19Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.22Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.17Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.21Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.23Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.11Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.28Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.16Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.17Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.30Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.16Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 50s      ms/item 35.22Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 26s      ms/item 35.45Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 02s      ms/item 35.31Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.16Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.25Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.23Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.15Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.25Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.15Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.23Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.23Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.16Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.20Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.17Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 15s      ms/item 35.41Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 51s      ms/item 35.23Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 27s      ms/item 35.38Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 03s      ms/item 35.22Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 39s      ms/item 35.19Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 15s      ms/item 35.24Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 51s      ms/item 35.22Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 27s      ms/item 35.18Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 03s      ms/item 35.13Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 39s      ms/item 35.30Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.17Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.15Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 23s      ms/item 37.32                                                                                                    
network-snapshot-001944        time 29m 30s      fid50k   122.7014
tick 112   kimg 1952.0    loss/reg: G ( 4.620 -1.000) D ( 0.098  0.054)  time 86400d 05h 27m sec/kimg 234.84  mem: GPU 3.03   CPU 6.30   exp
tick 113   kimg 1960.0    loss/reg: G ( 4.634 -1.000) D ( 0.091  0.053)  time 86400d 05h 58m sec/kimg 234.65  mem: GPU 3.03   CPU 6.30   exp
tick 114   kimg 1968.0    loss/reg: G ( 4.694 -1.000) D ( 0.084  0.055)  time 86400d 06h 30m sec/kimg 235.01  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 35.77Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.94Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 36.01Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.92Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.89Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 35.92Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 17s       ms/item 35.88Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 54s       ms/item 36.15Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 31s       ms/item 35.81Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 08s       ms/item 36.03Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 45s       ms/item 36.35Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 22s       ms/item 35.80Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 59s       ms/item 36.01Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 36s       ms/item 36.05Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 12s       ms/item 35.94Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 50s       ms/item 36.39Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 36.08Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 03s      ms/item 35.75Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 40s      ms/item 36.03Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 17s      ms/item 36.17Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 54s      ms/item 36.06Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 31s      ms/item 35.99Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 08s      ms/item 36.19Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 45s      ms/item 35.81Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 22s      ms/item 36.01Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 58s      ms/item 35.99Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 35s      ms/item 36.08Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 12s      ms/item 36.08Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 49s      ms/item 36.03Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 26s      ms/item 35.99Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 03s      ms/item 36.28Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 40s      ms/item 36.02Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 17s      ms/item 36.13Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 54s      ms/item 36.37Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 31s      ms/item 35.75Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 08s      ms/item 35.98Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 45s      ms/item 36.29Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 22s      ms/item 36.34Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 59s      ms/item 35.80Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 36s      ms/item 36.00Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 13s      ms/item 36.06Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 49s      ms/item 36.03Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 26s      ms/item 35.79Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 03s      ms/item 36.18Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 40s      ms/item 35.78Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 17s      ms/item 36.20Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 54s      ms/item 35.85Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 31s      ms/item 36.33Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 03s      ms/item 37.94                                                                                                    
network-snapshot-001968        time 30m 09s      fid50k   125.1943
tick 115   kimg 1976.0    loss/reg: G ( 4.723 -1.000) D ( 0.081  0.055)  time 86400d 07h 31m sec/kimg 234.61  mem: GPU 3.03   CPU 6.30   exp
tick 116   kimg 1984.0    loss/reg: G ( 4.803 -1.000) D ( 0.076  0.054)  time 86400d 08h 02m sec/kimg 234.99  mem: GPU 3.03   CPU 6.30   exp
tick 117   kimg 1992.0    loss/reg: G ( 4.514 -1.000) D ( 0.122  0.051)  time 86400d 08h 34m sec/kimg 234.77  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.58Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 13s       ms/item 35.75Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 35.63Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 26s       ms/item 35.82Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 03s       ms/item 36.15Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 39s       ms/item 35.43Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 16s       ms/item 35.97Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 53s       ms/item 35.62Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 30s       ms/item 36.18Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 06s       ms/item 35.62Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 43s       ms/item 35.99Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 20s       ms/item 35.57Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 56s       ms/item 35.61Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 33s       ms/item 35.64Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 09s       ms/item 35.85Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 46s       ms/item 35.71Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 22s      ms/item 35.68Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 59s      ms/item 35.84Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 36s      ms/item 35.95Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 12s      ms/item 35.61Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 49s      ms/item 35.57Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 26s      ms/item 35.92Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 02s      ms/item 35.91Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 39s      ms/item 35.78Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 16s      ms/item 35.98Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 53s      ms/item 36.25Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 29s      ms/item 35.45Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 06s      ms/item 35.88Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 43s      ms/item 36.04Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 19s      ms/item 35.60Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 56s      ms/item 35.97Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 33s      ms/item 35.86Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 10s      ms/item 36.01Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 46s      ms/item 35.57Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 23s      ms/item 35.84Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 59s      ms/item 35.53Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 36s      ms/item 35.85Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 13s      ms/item 36.29Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 49s      ms/item 35.52Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 26s      ms/item 35.59Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 03s      ms/item 36.02Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 39s      ms/item 35.78Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 16s      ms/item 35.76Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 53s      ms/item 35.80Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 29s      ms/item 35.81Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 06s      ms/item 35.64Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 43s      ms/item 36.01Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 20s      ms/item 36.06Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 52s      ms/item 37.52                                                                                                    
network-snapshot-001992        time 29m 58s      fid50k   122.6905
tick 118   kimg 2000.0    loss/reg: G ( 4.606 -1.000) D ( 0.073  0.058)  time 86400d 09h 35m sec/kimg 234.64  mem: GPU 3.03   CPU 6.30   exp
tick 119   kimg 2008.0    loss/reg: G ( 4.740 -1.000) D ( 0.087  0.053)  time 86400d 10h 06m sec/kimg 234.77  mem: GPU 3.03   CPU 6.30   exp
tick 120   kimg 2016.0    loss/reg: G ( 4.466 -1.000) D ( 0.115  0.053)  time 86400d 10h 38m sec/kimg 234.74  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.29Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 35.82Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 50s       ms/item 35.80Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 27s       ms/item 35.95Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 04s       ms/item 35.82Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 36.38Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 35.77Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 36.01Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 31s       ms/item 35.84Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 36.20Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.21Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 36.34Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 36.06Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 35.97Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.18Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 50s       ms/item 35.99Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 27s      ms/item 36.07Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 04s      ms/item 36.00Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 41s      ms/item 35.93Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 18s      ms/item 36.25Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 55s      ms/item 36.16Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 32s      ms/item 36.04Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 09s      ms/item 36.22Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 46s      ms/item 35.75Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 23s      ms/item 35.85Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 59s      ms/item 36.12Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 37s      ms/item 36.15Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 13s      ms/item 35.91Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 50s      ms/item 35.97Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 27s      ms/item 35.99Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 04s      ms/item 36.05Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 41s      ms/item 36.03Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 18s      ms/item 36.16Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 55s      ms/item 35.96Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 31s      ms/item 35.95Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 08s      ms/item 35.92Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 46s      ms/item 36.41Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 23s      ms/item 36.35Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 59s      ms/item 35.79Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 36s      ms/item 35.96Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 13s      ms/item 35.78Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 50s      ms/item 35.97Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 27s      ms/item 36.31Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 04s      ms/item 36.20Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 41s      ms/item 35.82Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 17s      ms/item 36.04Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 54s      ms/item 36.04Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 31s      ms/item 36.15Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 04s      ms/item 38.05                                                                                                    
network-snapshot-002016        time 30m 10s      fid50k   124.4913
tick 121   kimg 2024.0    loss/reg: G ( 4.748 -1.000) D ( 0.069  0.055)  time 86400d 11h 39m sec/kimg 234.53  mem: GPU 3.03   CPU 6.30   exp
tick 122   kimg 2032.0    loss/reg: G ( 4.441 -1.000) D ( 0.129  0.054)  time 86400d 12h 10m sec/kimg 234.83  mem: GPU 3.03   CPU 6.30   exp
tick 123   kimg 2040.0    loss/reg: G ( 4.810 -1.000) D ( 0.064  0.052)  time 86400d 12h 42m sec/kimg 234.70  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.17Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.20Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.16Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.23Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.26Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.10Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 12s       ms/item 35.24Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 48s       ms/item 35.17Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 24s       ms/item 35.19Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 00s       ms/item 35.20Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 36s       ms/item 35.22Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.22Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.16Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.22Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.16Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.24Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.17Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.23Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.19Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.24Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.17Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.17Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.20Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 25s      ms/item 35.27Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 01s      ms/item 35.19Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 37s      ms/item 35.17Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 13s      ms/item 35.21Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 49s      ms/item 35.21Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 25s      ms/item 35.24Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 01s      ms/item 35.14Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 37s      ms/item 35.19Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 13s      ms/item 35.20Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 49s      ms/item 35.24Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 25s      ms/item 35.19Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 01s      ms/item 35.15Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.31Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.12Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.25Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.19Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.20Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.18Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 14s      ms/item 35.19Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 50s      ms/item 35.18Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 26s      ms/item 35.21Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 02s      ms/item 35.24Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 38s      ms/item 35.19Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 14s      ms/item 35.19Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 50s      ms/item 35.19Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 22s      ms/item 37.32                                                                                                    
network-snapshot-002040        time 29m 28s      fid50k   122.0398
tick 124   kimg 2048.0    loss/reg: G ( 4.491 -1.000) D ( 0.113  0.051)  time 86400d 13h 42m sec/kimg 234.69  mem: GPU 3.03   CPU 6.30   exp
tick 125   kimg 2056.0    loss/reg: G ( 4.523 -1.000) D ( 0.103  0.053)  time 86400d 14h 14m sec/kimg 234.83  mem: GPU 3.03   CPU 6.30   exp
tick 126   kimg 2064.0    loss/reg: G ( 4.767 -1.000) D ( 0.077  0.054)  time 86400d 14h 45m sec/kimg 234.60  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.08Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.02Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.97Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.05Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 36.24Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 41s       ms/item 35.95Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 36.04Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 36.07Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 35.90Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 09s       ms/item 35.99Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 46s       ms/item 36.41Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 23s       ms/item 35.80Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 35.99Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.14Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 13s       ms/item 35.75Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 51s       ms/item 36.54Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 28s      ms/item 36.18Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 05s      ms/item 35.82Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 42s      ms/item 36.19Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 36.20Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 55s      ms/item 35.96Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 33s      ms/item 36.25Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 09s      ms/item 35.99Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 46s      ms/item 35.98Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 23s      ms/item 35.96Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 00s      ms/item 36.10Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 37s      ms/item 36.03Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 14s      ms/item 36.14Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 51s      ms/item 36.03Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 28s      ms/item 35.99Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 05s      ms/item 36.07Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 42s      ms/item 36.16Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 18s      ms/item 35.91Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 55s      ms/item 36.05Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 32s      ms/item 36.16Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 09s      ms/item 36.06Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 46s      ms/item 36.11Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 23s      ms/item 36.02Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 00s      ms/item 35.82Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 37s      ms/item 36.06Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 14s      ms/item 35.97Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 50s      ms/item 36.04Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 27s      ms/item 35.97Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 04s      ms/item 35.92Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 41s      ms/item 36.08Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 18s      ms/item 36.01Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 55s      ms/item 35.98Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 32s      ms/item 35.86Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 04s      ms/item 38.07                                                                                                    
network-snapshot-002064        time 30m 10s      fid50k   121.1230
tick 127   kimg 2072.0    loss/reg: G ( 4.640 -1.000) D ( 0.086  0.052)  time 86400d 15h 47m sec/kimg 234.79  mem: GPU 3.03   CPU 6.30   exp
tick 128   kimg 2080.0    loss/reg: G ( 4.743 -1.000) D ( 0.086  0.054)  time 86400d 16h 18m sec/kimg 234.94  mem: GPU 3.03   CPU 6.30   exp
tick 129   kimg 2088.0    loss/reg: G ( 4.581 -1.000) D ( 0.116  0.048)  time 86400d 16h 49m sec/kimg 234.55  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.43Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.15Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.21Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.24Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.18Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.21Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.25Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.15Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.20Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.25Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.14Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.27Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.14Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.31Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.28Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.17Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.22Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.30Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.11Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.17Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.22Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.21Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.20Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 25s      ms/item 35.20Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 02s      ms/item 35.26Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.19Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.13Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.22Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.19Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.21Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.23Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.23Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.14Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.24Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.14Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.27Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.22Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.16Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.21Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.16Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.24Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 14s      ms/item 35.16Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 50s      ms/item 35.19Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 26s      ms/item 35.22Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 02s      ms/item 35.19Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 38s      ms/item 35.18Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.23Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.17Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 22s      ms/item 37.21                                                                                                    
network-snapshot-002088        time 29m 29s      fid50k   122.7734
tick 130   kimg 2096.0    loss/reg: G ( 4.836 -1.000) D ( 0.072  0.051)  time 86400d 17h 50m sec/kimg 234.75  mem: GPU 3.03   CPU 6.30   exp
tick 131   kimg 2104.0    loss/reg: G ( 4.620 -1.000) D ( 0.107  0.052)  time 86400d 18h 21m sec/kimg 234.48  mem: GPU 3.03   CPU 6.30   exp
tick 132   kimg 2112.0    loss/reg: G ( 4.591 -1.000) D ( 0.127  0.053)  time 86400d 18h 52m sec/kimg 234.80  mem: GPU 3.03   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 37s          ms/item 36.27Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 14s       ms/item 36.13Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 51s       ms/item 35.73Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 28s       ms/item 36.58Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 05s       ms/item 35.77Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 42s       ms/item 35.98Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 18s       ms/item 35.98Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 55s       ms/item 36.12Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 32s       ms/item 35.93Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 10s       ms/item 36.50Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 47s       ms/item 36.27Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 24s       ms/item 36.27Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 01s       ms/item 35.82Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 38s       ms/item 36.42Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 15s       ms/item 35.96Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 52s       ms/item 35.97Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 29s      ms/item 36.20Evaluation: computing generator features items 18432/50000 (36.86%) time 11m 06s      ms/item 36.14Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 43s      ms/item 36.25Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 19s      ms/item 35.78Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 57s      ms/item 36.33Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 34s      ms/item 36.46Evaluation: computing generator features items 23552/50000 (47.10%) time 14m 11s      ms/item 35.92Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 48s      ms/item 35.97Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 25s      ms/item 36.30Evaluation: computing generator features items 26624/50000 (53.25%) time 16m 02s      ms/item 36.19Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 39s      ms/item 35.90Evaluation: computing generator features items 28672/50000 (57.34%) time 17m 15s      ms/item 35.79Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 52s      ms/item 36.18Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 29s      ms/item 36.03Evaluation: computing generator features items 31744/50000 (63.49%) time 19m 06s      ms/item 35.99Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 43s      ms/item 36.02Evaluation: computing generator features items 33792/50000 (67.58%) time 20m 20s      ms/item 36.35Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 57s      ms/item 36.01Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 34s      ms/item 35.91Evaluation: computing generator features items 36864/50000 (73.73%) time 22m 11s      ms/item 36.15Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 48s      ms/item 35.98Evaluation: computing generator features items 38912/50000 (77.82%) time 23m 24s      ms/item 35.98Evaluation: computing generator features items 39936/50000 (79.87%) time 24m 02s      ms/item 36.20Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 38s      ms/item 35.92Evaluation: computing generator features items 41984/50000 (83.97%) time 25m 15s      ms/item 36.10Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 52s      ms/item 36.16Evaluation: computing generator features items 44032/50000 (88.06%) time 26m 29s      ms/item 36.07Evaluation: computing generator features items 45056/50000 (90.11%) time 27m 06s      ms/item 36.14Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 43s      ms/item 35.71Evaluation: computing generator features items 47104/50000 (94.21%) time 28m 20s      ms/item 36.09Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 57s      ms/item 36.21Evaluation: computing generator features items 49152/50000 (98.30%) time 29m 34s      ms/item 35.88Evaluation: computing generator features items 50000/50000 (100.00%) time 30m 06s      ms/item 37.93                                                                                                    
network-snapshot-002112        time 30m 12s      fid50k   120.0227
tick 133   kimg 2120.0    loss/reg: G ( 4.722 -1.000) D ( 0.086  0.053)  time 86400d 19h 54m sec/kimg 234.77  mem: GPU 3.04   CPU 6.30   exp
tick 134   kimg 2128.0    loss/reg: G ( 4.679 -1.000) D ( 0.082  0.054)  time 86400d 20h 25m sec/kimg 234.48  mem: GPU 3.04   CPU 6.30   exp
tick 135   kimg 2136.0    loss/reg: G ( 4.685 -1.000) D ( 0.088  0.054)  time 86400d 20h 57m sec/kimg 236.32  mem: GPU 3.04   CPU 6.30   exp
Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.34Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.25Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 48s       ms/item 35.21Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 24s       ms/item 35.16Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 00s       ms/item 35.23Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 36s       ms/item 35.21Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 13s       ms/item 35.21Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 49s       ms/item 35.14Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 25s       ms/item 35.20Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 01s       ms/item 35.23Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 37s       ms/item 35.22Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 13s       ms/item 35.19Evaluation: computing generator features items 13312/50000 (26.62%) time 7m 49s       ms/item 35.16Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 25s       ms/item 35.31Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 01s       ms/item 35.12Evaluation: computing generator features items 16384/50000 (32.77%) time 9m 37s       ms/item 35.18Evaluation: computing generator features items 17408/50000 (34.82%) time 10m 13s      ms/item 35.25Evaluation: computing generator features items 18432/50000 (36.86%) time 10m 49s      ms/item 35.17Evaluation: computing generator features items 19456/50000 (38.91%) time 11m 25s      ms/item 35.19Evaluation: computing generator features items 20480/50000 (40.96%) time 12m 01s      ms/item 35.23Evaluation: computing generator features items 21504/50000 (43.01%) time 12m 37s      ms/item 35.26Evaluation: computing generator features items 22528/50000 (45.06%) time 13m 13s      ms/item 35.37Evaluation: computing generator features items 23552/50000 (47.10%) time 13m 49s      ms/item 35.16Evaluation: computing generator features items 24576/50000 (49.15%) time 14m 26s      ms/item 35.24Evaluation: computing generator features items 25600/50000 (51.20%) time 15m 02s      ms/item 35.22Evaluation: computing generator features items 26624/50000 (53.25%) time 15m 38s      ms/item 35.15Evaluation: computing generator features items 27648/50000 (55.30%) time 16m 14s      ms/item 35.19Evaluation: computing generator features items 28672/50000 (57.34%) time 16m 50s      ms/item 35.20Evaluation: computing generator features items 29696/50000 (59.39%) time 17m 26s      ms/item 35.20Evaluation: computing generator features items 30720/50000 (61.44%) time 18m 02s      ms/item 35.23Evaluation: computing generator features items 31744/50000 (63.49%) time 18m 38s      ms/item 35.20Evaluation: computing generator features items 32768/50000 (65.54%) time 19m 14s      ms/item 35.17Evaluation: computing generator features items 33792/50000 (67.58%) time 19m 50s      ms/item 35.23Evaluation: computing generator features items 34816/50000 (69.63%) time 20m 26s      ms/item 35.18Evaluation: computing generator features items 35840/50000 (71.68%) time 21m 02s      ms/item 35.18Evaluation: computing generator features items 36864/50000 (73.73%) time 21m 38s      ms/item 35.21Evaluation: computing generator features items 37888/50000 (75.78%) time 22m 14s      ms/item 35.23Evaluation: computing generator features items 38912/50000 (77.82%) time 22m 50s      ms/item 35.23Evaluation: computing generator features items 39936/50000 (79.87%) time 23m 26s      ms/item 35.27Evaluation: computing generator features items 40960/50000 (81.92%) time 24m 02s      ms/item 35.06Evaluation: computing generator features items 41984/50000 (83.97%) time 24m 38s      ms/item 35.25Evaluation: computing generator features items 43008/50000 (86.02%) time 25m 14s      ms/item 35.17Evaluation: computing generator features items 44032/50000 (88.06%) time 25m 50s      ms/item 35.18Evaluation: computing generator features items 45056/50000 (90.11%) time 26m 26s      ms/item 35.25Evaluation: computing generator features items 46080/50000 (92.16%) time 27m 02s      ms/item 35.18Evaluation: computing generator features items 47104/50000 (94.21%) time 27m 38s      ms/item 35.21Evaluation: computing generator features items 48128/50000 (96.26%) time 28m 15s      ms/item 35.25Evaluation: computing generator features items 49152/50000 (98.30%) time 28m 51s      ms/item 35.11Evaluation: computing generator features items 50000/50000 (100.00%) time 29m 22s      ms/item 37.25                                                                                                    
network-snapshot-002136        time 29m 29s      fid50k   122.6577
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 386, in training_loop
    run_training_stage(loss, stage, device, real_img, real_c, gen_z, gen_c, batch_size, batch_gpu, num_gpus)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 193, in run_training_stage
    gen_z = z, gen_c = cz, sync = sync, gain = stage.interval)
  File "/home/quoniam/Work/TileGAN/gan/training/loss.py", line 70, in accumulate_gradients
    gen_img, _gen_ws = self.run_G(gen_z, gen_c, sync = (sync and not G_pl)) # May get synced by G_pl
  File "/home/quoniam/Work/TileGAN/gan/training/loss.py", line 52, in run_G
    img = self.G(ws = ws, subnet = "synthesis")
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/quoniam/Work/TileGAN/gan/training/networks.py", line 1319, in forward
    img, att_maps = self.synthesis(ws, pos = self.pos, mask = mask, **synthesis_kwargs)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/quoniam/Work/TileGAN/gan/training/networks.py", line 1261, in forward
    att_maps = self.list2tensor(att_maps, ws.device)
  File "/home/quoniam/Work/TileGAN/gan/training/networks.py", line 1236, in list2tensor
    att_map = upfirdn2d.upsample2d(att_map, f = nearest_neighbors_kernel(att_map.device, factor), up = factor)
  File "/home/quoniam/Work/TileGAN/gan/training/networks.py", line 52, in nearest_neighbors_kernel
    return upfirdn2d.setup_filter([1] * factor, device = device)
  File "/home/quoniam/Work/TileGAN/gan/torch_utils/ops/upfirdn2d.py", line 108, in setup_filter
    f = f.to(device=device)
KeyboardInterrupt
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:07<00:00,  7.33s/it]100%|##########| 1/1 [00:07<00:00,  7.33s/it]
Visualizations Completed!
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:07<00:00,  7.28s/it]100%|##########| 1/1 [00:07<00:00,  7.28s/it]
Visualizations Completed!
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:07<00:00,  7.26s/it]100%|##########| 1/1 [00:07<00:00,  7.26s/it]
Visualizations Completed!
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002112.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:07<00:00,  7.29s/it]100%|##########| 1/1 [00:07<00:00,  7.29s/it]
Visualizations Completed!
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002112.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:07<00:00,  7.27s/it]100%|##########| 1/1 [00:07<00:00,  7.27s/it]
Generating style mixes...
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 297, in vis
    mix_imgs = run(G, mix_z, c, batch_size, truncation_psi, noise_mode = "const", take_w = True)[0]
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 21, in run
    outs = [G(z, c, truncation_psi = truncation_psi, **kwargs) for z, c in zip(zs.split(batch_size), cs.split(batch_size))]
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 21, in <listcomp>
    outs = [G(z, c, truncation_psi = truncation_psi, **kwargs) for z, c in zip(zs.split(batch_size), cs.split(batch_size))]
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1314, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 891, in forward
  File "/home/quoniam/Work/TileGAN/gan/torch_utils/misc.py", line 72, in assert_shape
    raise AssertionError(f"Wrong number of dimensions: got {tensor.ndim}, expected {len(ref_shape)}")
AssertionError: Wrong number of dimensions: got 4, expected 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002112.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/100 [00:00<?, ?it/s][A
  7%|7         | 7/100 [00:00<00:01, 68.81it/s][A
 14%|#4        | 14/100 [00:00<00:01, 62.00it/s][A
 21%|##1       | 21/100 [00:00<00:01, 64.21it/s][A
 28%|##8       | 28/100 [00:00<00:01, 63.70it/s][A
 35%|###5      | 35/100 [00:00<00:01, 62.26it/s][A
 42%|####2     | 42/100 [00:00<00:00, 61.83it/s][A
 49%|####9     | 49/100 [00:00<00:00, 60.85it/s][A
 57%|#####6    | 57/100 [00:00<00:00, 64.78it/s][A
 64%|######4   | 64/100 [00:01<00:00, 63.01it/s][A
 71%|#######1  | 71/100 [00:01<00:00, 63.80it/s][A
 78%|#######8  | 78/100 [00:01<00:00, 63.55it/s][A
 85%|########5 | 85/100 [00:01<00:00, 62.39it/s][A
 93%|#########3| 93/100 [00:01<00:00, 65.80it/s][A
100%|##########| 100/100 [00:01<00:00, 62.50it/s][A100%|##########| 100/100 [00:01<00:00, 63.14it/s]

  0%|          | 0/100 [00:00<?, ?it/s][A  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 164, in vis
    misc.save_npys(latents, pattern_of("latents-z", step, "npy"), verbose, idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 61, in save_npys
    save_npy(npy, path % (offset + i))
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 53, in save_npy
    np.save(f, mat)
  File "<__array_function__ internals>", line 6, in save
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/npyio.py", line 528, in save
    arr = np.asanyarray(arr)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/tensor.py", line 621, in __array__
    return self.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002112.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/100 [00:00<?, ?it/s][A
  8%|8         | 8/100 [00:00<00:01, 63.93it/s][A
 15%|#5        | 15/100 [00:00<00:01, 65.89it/s][A
 22%|##2       | 22/100 [00:00<00:01, 66.03it/s][A
 29%|##9       | 29/100 [00:00<00:01, 63.66it/s][A
 36%|###6      | 36/100 [00:00<00:01, 62.25it/s][A
 43%|####3     | 43/100 [00:00<00:00, 63.48it/s][A
 50%|#####     | 50/100 [00:00<00:00, 64.61it/s][A
 57%|#####6    | 57/100 [00:00<00:00, 64.93it/s][A
 64%|######4   | 64/100 [00:00<00:00, 65.95it/s][A
 71%|#######1  | 71/100 [00:01<00:00, 66.05it/s][A
 78%|#######8  | 78/100 [00:01<00:00, 62.39it/s][A
 85%|########5 | 85/100 [00:01<00:00, 60.56it/s][A
 92%|#########2| 92/100 [00:01<00:00, 62.83it/s][A
 99%|#########9| 99/100 [00:01<00:00, 63.28it/s][A100%|##########| 100/100 [00:01<00:00, 63.75it/s]

  0%|          | 0/100 [00:00<?, ?it/s][A100%|##########| 100/100 [00:00<00:00, 7865.70it/s]

  0%|          | 0/100 [00:00<?, ?it/s][A  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 165, in vis
    misc.save_npys(wlatents, pattern_of("latents-w", step, "npy"), verbose, idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 63, in save_npys
    save_npy(npy, path % (offset + i))
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 53, in save_npy
    mat = mat.cpu().numpy()
AttributeError: 'numpy.ndarray' object has no attribute 'cpu'
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002112.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Run evaluation...
Evaluation: computing dataset features items 999  /999 (100.00%) time 7s           ms/item 7.19Evaluation: computing generator features items 1024 /50000 (2.05%) time 36s          ms/item 35.06Evaluation: computing generator features items 2048 /50000 (4.10%) time 1m 12s       ms/item 35.36Evaluation: computing generator features items 3072 /50000 (6.14%) time 1m 49s       ms/item 35.59Evaluation: computing generator features items 4096 /50000 (8.19%) time 2m 25s       ms/item 36.06Evaluation: computing generator features items 5120 /50000 (10.24%) time 3m 02s       ms/item 35.91Evaluation: computing generator features items 6144 /50000 (12.29%) time 3m 39s       ms/item 36.28Evaluation: computing generator features items 7168 /50000 (14.34%) time 4m 16s       ms/item 36.00Evaluation: computing generator features items 8192 /50000 (16.38%) time 4m 54s       ms/item 36.45Evaluation: computing generator features items 9216 /50000 (18.43%) time 5m 31s       ms/item 36.38Evaluation: computing generator features items 10240/50000 (20.48%) time 6m 08s       ms/item 36.29Evaluation: computing generator features items 11264/50000 (22.53%) time 6m 45s       ms/item 36.33Evaluation: computing generator features items 12288/50000 (24.58%) time 7m 22s       ms/item 36.19Evaluation: computing generator features items 13312/50000 (26.62%) time 8m 00s       ms/item 36.48Evaluation: computing generator features items 14336/50000 (28.67%) time 8m 37s       ms/item 36.24Evaluation: computing generator features items 15360/50000 (30.72%) time 9m 14s       ms/item 36.22Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 356, in training_loop
    evaluate(Gs, resume_pkl, metrics, eval_images_num, dataset_args, num_gpus, rank, device, log)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 227, in evaluate
    progress = metric_utils.ProgressMonitor(verbose = log))
  File "/home/quoniam/Work/TileGAN/gan/metrics/metric_main.py", line 39, in compute_metric
    results = _metric_dict[metric](opts)
  File "/home/quoniam/Work/TileGAN/gan/metrics/metric_main.py", line 97, in _fid
    fid = frechet_inception_distance.compute_fid(opts)
  File "/home/quoniam/Work/TileGAN/gan/metrics/frechet_inception_distance.py", line 18, in compute_fid
    rel_lo = 0, rel_hi = 1, capture_mean_cov = True).get_mean_cov()
  File "/home/quoniam/Work/TileGAN/gan/metrics/metric_utils.py", line 255, in compute_feature_stats_for_generator
    images.append(run_generator(z, c))
  File "/home/quoniam/Work/TileGAN/gan/metrics/metric_utils.py", line 233, in run_generator
    img = G(z = z, c = c)[0]
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1319, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1259, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 1155, in forward
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 246, in forward
  File "/home/quoniam/Work/TileGAN/gan/torch_utils/misc.py", line 89, in decorator
    return fn(*args, **kwargs)
  File "/home/quoniam/Work/TileGAN/gan/torch_utils/ops/conv2d_resample.py", line 106, in conv2d_resample
    x = _conv2d_wrapper(x=x, w=w, groups=groups, flip_weight=flip_weight)
  File "/home/quoniam/Work/TileGAN/gan/torch_utils/ops/conv2d_resample.py", line 28, in _conv2d_wrapper
    w = w.flip([2, 3])
KeyboardInterrupt
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
Setting up PyTorch plugin "bias_act_plugin"... Done.
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       

torch.Size([4, 3, 256, 256])
torch.Size([128, 3, 1, 1])
torch.Size([4, 4])
torch.Size([128, 3, 1, 1])
torch.Size([256, 128, 1, 1])
torch.Size([4, 4])
torch.Size([256, 128, 1, 1])
torch.Size([128, 128, 3, 3])
torch.Size([4, 4])
torch.Size([128, 128, 3, 3])
torch.Size([256, 128, 3, 3])
torch.Size([4, 4])
torch.Size([256, 128, 3, 3])
torch.Size([512, 256, 1, 1])
torch.Size([4, 4])
torch.Size([512, 256, 1, 1])
torch.Size([256, 256, 3, 3])
torch.Size([4, 4])
torch.Size([256, 256, 3, 3])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([512, 256, 3, 3])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 512, 3, 3])
torch.Size([4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([512, 513, 3, 3])
torch.Size([4, 4])
torch.Size([512, 513, 3, 3])

Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
torch.Size([4, 17, 32])
torch.Size([4, 16])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([64, 32])
torch.Size([16, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 15, 32])
torch.Size([4, 17, 1, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 16, 512])
torch.Size([16, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 4, 4])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 4, 4])
torch.Size([4, 512])
torch.Size([4, 512, 4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 64, 512])
torch.Size([64, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 8, 8])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 8, 8])
torch.Size([4, 512])
torch.Size([4, 512, 8, 8])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 256, 512])
torch.Size([256, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 16, 16])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 16, 16])
torch.Size([4, 512])
torch.Size([4, 512, 16, 16])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 1024, 512])
torch.Size([1024, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 1, 1])
torch.Size([4, 4])
torch.Size([512, 512, 1, 1])
torch.Size([4, 512, 32, 32])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 32, 32])
torch.Size([4, 512])
torch.Size([4, 512, 32, 32])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 512, 64, 64])
torch.Size([512, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 512, 3, 3])
torch.Size([4, 4096, 512])
torch.Size([4096, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 2, 32])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 1, 1])
torch.Size([4, 4])
torch.Size([256, 512, 1, 1])
torch.Size([4, 512, 64, 64])
torch.Size([256, 512, 3, 3])
torch.Size([4, 512, 64, 64])
torch.Size([4, 512])
torch.Size([4, 512, 64, 64])
torch.Size([1024, 512, 3, 3])
torch.Size([4, 4])
torch.Size([2048, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([2, 2])
torch.Size([4, 256, 128, 128])
torch.Size([256, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 256, 3, 3])
torch.Size([4, 16384, 256])
torch.Size([16384, 32])
torch.Size([4, 16, 32])
torch.Size([16, 32])
torch.Size([4, 17, 4, 32])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 1, 1])
torch.Size([4, 4])
torch.Size([128, 256, 1, 1])
torch.Size([4, 256, 128, 128])
torch.Size([128, 256, 3, 3])
torch.Size([4, 256, 128, 128])
torch.Size([4, 256])
torch.Size([4, 256, 128, 128])
torch.Size([512, 256, 3, 3])
torch.Size([4, 4])
torch.Size([1024, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([128, 128, 3, 3])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([512, 128, 3, 3])
torch.Size([4, 4])
torch.Size([512, 128, 3, 3])
torch.Size([3, 128, 1, 1])
torch.Size([4, 128, 256, 256])
torch.Size([4, 128])
torch.Size([4, 128, 256, 256])
torch.Size([12, 128, 1, 1])
torch.Size([12, 128, 1, 1])
torch.Size([64])
torch.Size([32])
torch.Size([32])
torch.Size([16])
torch.Size([16])
torch.Size([8])
torch.Size([8])
torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 2])
torch.Size([2, 2])
100%|##########| 1/1 [00:07<00:00,  7.36s/it]100%|##########| 1/1 [00:07<00:00,  7.36s/it]
Visualizations Completed!
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:07<00:00,  7.29s/it]100%|##########| 1/1 [00:07<00:00,  7.29s/it]
Visualizations Completed!
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]100%|##########| 1/1 [00:07<00:00,  7.30s/it]100%|##########| 1/1 [00:07<00:00,  7.31s/it]
Visualizations Completed!
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]ok
  0%|          | 0/1 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 192, in vis
    hmap = np.sum(pallete * hmap, axis = 1)
UnboundLocalError: local variable 'pallete' referenced before assignment
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 170, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 170, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 170, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A  0%|          | 0/32 [00:00<?, ?it/s]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 164, in vis
    misc.save_npys(latents, pattern_of("latents-z", step, "npy"), verbose, idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 63, in save_npys
    save_npy(npy, path % (offset + i))
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 53, in save_npy
    mat = mat.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2344.09it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A  0%|          | 0/32 [00:00<?, ?it/s]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 165, in vis
    misc.save_npys(wlatents, pattern_of("latents-w", step, "npy"), verbose, idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 63, in save_npys
    save_npy(npy, path % (offset + i))
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 53, in save_npy
    mat = mat.cpu().numpy()
AttributeError: 'numpy.ndarray' object has no attribute 'cpu'
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A  0%|          | 0/32 [00:00<?, ?it/s]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 164, in vis
    misc.save_npys(latents, pattern_of("latents-z", step, "npy"), verbose, idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 63, in save_npys
    save_npy(npy, path % (offset + i))
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 53, in save_npy
    mat = mat.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][Atensor([[-2.0702e+00,  3.9644e-01, -2.1935e+00, -7.5795e-01, -1.6496e-01,
          1.2697e-01, -4.9211e-01,  4.8031e-01, -2.1382e+00, -6.6522e-01,
          1.1264e+00, -6.6942e-01,  1.1251e+00, -2.0074e+00,  1.8077e+00,
         -5.6230e-01, -1.6375e+00, -3.9855e-01,  8.2695e-01,  6.5121e-01,
         -1.9775e+00, -1.0686e+00,  6.4483e-01,  1.6635e+00, -1.5279e+00,
         -6.3964e-01, -1.1406e-01,  1.3538e+00,  2.4777e-01, -7.4259e-01,
         -1.5628e+00, -8.1489e-01],
        [-4.2014e-01, -2.0818e+00,  2.2428e+00,  5.0860e-02,  1.0491e+00,
         -2.0655e+00,  9.3360e-01, -6.5423e-01, -7.9213e-02,  1.0951e+00,
          3.3411e+00,  2.0829e-02,  6.9628e-01, -1.5386e+00, -1.6186e+00,
         -1.0775e+00,  8.4396e-01, -1.1905e+00, -1.0354e+00,  3.9296e-01,
         -1.2424e+00,  1.1594e-01, -1.9460e+00, -6.1525e-01,  1.6019e+00,
          9.3399e-01, -1.0583e+00, -1.0902e+00, -3.1482e-01, -3.9290e-01,
         -3.2102e-02, -7.8144e-01],
        [-1.4653e+00,  1.0685e-01, -1.8953e-01,  1.0862e+00,  3.4260e-01,
          4.2734e-02,  5.7370e-01,  5.5032e-01,  5.3053e-01,  9.5548e-01,
          7.4734e-01,  1.8692e-01,  8.5704e-01, -9.9103e-01, -1.8810e+00,
         -9.4651e-02,  2.1274e+00, -3.4250e-01, -7.7832e-01, -1.6764e-01,
          2.8204e-01,  1.6692e+00, -1.7933e+00, -5.5246e-01,  5.0841e-01,
         -7.4816e-01, -2.3881e-01,  8.3029e-01, -8.6147e-01,  2.0035e+00,
          1.4834e-01, -1.3108e+00],
        [ 1.0038e+00,  7.2728e-01,  7.0315e-01, -1.9889e+00, -4.4514e-01,
          1.2806e+00, -1.0718e+00, -2.5387e-01,  6.3295e-01,  1.0416e+00,
          1.5281e+00, -1.3976e+00, -7.5526e-01,  9.1062e-01,  3.6830e-01,
          4.1155e-01,  8.8007e-01, -9.0252e-01, -1.1464e+00, -1.2146e+00,
         -1.4615e-01, -1.9677e+00, -1.8643e+00, -3.8867e-01, -1.1701e+00,
          1.4619e+00, -2.7823e-01,  4.2237e-01, -2.6028e+00, -4.1622e+00,
         -3.6310e-01, -1.9883e-01],
        [ 3.0349e-01,  3.2484e-01,  1.4826e+00, -2.5058e-01,  5.2401e-01,
         -1.2420e+00,  6.1597e-01, -1.5518e+00,  1.0807e+00,  2.2208e+00,
          1.5400e+00, -1.2927e+00, -1.8642e-01,  4.8459e-01, -1.5015e+00,
         -2.1149e-01,  1.5899e+00,  4.7421e-01,  1.3184e+00,  1.0428e+00,
          1.3439e-01,  4.2100e-01, -2.1530e+00, -5.7995e-03,  1.6960e-01,
         -2.8599e-01, -6.8340e-03,  1.4037e+00, -1.3842e+00,  2.3235e+00,
          9.1483e-01, -4.4556e-01],
        [ 3.8347e-01,  6.8268e-01,  2.1517e-01, -1.1415e+00,  9.3499e-01,
         -7.3689e-01,  8.5201e-01, -3.4123e-01,  1.5018e+00,  4.1892e-01,
          2.4088e-01,  1.6796e+00,  8.9196e-01, -6.3770e-01, -1.5930e+00,
          1.3307e+00, -1.0720e+00,  7.4392e-01, -1.5355e+00, -1.6373e+00,
          1.4148e+00,  8.1842e-01,  1.8006e-01, -7.5097e-01,  1.1402e+00,
          3.9545e-01, -2.6146e+00, -5.1612e-01, -1.6937e-01,  5.1721e-01,
          3.4364e-01, -1.4160e+00],
        [ 9.8160e-01,  1.0330e+00, -1.3352e+00,  1.4912e-01,  1.7725e-02,
          2.3196e-01,  1.2608e+00,  1.7312e-02,  4.1096e-01, -6.4737e-02,
         -8.3054e-01, -6.0261e-01, -1.1636e+00, -3.3255e-01,  3.7450e-02,
         -5.0705e-01, -5.9213e-02, -1.0389e+00,  5.5579e-01, -6.8690e-01,
          1.6566e+00, -8.5673e-01,  4.7322e-01, -3.7559e-01,  1.2787e-01,
         -3.5529e-02, -8.5493e-02,  7.0467e-01, -7.1331e-01, -1.0057e+00,
          7.3178e-01, -2.6421e-01],
        [-1.3948e+00,  1.9210e-01, -1.7109e+00,  1.2109e+00,  8.6550e-01,
          5.6124e-01, -1.7448e+00,  5.8244e-01, -2.1979e-01,  6.7816e-02,
          7.6930e-01,  1.1513e-01, -4.2157e-02,  5.4304e-01,  1.6052e+00,
         -5.9968e-01,  8.2408e-02,  1.7533e+00,  9.5411e-01,  2.0507e+00,
         -1.0706e-01, -2.1828e+00, -9.2686e-01, -1.7501e-01,  2.4790e+00,
          3.7068e-01, -1.2757e-01, -2.7630e+00, -1.3011e+00, -8.1059e-03,
         -9.9569e-02, -6.6753e-01],
        [ 3.4134e-01, -7.8792e-01, -1.1628e+00,  9.1906e-01, -7.9557e-01,
         -6.6908e-01, -3.6007e-01, -1.2920e+00,  1.5563e-01, -5.2858e-01,
          5.9627e-01, -1.1290e+00,  9.2798e-01, -8.9076e-01,  1.3457e+00,
          1.4501e+00,  2.1626e+00, -9.1456e-01, -2.9754e-03, -1.9573e+00,
          1.2084e+00,  1.6412e+00,  2.1594e-01,  1.3080e+00,  1.8790e+00,
          5.6304e-01, -9.8907e-01, -5.3687e-01,  7.2811e-02,  3.6042e-01,
         -3.2212e-01,  3.4002e-01],
        [ 6.8631e-01, -6.8785e-01,  1.8387e+00,  5.9867e-01, -6.5957e-01,
          7.9377e-01,  9.7733e-01,  1.2672e-01,  3.4386e-01,  8.9607e-01,
          5.4352e-01, -1.9247e+00, -1.4817e+00,  1.6803e+00, -2.7856e-01,
          2.4418e+00, -2.4711e+00, -2.2324e-01, -4.2139e-01,  7.3328e-01,
         -7.2891e-02, -1.9333e-01, -7.7986e-01, -2.0830e+00, -6.2299e-01,
          6.7856e-01,  4.6628e-01, -2.9752e-01, -9.1157e-01, -3.9486e-01,
          2.2186e-01, -8.1363e-01],
        [-2.8312e-01, -1.3758e+00, -2.1684e-01, -2.5180e-01, -3.8537e-01,
          4.8470e-01, -1.1188e-01, -1.7896e-01, -1.3992e-02, -2.8371e+00,
          1.4998e-01,  8.5231e-01,  4.4773e-01, -1.7301e+00,  8.7433e-01,
          1.3895e+00,  4.4273e-01, -1.3367e+00,  7.0596e-01,  2.5098e-01,
         -1.4677e+00,  6.1610e-01, -2.1144e+00, -2.3385e-01, -4.9719e-01,
          1.8660e+00,  7.6695e-01,  1.4698e+00, -8.5123e-01,  4.8042e-01,
          1.2461e+00, -9.1584e-01],
        [-7.4473e-01, -7.3497e-01,  9.7743e-01, -1.6790e+00,  2.2274e-01,
         -2.2446e-01,  3.9718e-01, -9.4353e-01,  1.7828e-01, -1.5828e-02,
          3.3147e-01,  2.7128e-01,  2.0982e+00, -1.2238e+00, -1.5611e-01,
         -1.5294e-01, -6.4548e-01,  5.7892e-01, -6.2799e-01, -2.6709e-01,
          1.4546e+00,  1.3702e+00, -4.1494e-01,  9.6203e-01,  1.2918e+00,
         -7.0183e-01, -2.4260e-01,  1.9132e+00,  9.3211e-01, -3.6220e-01,
          1.6973e+00, -4.0230e-02],
        [ 1.5516e+00,  2.4464e-01,  8.9568e-01, -7.5778e-01,  9.3644e-01,
         -1.2479e+00,  5.4880e-01, -1.1639e+00,  1.3389e+00,  4.5012e-01,
         -1.8155e-01,  4.5334e-01, -3.1752e-01, -1.4990e+00, -6.4565e-02,
          8.5147e-01,  2.8195e+00, -4.6786e-01,  1.3108e+00, -6.5452e-01,
         -5.9401e-01,  2.4205e+00, -1.5023e+00, -1.2826e+00, -7.0483e-01,
         -8.1479e-01, -1.8034e+00, -4.3253e-01,  1.2864e+00, -1.0689e+00,
         -7.9600e-01, -1.5411e+00],
        [ 3.0821e-01,  1.5546e+00, -5.5987e-01,  1.3700e+00,  7.4818e-02,
          1.6981e+00,  1.0028e+00,  1.0322e+00,  2.0161e-01,  1.7872e+00,
          8.8153e-02,  3.2716e-01, -4.6041e-01, -1.8747e+00,  1.9304e+00,
         -2.1513e+00,  1.3853e+00, -6.7189e-01, -8.7391e-01, -1.1562e+00,
          2.1563e+00,  5.3726e-02,  1.1687e+00, -2.8480e-01, -1.5532e-01,
          4.4263e-01, -1.1273e+00, -1.4723e+00,  6.9758e-01,  7.8057e-01,
         -8.5333e-01, -1.9360e+00],
        [-1.7653e-02,  4.7018e-01,  3.3443e-01,  6.6867e-01, -3.9800e-01,
         -8.8061e-01,  2.0323e+00, -7.5691e-02,  1.8161e+00, -7.1798e-02,
         -2.3104e-01, -1.4094e+00, -3.4709e-01, -1.0885e+00,  1.2593e+00,
          5.2366e-01,  2.3863e+00,  2.5376e-01,  6.9674e-01,  1.0928e-01,
          2.5721e-01,  1.8674e+00,  8.7785e-01, -9.2038e-01, -1.9266e-01,
          1.7161e+00, -9.9126e-02, -6.4722e-01, -1.4628e+00, -7.0415e-01,
          3.9353e-02, -9.7722e-01],
        [-3.7857e-01, -1.8190e-01,  1.3163e+00, -1.6114e+00,  1.2193e-01,
         -2.0676e-01,  1.0547e-01,  1.2730e+00, -1.0378e+00, -2.0513e-01,
          8.4265e-01, -4.3803e-01, -6.7408e-01,  3.8959e-01, -2.0735e+00,
          1.3400e-01, -7.7036e-01,  4.2771e-01,  7.2874e-01, -6.3259e-01,
          3.7856e-01,  5.0286e-01, -2.5026e-01, -7.4550e-01,  1.0618e+00,
         -6.7451e-01, -1.0613e-01,  1.5324e+00,  3.5429e-01,  9.6087e-01,
          6.6340e-02,  2.1659e+00],
        [-3.1440e-01, -7.0959e-01, -2.7013e-01, -1.7075e+00, -8.8451e-01,
          8.7612e-01,  1.7928e+00, -7.9817e-01, -3.5613e-01,  4.9641e-01,
         -8.5374e-02, -2.1501e-01, -1.8991e+00, -5.9757e-01, -1.0505e+00,
         -5.3757e-02, -1.7188e-01, -1.7141e+00,  7.6503e-02,  1.0479e+00,
          8.6191e-01,  1.8911e-01, -3.4361e-01,  3.0865e-01, -9.8527e-01,
          1.1188e+00, -4.0871e-01, -3.0112e-02,  7.6027e-01,  1.0529e+00,
         -5.3538e-01,  1.6170e+00]], device='cuda:0')
  0%|          | 0/32 [00:00<?, ?it/s]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 164, in vis
    misc.save_npys(latents, pattern_of("latents-z", step, "npy"), verbose, idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 63, in save_npys
    save_npy(npy, path % (offset + i))
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 53, in save_npy
    mat = mat.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][Atensor([[ 1.8713e-01, -1.1945e+00, -3.9038e-01, -8.5473e-01,  6.5956e-01,
         -7.6064e-01,  7.2130e-01,  6.8287e-01,  8.1331e-01,  1.0137e+00,
         -8.1248e-01,  4.8648e-01,  5.9599e-01,  2.1140e+00, -1.9223e-01,
         -1.0254e+00,  4.3309e-01, -1.3032e+00, -7.0757e-01,  2.0512e-01,
          1.0076e+00,  7.5795e-01, -4.7012e-01, -2.7741e-01,  9.4551e-01,
         -2.1161e-02,  1.1186e+00, -1.6512e+00, -9.8960e-01,  2.0320e-01,
          3.0758e-01, -8.2740e-01],
        [-8.1042e-01,  2.9933e-01, -2.6626e+00,  1.7609e+00, -7.7073e-01,
         -1.6067e+00, -6.7251e-01, -3.8628e-01,  1.3190e+00, -8.6561e-01,
          3.0520e-01, -5.1127e-01, -5.1267e-01, -7.5054e-01,  3.0768e-01,
         -1.5345e-01, -1.7250e+00,  1.6823e-01,  8.8429e-01,  6.0960e-02,
         -1.0495e+00,  5.0361e-01,  2.5115e-01, -1.1743e+00, -4.3063e-01,
          9.5702e-01,  1.0835e+00,  1.5303e+00, -8.5925e-01, -3.0807e-03,
          2.2856e-01, -2.7410e-01],
        [-7.6168e-01, -5.2911e-01,  4.6063e-01, -5.5443e-01, -1.2053e+00,
          1.0019e+00,  2.3898e-01,  9.8026e-01,  2.8938e-01, -5.4080e-01,
          1.1726e-01,  6.8242e-01,  8.2764e-01,  5.6142e-01,  1.3473e+00,
          5.0280e-01, -5.5351e-01,  9.9556e-02, -8.6722e-01, -4.8310e-02,
         -8.8874e-01,  1.8178e+00,  4.5314e-01,  2.7572e+00, -4.0792e-01,
          6.1081e-01, -1.0397e+00,  5.0884e-01, -2.8682e-01, -1.1388e-01,
         -1.5193e+00, -4.6708e-01],
        [ 7.8289e-02, -1.4410e+00, -7.1747e-01,  7.5669e-01,  9.2174e-01,
         -3.1891e-01, -3.7365e-01, -1.1906e+00,  1.8256e+00, -1.1558e+00,
          1.9155e+00, -1.1470e+00,  6.0613e-01,  6.7816e-01,  1.8393e-01,
          6.1939e-01, -1.4055e+00,  4.8775e-01, -2.4384e-01, -2.3026e+00,
         -4.3943e-01,  9.1689e-01,  4.9576e-01,  9.2312e-02, -7.7238e-01,
         -2.9656e-01, -2.3034e-01,  1.1478e+00, -1.9076e-01, -9.4912e-01,
          7.9536e-02,  1.5069e-01],
        [ 4.5422e-02,  4.4430e-01, -7.7304e-02, -2.4642e-01, -1.0827e+00,
         -8.1210e-01, -2.9271e-01,  5.0128e-01, -2.5221e-01,  7.2488e-01,
          7.0672e-03,  6.4439e-01, -5.4198e-01, -1.0940e+00, -2.4619e-01,
          4.0643e-01, -1.1282e+00, -9.5920e-01,  3.4546e-01,  4.8886e-01,
          7.2744e-01, -2.1583e+00, -1.5100e+00,  1.9004e+00,  2.3954e-01,
         -6.2124e-01,  2.8682e-01,  3.1517e-01, -1.6610e+00, -2.0286e+00,
          8.4940e-01,  1.9385e+00],
        [ 4.5656e-01, -3.4443e-01, -2.5739e-01,  1.4803e+00, -6.9134e-01,
          7.2417e-01,  2.6564e-01,  8.5112e-01,  2.4331e-01, -8.0552e-02,
         -2.3092e-02,  1.3079e+00,  1.0343e-02, -3.0831e-01,  8.6463e-02,
         -9.9577e-01, -6.3124e-01,  2.7177e-01,  7.9578e-01, -3.1596e-01,
         -2.1413e-01,  2.4459e-01,  4.7884e-01, -8.4421e-02,  1.5580e+00,
          5.4449e-01, -7.1751e-01, -4.0449e-01,  5.0984e-01, -4.4867e-01,
         -9.8571e-01,  1.5713e+00],
        [ 8.5881e-01, -1.0007e-01, -1.9893e+00, -4.1284e-02,  3.3314e-01,
          1.8071e+00, -1.1188e+00,  2.8722e-01, -3.0634e-01, -4.7464e-01,
         -1.9000e-01, -3.8977e-01,  1.2333e+00, -5.7692e-01, -2.6344e-01,
         -6.2667e-03, -3.2700e-01,  1.5100e+00,  1.8224e-01, -4.6387e-01,
          3.8995e-01,  1.3828e-01, -1.5725e+00, -6.1049e-02,  4.5289e-01,
         -4.0000e-01,  4.7483e-01, -6.3812e-01, -9.9504e-01, -2.7228e-01,
         -1.1924e+00,  7.1375e-02],
        [-1.3200e+00, -8.0627e-01, -9.8460e-01,  7.6632e-01,  5.2732e-01,
         -1.6756e+00,  1.5638e+00,  1.2901e+00,  2.3537e-01, -1.4255e+00,
          1.0698e+00,  4.3965e-02, -1.2095e+00, -9.1197e-02, -1.0562e+00,
          2.6929e-01, -3.2015e-02, -5.2730e-01, -3.6500e-01, -1.5716e+00,
         -2.1919e+00, -2.2107e-01,  1.0671e+00, -1.4645e+00,  2.1612e+00,
         -3.6559e-01,  6.8761e-01,  1.1352e+00,  1.5022e-01, -6.3401e-01,
         -8.6767e-01, -1.4303e+00],
        [ 3.4947e-01, -9.7340e-01, -1.0501e+00,  6.0887e-02,  1.1122e+00,
         -4.9095e-01, -1.6499e+00,  1.1046e+00, -1.9681e+00, -4.7713e-01,
          8.5433e-01,  5.5241e-01,  4.0706e-01,  1.2305e+00, -7.0607e-01,
          8.7100e-01, -3.5248e-01,  7.3014e-01,  4.1619e-01, -1.8312e-01,
         -4.9378e-01,  1.1429e+00,  5.7109e-02, -2.5739e-01,  2.0963e+00,
         -1.0038e+00,  2.1028e-01, -1.6120e+00, -1.3774e+00, -4.5950e-01,
          3.7436e-01,  4.7306e-01],
        [-3.5534e-01,  4.6922e-01,  9.2374e-02,  9.1116e-01,  1.1439e+00,
          1.9616e+00, -1.3492e+00, -3.9171e-01,  5.2053e-01, -2.1479e+00,
         -1.2516e-01, -4.7176e-01,  4.0139e-01,  1.2901e+00, -1.3711e+00,
         -1.7638e-01,  1.4988e-01,  1.7293e-01, -1.7352e+00, -4.9256e-01,
         -3.6797e-02, -2.0669e+00,  1.3426e+00,  7.4242e-01,  1.9565e-01,
          2.5400e-01,  1.0908e+00,  2.3572e-01, -5.9010e-01, -1.4999e+00,
         -7.7446e-01, -1.2407e+00],
        [ 4.3079e-01,  8.8393e-01, -7.6465e-01, -1.1173e+00, -3.5513e-01,
          9.7301e-01,  1.0905e+00, -4.9201e-01,  3.6548e-01, -1.6431e+00,
         -2.2277e-01, -2.2887e-01, -7.6535e-01, -9.6357e-01,  1.8225e-01,
          9.4060e-02, -3.9540e-01,  2.4874e+00,  1.2930e+00,  2.5969e+00,
         -3.3641e-01,  1.6123e+00,  5.7195e-01,  2.0943e-01, -2.0644e+00,
          6.9161e-01, -6.5078e-01, -9.8658e-01,  4.4342e-01,  1.1284e-01,
         -3.2120e-01,  4.2191e-01],
        [-1.2252e+00,  1.2518e+00, -5.7030e-02,  8.8480e-01, -1.9853e-01,
         -4.6184e-01,  2.0476e-01, -2.1224e-02,  1.0595e+00, -2.3813e+00,
         -1.3093e+00, -6.2686e-01,  8.8959e-01,  2.6387e+00, -1.4281e+00,
          1.8410e+00, -1.6456e-01, -1.1710e-01, -6.6608e-01,  5.6282e-01,
          5.4760e-01, -1.0698e+00, -1.2589e+00,  1.0807e+00,  6.5631e-01,
          1.4480e-01,  1.1485e+00, -2.0114e-01,  5.2195e-01, -2.1264e-01,
          1.2250e+00, -5.1767e-01],
        [ 6.1184e-01, -4.5756e-01,  1.7077e+00,  2.6967e-01, -5.4988e-01,
         -6.0269e-02, -2.7597e-01, -1.3984e+00,  2.3998e+00,  1.7664e+00,
         -1.1100e+00, -1.5374e+00,  1.9658e-01, -1.2705e+00, -8.0369e-01,
          2.8182e-01,  1.5186e+00,  1.0160e+00,  7.0827e-01, -2.6028e-01,
         -1.8410e-01, -1.7061e+00,  4.6738e-02, -8.2709e-01, -5.4137e-02,
          2.7182e-02,  1.2813e+00,  8.0277e-01,  1.4719e-01,  7.1027e-01,
          5.1663e-01, -7.3696e-03],
        [-3.1606e-01,  1.4517e-01,  1.5707e+00, -8.0696e-01, -6.0574e-01,
          4.1990e-01,  1.1788e+00, -5.5924e-02,  8.6176e-01,  6.3585e-01,
          1.5529e+00, -4.0807e-01,  4.4099e-01, -1.0899e+00, -9.1117e-01,
         -1.1620e+00, -4.0176e-01,  4.8482e-01, -3.7346e-01, -1.1011e+00,
          6.2858e-01, -1.3839e+00,  2.1883e-01,  4.1720e-01, -8.3071e-02,
         -3.7502e-01,  1.0755e+00, -4.3463e-01, -9.3419e-01,  1.5252e+00,
          3.9985e-01,  3.8264e-01],
        [-1.1516e+00, -1.7483e+00, -1.4203e-01, -4.4002e-01, -7.0176e-03,
         -1.7266e-01,  5.3216e-01, -3.2244e-02, -1.7406e+00,  1.0085e+00,
          3.8460e-01,  1.5147e-01,  2.1291e+00, -1.4129e+00, -7.1714e-01,
          1.0028e+00, -1.4583e-01,  3.2144e+00,  2.0255e-01, -6.5328e-01,
         -2.0883e-01,  2.4289e-01, -1.3853e+00, -5.0350e-01, -2.0549e+00,
          2.1639e+00,  1.3537e+00, -3.7412e-01,  3.4730e-01,  2.1949e-01,
          6.4630e-01,  2.1191e+00],
        [-3.4308e-01,  6.5627e-01, -1.4932e-01,  9.3198e-01,  7.3292e-01,
          6.1554e-01, -6.4092e-02, -2.0834e+00,  7.0278e-01,  5.8633e-01,
         -3.2362e-01,  9.8644e-01, -7.6705e-01,  3.4521e-01, -2.2082e-01,
          2.0427e-01,  6.4461e-01,  1.5188e-01, -3.3803e-01, -4.5509e-01,
          2.1556e+00,  5.9018e-01,  1.2927e-01,  2.4215e-01,  2.3705e-01,
         -1.6327e+00, -9.6899e-02,  2.5261e-01, -2.2473e-01,  7.8843e-01,
         -4.7151e-01, -1.4278e+00],
        [ 1.4520e+00, -7.4420e-01, -8.6921e-01,  3.1371e-01, -6.7242e-01,
         -4.3328e-01,  1.0479e+00,  1.0551e+00,  6.6160e-01,  1.6412e-02,
          5.7427e-02,  1.2666e+00, -6.7229e-01,  2.1863e+00,  2.1562e+00,
          4.7634e-01, -1.1652e+00, -1.9102e+00, -7.2812e-01, -2.5104e-01,
          1.6693e+00,  1.4228e+00,  1.2914e+00,  9.8858e-01,  3.1749e-01,
          2.5948e-01, -3.5146e-01, -1.7796e+00, -2.1817e+00, -1.0415e+00,
         -1.4955e+00, -3.9683e-01]], device='cuda:0')
tensor([[ 0.6149,  0.3668,  0.0979, -0.1200, -1.0282, -0.2937, -0.1111,  1.1227,
         -0.7472, -0.7867, -1.3390, -1.6025, -0.3488,  0.4351,  0.6123,  0.1726,
         -1.5557, -0.1274, -2.0807,  1.3363, -0.0986, -1.8992,  1.5701,  1.1225,
         -1.7368, -1.1250, -0.6346, -1.6926,  0.8385, -0.2533,  0.3249, -0.4346],
        [-2.6208,  0.3504,  1.3282,  0.2636, -0.9213,  0.0216, -0.5672,  1.5717,
         -0.3570, -1.2622, -0.3297, -0.4736,  0.3802,  0.5161, -0.5779, -0.8300,
          1.7410, -1.6869,  0.3839,  0.6430,  1.3216,  3.4090,  1.6638,  0.1059,
         -0.0039, -1.6058,  0.1468,  0.5295, -0.8487, -0.5059, -1.1962, -0.4623],
        [ 1.2011, -0.3163,  0.4503, -0.1799, -0.4281, -0.5529,  0.9572, -1.0273,
          0.0521, -1.5702, -0.2679,  2.6397,  0.2394, -0.4614,  1.4080, -0.9582,
         -1.2213,  0.2196, -1.0853, -1.0781, -0.8728,  1.1266,  1.1580,  1.1186,
          0.6882, -0.4606, -3.3110,  0.3408,  0.9074,  0.3750, -0.4568, -1.4745],
        [-1.0378, -0.2016, -0.2909,  2.0433, -0.4270,  0.1370, -0.8136,  0.6350,
         -0.8350,  0.2513,  1.9273,  0.2108, -0.0720,  0.1803,  0.4304, -0.8834,
          2.9727,  0.9909,  0.2967, -0.7522, -0.7158,  0.0182,  0.3103,  0.0706,
         -2.0056,  0.1107,  0.5902,  0.5364,  1.0735, -0.3710,  0.2297,  0.1276],
        [ 0.0734, -0.8515, -1.2563,  0.5686,  0.7821,  1.3477,  0.3934,  1.8021,
          0.0252,  0.4713,  1.4911, -0.3647,  1.7946,  0.4834, -1.7849,  0.8488,
          0.0690,  1.6769, -0.2898,  0.3358, -0.8782, -0.1011,  1.0819,  0.7190,
          1.0291, -1.6176, -1.3257, -0.9353,  0.4834, -0.8493,  0.6465, -0.0370],
        [-0.6547,  0.1752,  0.6690, -0.4668,  1.1454, -0.7563,  0.4409,  0.3493,
          1.5891,  0.0079, -1.1364, -2.2461,  1.5411,  2.3663, -0.7544,  0.2092,
          0.4864,  0.9199, -1.5515,  0.6047,  1.7478,  0.5223, -1.3825, -1.2722,
          0.2638,  1.5266, -0.6028, -0.6051, -1.8543,  0.0916,  3.2098,  0.2813],
        [-0.2080,  1.0467, -2.2879, -1.3919, -0.7313, -1.7217, -0.0372,  0.1096,
          0.2745, -0.6172, -2.3209, -0.3291,  1.1818,  0.0941,  1.1253,  0.5710,
          1.1818,  0.6634,  0.2189, -1.1726,  0.2940, -0.6497, -0.5418,  0.9571,
         -0.2829,  0.5950, -1.4463, -0.7725,  0.9484,  1.1197, -1.1089,  1.1780],
        [-0.0606,  0.1299, -0.5047, -1.1772,  0.2354,  0.8847, -0.0575,  1.6836,
          0.1273, -0.6941,  0.2707, -2.4203, -1.1882, -0.8418, -1.0800, -2.1787,
          1.2718,  1.9911,  0.3353,  0.3604, -2.2786, -1.0881, -1.0478,  1.3497,
          0.8124,  1.2019,  1.5147,  0.0781, -1.2319, -0.5013, -0.3855, -2.1167],
        [ 1.4111,  0.7952, -1.1771, -0.1810, -0.4384, -0.5805, -0.0952, -0.3699,
          1.4821, -0.2262, -1.0031, -1.3082, -0.3308,  1.4690,  1.1407, -1.2474,
         -0.9489,  1.0512, -1.5218,  1.2379,  0.1716, -1.0842, -0.4301,  0.5968,
          0.1466,  1.0889, -0.6136, -0.5534,  1.3463,  0.1800, -0.3567,  0.7722],
        [ 0.0599,  0.8916, -0.4253, -1.3789,  0.3495,  0.7140, -0.3894,  0.6587,
         -0.5142, -1.2897, -0.3717,  0.1667, -0.5393, -0.6083,  1.4151, -1.3891,
         -1.3491,  0.1639,  0.9470,  0.0313,  0.4110,  1.1729,  0.4387, -0.0964,
         -0.1480, -0.0378, -1.6281, -0.4416, -1.2335,  0.4410, -1.9569, -0.6170],
        [ 0.1524, -1.3245,  1.0166, -1.4489,  1.2905,  0.1263, -0.7836,  0.6290,
          1.3941,  1.6113, -1.2177, -0.5484, -1.4878,  1.2762, -0.1349,  0.6170,
          1.6737, -1.9575,  0.5941, -1.3744,  0.4177,  1.4500,  1.6214,  0.7335,
         -1.0185, -0.1838, -0.4128, -0.6049,  0.7422,  0.8263,  0.2479,  0.5912],
        [-0.3218, -0.0393,  0.2418, -0.0162,  0.2489,  0.9620, -0.9505, -0.9792,
          0.0851, -1.0565, -0.1599,  1.5109, -0.7795,  0.6327,  0.0630, -0.1782,
         -0.0891, -1.6826, -1.4684, -0.6992,  0.1501,  1.2071, -1.3014, -1.4216,
          0.5588,  0.6392, -0.3857, -1.3915, -0.3124, -0.4332,  0.0527, -0.0115],
        [ 0.3060, -0.2411,  1.2355, -0.2071,  0.3639,  0.7636, -0.8918, -1.7449,
          1.7857,  0.1157,  0.3116, -0.9436,  0.6132, -1.5152, -0.3727,  0.5258,
         -0.8702,  0.5550,  1.0048,  0.5647, -0.5586, -0.2613,  1.0856,  1.3979,
         -1.9939, -0.1899,  1.6222, -0.0873,  0.7562, -0.7390, -1.7522, -0.0231],
        [-0.4365,  0.6065,  0.7542,  0.7820,  0.0497,  0.5607, -0.9108, -0.5191,
         -0.3061,  1.6541, -1.2599,  0.5636,  0.9377, -0.4208, -0.4544,  0.4915,
          1.4042, -0.8881,  0.6973,  0.0314, -0.3416,  0.5831,  0.3678,  1.6803,
          0.6932, -0.9477,  1.3250,  0.7266, -2.1178,  0.7269, -0.6162,  1.4316],
        [-0.0430, -0.0708, -0.3726, -0.2488,  0.1366, -0.2920,  0.4476, -0.8841,
         -0.2232, -0.3376,  0.1158,  1.4672,  1.1477,  0.5690,  1.4491, -0.7518,
          0.6399, -0.3346, -0.0101, -2.8945,  1.1612,  0.2101, -0.0372,  0.9724,
         -1.1880, -1.2566, -0.0688, -0.2864,  0.0809, -0.5503, -0.4425, -0.8998],
        [ 0.4359,  0.3948,  1.4567,  0.5169, -1.2056, -3.2730,  2.1448,  0.1799,
         -0.9921, -0.8128, -1.5680,  0.0604, -0.0846, -0.7469, -1.1252,  0.3106,
          0.6122, -0.6220, -0.5320, -1.1304,  0.4978,  0.9298,  0.9872, -0.6129,
         -0.6360, -0.1185,  0.6227, -2.2126,  0.1860, -0.5994,  0.6722,  0.4593],
        [-0.1922, -0.6171, -2.6957, -0.9202,  0.0920, -1.5656, -0.6708, -0.5390,
          0.4753,  0.4908, -0.1902, -0.6062,  1.3550, -0.8709,  0.5453, -0.4530,
         -0.4085, -0.7627,  0.4446,  0.4955,  1.5224, -0.7096, -0.1186,  1.3237,
          0.3662,  0.4652, -0.3823, -0.0248,  3.7254, -0.7887, -0.8548, -1.0827]],
       device='cuda:0')
tensor([[ 8.0784e-01, -9.7007e-02, -4.7088e-02, -7.7999e-01,  1.0426e+00,
         -2.1296e-01, -7.1957e-01, -2.9266e-01, -5.0334e-01, -1.0758e-01,
          4.5050e-01,  7.1993e-01, -1.0915e+00,  1.1817e+00, -1.3650e+00,
         -2.0741e+00,  1.5872e+00, -1.7134e-01, -1.8056e+00, -6.3737e-01,
         -2.2648e-01,  1.1430e+00, -1.4224e+00, -4.8846e-01,  7.7219e-01,
         -4.3786e-01,  8.0569e-01, -2.1742e+00, -1.4360e-01,  1.2310e+00,
          4.9155e-01,  2.4398e+00],
        [-1.3736e+00, -5.9797e-01,  1.4599e-01, -4.3669e-01, -7.5953e-01,
          2.8601e-01, -2.2526e-01,  2.0560e-01,  8.9170e-01,  3.8342e-01,
          1.7896e+00, -2.0359e-01,  4.4516e-01,  9.9675e-01, -7.7135e-01,
          1.8677e+00, -1.1709e+00, -1.3325e+00, -6.4150e-01, -1.1072e+00,
         -6.1145e-01,  1.6499e+00,  6.5898e-01,  1.2291e+00,  1.4237e-01,
          1.9327e-01, -6.3148e-01, -4.0778e-01,  4.5729e-01, -1.8803e+00,
          8.5433e-01,  7.8913e-01],
        [-2.4137e-01, -1.6400e+00, -6.2009e-01, -3.6885e-01,  4.2745e-01,
          1.9114e+00, -4.6485e-01, -4.2843e-01,  1.6497e+00, -9.7427e-01,
         -9.1594e-01,  1.2146e+00, -3.8395e-01, -1.1205e+00,  1.3491e+00,
         -1.1793e+00, -3.6230e-01, -1.6208e+00, -9.1552e-01, -1.1704e-01,
          9.5617e-01, -7.9677e-01, -1.3980e+00, -2.0951e-01, -1.7090e-01,
         -5.9637e-01, -3.1722e-01, -1.5100e+00, -6.8398e-01, -1.5842e+00,
         -6.7181e-01, -4.3692e-01],
        [ 1.4442e+00,  1.8290e-02,  1.3186e+00,  1.1512e+00,  1.0956e+00,
          1.7708e-01, -1.3213e+00, -1.1976e+00,  2.4572e-01,  1.1493e+00,
         -5.2059e-02,  7.3304e-01, -3.0738e-01, -1.3939e+00, -1.6021e+00,
          1.5715e+00,  1.8737e+00,  7.6146e-01,  2.0517e+00,  2.7837e-01,
          7.6456e-01,  6.3871e-01, -6.8589e-01,  2.3037e-01, -1.4841e+00,
         -2.1444e+00, -5.4591e-01,  1.1760e+00, -2.2919e+00, -2.5809e-01,
         -1.6326e+00, -5.3267e-01],
        [-8.9460e-01,  7.3176e-01,  1.9356e+00,  1.9767e+00,  5.3395e-01,
         -9.0766e-04, -2.1353e-01, -2.3717e-01, -3.2015e-01,  5.7030e-01,
         -1.3429e+00,  8.0107e-02,  3.7384e-01, -1.0146e+00,  1.1376e+00,
          1.6714e+00, -1.4504e+00, -1.2062e+00,  1.0071e-01, -2.2972e-01,
         -2.1994e-01,  1.3897e+00,  4.2907e-01,  7.0824e-01,  5.2446e-01,
          1.7421e+00,  4.9443e-01, -7.0165e-01,  2.3670e-01,  4.5541e-01,
         -1.0126e+00,  1.2938e+00],
        [ 5.8823e-01,  3.2440e-01, -1.7059e+00, -1.6104e+00,  7.3063e-01,
         -2.4098e-01, -1.9313e+00, -2.0171e-01, -1.2454e+00,  2.9377e-01,
         -2.0324e-01,  8.0675e-01,  1.2074e+00, -1.5308e+00, -2.8221e-01,
         -1.2402e+00,  1.8151e+00,  2.0527e+00,  5.9674e-02,  7.2626e-02,
         -1.1597e+00, -1.7958e+00, -2.7345e-01, -8.7567e-01, -9.4565e-01,
         -1.4574e-01, -5.1654e-01,  1.6035e-01, -3.6529e-01,  1.2640e-02,
          7.3353e-01, -9.2238e-01],
        [ 5.4379e-01,  3.8489e-01,  1.0261e+00, -2.8096e-01, -7.6273e-01,
         -6.9528e-01,  9.7803e-01, -6.3394e-01, -1.7843e+00, -4.0972e-01,
          6.4658e-01, -1.5379e-01,  6.9022e-01, -1.1797e+00,  1.8826e-01,
         -9.2861e-02,  1.0514e+00, -6.6135e-01,  3.2499e-01,  9.4205e-01,
         -3.6889e-01,  1.1609e+00, -9.1314e-01, -1.6915e+00,  1.2672e+00,
         -1.0987e+00,  9.7764e-01, -4.5802e-01, -1.3620e+00,  1.2393e+00,
          1.2654e+00,  1.3768e+00],
        [-1.6476e-02,  5.5933e-01, -1.8019e+00, -7.2160e-02, -1.9482e+00,
         -7.2560e-02, -1.7611e-01,  4.2693e-01,  5.1097e-01,  2.3228e+00,
         -3.1459e-01,  3.8010e-01, -4.9707e-01,  1.7050e-01, -1.3945e-01,
          2.2414e-01, -1.0312e+00, -4.6030e-01,  1.8825e+00,  1.3342e+00,
         -8.4763e-01, -8.2281e-01,  3.3356e-01,  7.0938e-01,  1.6349e+00,
         -9.2256e-01, -1.6503e+00, -1.7577e+00,  1.1791e+00, -2.2123e-01,
         -3.5963e-01, -4.6974e-01],
        [-5.7674e-01, -5.8176e-03, -5.2598e-02,  1.2826e+00,  4.0199e-01,
         -1.5983e+00, -2.2240e-01,  8.5847e-01,  2.8789e-01, -6.7775e-01,
          8.0951e-01, -1.3609e+00, -5.7628e-01,  3.7312e-01, -1.3913e+00,
          4.2617e-01,  1.8439e-01, -8.5166e-01,  1.6593e+00, -4.1859e-01,
          7.1355e-01,  9.7719e-01,  4.7677e-01, -2.1887e-01,  1.1833e+00,
          7.7402e-01, -1.1725e+00, -3.4336e+00,  4.1620e-01, -6.6469e-01,
         -5.6400e-01, -4.2428e-01],
        [ 2.7988e-03,  1.2189e+00, -9.2119e-01, -1.4847e+00,  1.6308e+00,
         -5.1133e-01, -7.7764e-01,  9.4136e-01,  6.9789e-01, -7.4786e-01,
          1.0342e+00,  4.1226e-01, -7.3603e-01,  6.3271e-01,  3.2149e-01,
          1.0305e+00, -2.0851e+00, -1.1406e+00,  5.4440e-01, -1.1975e-01,
         -1.0968e+00,  5.3340e-01,  1.7287e+00,  2.8467e-01,  1.1030e+00,
         -2.3608e-01, -1.1676e+00, -1.8579e+00,  3.5108e-01,  2.6679e+00,
          4.4001e-02,  7.9094e-01],
        [ 4.5791e-01,  8.2488e-01,  5.9098e-01,  9.7951e-01,  1.4259e+00,
          8.2911e-02, -1.8704e+00, -2.4685e-02, -6.8301e-01, -1.7722e-02,
         -1.6268e+00, -5.9602e-01,  8.4740e-01, -5.1467e-01, -6.9050e-01,
          7.0066e-02, -5.8612e-01, -1.0136e+00, -8.2132e-01, -1.0088e+00,
         -9.6433e-01, -5.0711e-02,  5.6411e-01, -3.1268e-01,  4.5837e-01,
         -5.0477e-01, -3.2493e-01,  6.6896e-01,  1.3719e+00,  1.1431e+00,
         -2.8163e-01,  2.7062e-02],
        [-3.4246e-01,  7.4134e-01, -1.4247e-02,  3.0388e-02,  1.5760e+00,
         -8.3815e-01,  1.4552e+00, -1.3735e+00,  9.5643e-01,  1.8439e+00,
          1.1474e+00, -2.1180e-01, -6.0653e-01,  1.4113e+00,  1.2494e-01,
         -1.3337e+00,  4.2065e-01, -7.1458e-01, -5.7335e-02,  3.8068e-02,
         -6.9862e-01, -9.5116e-01,  2.4653e-01,  1.4146e+00, -7.8016e-02,
          1.4456e-01, -1.8346e+00, -2.9012e-01, -1.4899e+00,  7.3626e-01,
          2.7706e-01,  1.0604e+00],
        [ 9.0936e-01,  3.1301e-01, -4.6410e-03, -5.3087e-01, -2.6228e-01,
          8.7812e-01,  3.3246e-01,  6.0093e-01,  7.0081e-02,  8.5448e-01,
          7.6051e-01, -1.0611e+00,  5.9678e-01,  7.1653e-01, -8.7906e-01,
         -6.0021e-01,  4.4271e-01, -3.8527e-01, -3.8777e-02, -3.0816e-01,
         -1.6937e+00,  5.4110e-01, -1.1240e+00, -1.0977e+00, -1.3204e+00,
         -3.7894e-02,  3.1639e-01, -9.6497e-01, -4.9498e-01, -2.7187e+00,
         -1.3047e+00,  8.1960e-01],
        [ 2.3132e+00, -8.2882e-01,  3.8512e-01, -2.1885e-01, -1.5334e+00,
          2.1960e+00,  5.3522e-01, -1.0443e+00,  2.6783e-01,  8.8300e-01,
          3.6087e-01, -8.3911e-01, -6.5860e-01, -2.5309e-01, -9.2236e-01,
         -6.7194e-01,  5.1522e-01,  1.2664e-02,  7.6360e-01, -5.9742e-01,
         -7.8580e-01,  3.0506e-01, -2.8291e-01,  1.6027e-01,  4.5655e-01,
          1.7730e+00, -1.4840e+00, -1.3079e+00,  3.6353e-01, -2.0840e+00,
          1.0498e+00,  3.1494e-02],
        [-4.3136e-01,  6.5149e-01,  1.0412e+00, -2.7609e-01, -4.0976e-01,
         -3.7739e-01,  1.2385e+00, -2.8197e-01, -9.9908e-01, -9.4288e-01,
         -7.0153e-01, -1.5789e-01,  4.6488e-02, -1.0304e+00, -3.8146e-01,
          6.8480e-02, -6.0134e-01, -4.6974e-01,  2.6985e+00,  1.9503e-02,
         -9.0226e-01, -9.3785e-01, -8.9254e-01,  1.2264e+00,  7.7754e-01,
         -1.2345e-01, -7.2857e-01,  6.0465e-01, -1.1161e+00,  3.0886e-01,
          8.1015e-01, -1.3617e-01],
        [ 8.1743e-01,  9.7155e-01, -1.4511e+00,  7.6214e-01, -5.6255e-02,
         -1.6306e+00,  2.2404e-01,  6.1634e-01, -7.7055e-01, -4.7397e-02,
         -4.8468e-01, -9.9110e-01, -2.4147e-01, -1.1156e+00,  8.8465e-01,
          1.0649e+00, -7.8797e-01,  5.7139e-01,  6.7178e-01,  2.8274e-01,
         -1.4916e-01, -6.4133e-01,  2.4476e+00, -1.2339e+00, -2.6259e-01,
          1.2745e+00,  9.9183e-01, -1.4400e+00, -6.1443e-01,  1.0391e-01,
          7.5125e-01,  2.5882e-01],
        [-9.4366e-01, -8.6570e-01,  7.4316e-01,  1.2131e+00, -5.6462e-01,
         -2.4662e+00, -2.8908e-01, -6.4401e-01,  3.4330e-01, -8.9363e-01,
         -2.1168e+00, -7.6253e-01,  1.9568e+00, -3.6511e-01, -1.8536e-01,
          5.3167e-01, -8.6631e-01, -9.0434e-01,  2.0236e-01, -2.1535e+00,
         -8.0961e-01, -9.6195e-01,  1.0217e+00, -5.9920e-01,  4.2082e-01,
          7.5508e-01, -3.0501e-01, -1.6378e+00, -1.3951e-01,  8.6708e-01,
          5.4562e-01, -5.8542e-01]], device='cuda:0')
tensor([[ 1.1045e+00,  3.8914e-01, -1.3592e+00, -7.9816e-01,  4.2457e-01,
         -5.1703e-01, -1.2237e+00, -9.3109e-01, -1.3505e-01,  1.1985e+00,
          2.1473e-01,  1.0506e+00,  2.6139e+00, -3.7787e-01,  7.0395e-01,
          1.4211e+00,  1.0200e+00,  1.9152e-01, -2.5156e-01, -4.7638e-01,
         -7.5546e-01, -2.0229e+00, -1.0147e+00,  2.1925e-01, -3.0805e-01,
          1.4909e-01, -2.0024e+00,  4.5864e-01,  3.9844e-01, -4.5195e-01,
          1.1210e+00,  8.7596e-01],
        [ 1.0329e+00,  4.3968e-01, -3.3341e-01,  1.4137e+00, -6.3721e-01,
         -1.4647e+00,  1.2676e-01,  3.3303e-01,  1.0129e-01, -1.9452e+00,
          7.6938e-01, -2.2084e+00,  5.9560e-01,  1.3074e+00, -4.7134e-01,
         -2.8853e-01,  4.1916e-01,  8.3977e-01,  3.1708e-01,  8.1920e-01,
         -3.8885e-01,  4.7735e-01, -2.7213e-01, -9.8308e-01, -1.1510e-01,
         -3.3535e-01, -4.7783e-01, -1.0358e+00, -5.7076e-01,  7.3705e-01,
         -1.3296e+00, -4.1656e-01],
        [-4.6432e-01,  1.2410e-01,  8.7031e-01,  4.2294e-01, -9.0415e-01,
          1.4327e+00, -3.8050e-01, -5.4220e-01, -9.9681e-03, -1.2948e-01,
          2.1746e-01, -1.3033e+00, -3.9773e-01, -7.2931e-01, -8.5313e-01,
          2.4150e+00,  1.5437e-01,  3.7920e-01,  9.6019e-01,  3.7480e-01,
          1.5149e-01,  8.2222e-01,  6.4317e-01, -2.5176e-01,  2.9113e-01,
          1.2566e-01,  3.1541e-01,  6.0417e-01, -3.3123e-01,  6.3996e-01,
         -7.5672e-01,  8.8622e-02],
        [-2.7293e-01,  1.2157e+00,  3.2741e-01,  6.9428e-02,  7.8087e-01,
         -2.3973e+00,  9.7725e-01,  1.5735e+00, -1.8807e+00, -6.1475e-01,
          7.9061e-01,  1.9777e-01,  9.6651e-01,  1.6744e+00, -3.8231e-01,
         -1.7790e+00, -1.4057e+00,  2.7287e-01, -3.4387e-01,  7.6666e-01,
          1.0759e-01,  1.1020e-02,  5.3651e-01,  1.9321e-02, -5.2919e-01,
         -2.1887e+00,  2.2140e-01,  6.8578e-01, -4.3727e-01, -1.7506e-01,
          1.2515e+00, -1.9384e-02],
        [ 1.5192e-01, -4.8549e-01,  1.5465e+00,  8.7528e-01, -1.5806e+00,
          1.5264e-01,  1.2124e+00,  6.3213e-01,  2.2564e+00,  7.6559e-01,
          1.5407e+00, -8.9411e-01,  2.0573e-01, -2.8802e+00,  7.1904e-01,
         -3.5654e-01, -1.0649e-01,  1.4751e+00, -8.2256e-01, -6.7980e-01,
         -1.3604e+00,  3.9589e-01, -6.7840e-01, -1.8430e+00,  5.7813e-01,
          1.4110e-01,  1.2052e+00,  4.8373e-01,  9.5752e-01,  1.5288e+00,
          1.9275e+00, -7.1320e-01],
        [-9.7406e-01, -1.3329e+00, -9.6410e-01, -5.7227e-01,  5.2090e-01,
         -3.3559e-01, -4.8088e-01, -4.4712e-01,  1.3871e-01, -2.1109e+00,
         -9.5307e-02,  1.0533e+00, -3.5842e-01, -1.8368e+00,  5.0368e-01,
         -4.7237e-01, -2.5381e-01,  1.5383e+00, -8.0687e-01,  1.5942e+00,
         -6.1254e-01, -9.5952e-01, -2.1759e-01,  3.2551e-02, -9.9505e-01,
         -1.8499e+00, -3.8187e-01, -4.6183e-02, -1.0025e+00, -5.7699e-01,
          1.1812e+00, -8.3416e-02],
        [-9.7538e-03,  1.9459e+00, -1.1717e+00, -2.2595e-02,  9.3664e-01,
         -1.2958e+00, -1.5993e+00, -2.7815e+00, -3.4835e-01, -1.1969e+00,
         -1.9618e-01, -9.5227e-01, -7.4363e-01, -4.2012e-01, -6.9298e-01,
          4.1679e-02,  4.8037e-01,  7.9444e-01,  6.5271e-01,  1.4325e+00,
         -3.1803e-01,  1.3592e+00,  2.4432e-01, -9.2627e-01,  1.2961e-02,
          2.6201e-03,  1.6989e+00,  1.8025e+00, -8.5075e-01,  4.0278e-01,
          1.1579e+00, -1.7277e+00],
        [ 9.3535e-01,  1.0770e+00, -1.4271e+00, -7.5725e-02,  9.8102e-01,
         -4.4744e-01,  2.7115e-01,  6.5937e-01, -6.6988e-01,  3.7548e-01,
         -1.0023e+00,  1.7014e+00, -8.0564e-01, -1.8534e+00, -5.3071e-01,
          2.3454e-01, -3.8044e-01,  1.5429e+00,  8.8230e-01, -6.9160e-01,
         -4.9575e-01, -3.2645e-01,  3.0632e-01, -1.6439e+00,  2.6358e-01,
          1.3024e-01, -9.5471e-01, -1.3793e-01, -1.5746e+00, -2.3438e+00,
          9.5965e-01,  9.7130e-01],
        [ 5.5518e-01,  8.2883e-02, -9.5208e-01,  1.7709e+00, -1.2942e+00,
          8.2901e-01,  2.5142e-01,  1.6968e+00, -5.2225e-02,  1.3400e+00,
         -1.8198e+00,  1.5455e+00,  6.1595e-01,  1.8066e-01,  3.5864e-01,
          8.1209e-01, -7.7205e-01, -8.8516e-01, -8.1861e-01,  4.3419e-02,
         -5.2436e-01, -1.0382e-01, -4.5754e-01,  2.0066e-01, -5.8017e-01,
         -8.8413e-01, -6.6332e-01,  5.6789e-01, -1.5921e+00,  4.3211e-01,
         -1.3400e+00,  3.2528e-01],
        [ 1.1890e+00,  1.1128e-01,  3.4806e-01,  4.4414e-01,  1.2073e+00,
          1.5237e+00, -1.6426e+00, -2.8173e-01,  7.3919e-01,  7.8947e-01,
          4.7295e-01,  8.7442e-01,  6.6821e-02,  1.8032e+00,  1.2513e-01,
         -2.2002e+00, -8.2147e-01,  6.1815e-01,  2.2467e+00, -2.1455e+00,
          3.2886e-01, -5.0033e-01, -1.1782e+00, -1.9823e+00,  4.8731e-01,
          5.7998e-01,  5.1062e-01, -8.3561e-01, -3.4791e-01,  1.4517e+00,
         -9.3931e-01, -5.9125e-01],
        [ 2.3957e-01,  9.7654e-01,  8.5962e-01,  2.1241e+00, -1.3375e+00,
         -1.0844e+00,  9.7824e-01, -2.1143e+00,  3.3844e-01, -8.1302e-01,
         -2.4832e+00,  1.2712e+00,  1.8515e-01, -6.5932e-01,  3.7639e-02,
          1.8136e-01,  3.9414e-01,  1.4173e-01,  1.2177e+00,  5.6841e-01,
         -4.9012e-01, -2.1063e+00,  1.9782e+00, -1.2601e+00,  1.3886e+00,
         -4.7227e-01, -8.0096e-01, -9.3906e-01,  1.4239e-01, -7.5152e-01,
         -3.9521e-01, -1.9486e+00],
        [-6.1162e-01,  1.1131e+00,  4.4166e-01,  1.7026e-01,  6.9846e-02,
          1.1067e+00, -5.1252e-01,  8.4891e-01,  6.0209e-01,  4.5780e-01,
          2.5623e-01,  6.1975e-01, -8.7001e-01,  1.5546e+00, -1.5887e+00,
         -2.5354e+00, -5.3284e-01,  5.4638e-01,  1.6530e+00,  4.5309e-01,
          8.8500e-01, -1.0452e+00,  2.2570e+00, -1.5574e+00, -4.4916e-01,
          7.6787e-01, -5.3574e-01,  7.7006e-01,  4.6077e-01,  9.6504e-01,
         -8.8178e-01, -6.0607e-01],
        [ 5.0226e-01,  7.3088e-01,  4.2549e-01, -3.2569e-01,  6.2643e-01,
          6.3072e-01,  2.4565e-01,  1.2602e+00, -6.9721e-01,  2.0914e-01,
         -5.1851e-01,  6.8145e-01,  1.2510e+00, -1.7323e-01,  6.1274e-01,
          1.8242e+00,  2.4381e-02, -1.6179e+00, -7.6787e-01,  1.4890e+00,
          6.2961e-02,  3.8150e-01,  4.9754e-01, -8.0662e-02, -4.1676e-01,
          4.1451e-01, -1.0124e+00, -1.2297e+00,  2.1450e-01, -1.0436e+00,
         -4.7220e-01, -1.1194e+00],
        [-2.6967e+00,  1.3739e-01, -3.0397e-01, -6.2365e-02, -1.1408e+00,
         -8.2037e-01, -8.7688e-02,  4.2466e-01, -4.4057e-01, -2.9236e-01,
          1.5292e-01,  5.2253e-01,  2.2101e+00, -3.6775e-01,  7.3739e-01,
          1.6845e+00,  8.6919e-02,  2.7347e-01,  8.0029e-01,  8.2864e-01,
          3.4772e-01,  2.8115e-01, -3.8256e-01, -7.4770e-01,  6.8612e-01,
         -1.9051e+00, -2.5582e+00, -9.5879e-01,  1.4733e-01,  1.4932e-01,
          1.4695e-01, -3.6045e-01],
        [ 3.6221e-01,  9.2620e-01, -7.8207e-02, -1.6634e-01,  3.7897e-01,
          1.6182e-01,  9.5285e-01,  7.0327e-01, -2.0579e+00, -4.3142e-01,
          1.3276e-01,  3.6934e-01,  5.4599e-01, -1.3184e-03, -2.1107e-02,
         -1.2742e+00,  1.9630e-01,  2.0170e-01,  6.7975e-01, -1.5827e+00,
          5.6533e-02, -2.4085e+00,  6.5012e-01, -1.2308e+00, -3.6566e-02,
          6.5479e-01,  1.2051e+00,  1.7592e+00, -1.5409e+00, -1.3749e-01,
         -1.7443e+00,  1.2624e-01],
        [-9.4674e-01,  3.6251e-01, -4.7375e-01,  1.0581e+00, -9.7894e-01,
         -9.9839e-01,  2.4237e+00,  2.0973e+00,  8.6499e-01,  5.5137e-01,
          2.1212e+00, -2.4123e-01, -8.2816e-01,  2.2919e+00, -1.6512e+00,
         -4.1347e-01, -8.0849e-01, -1.2015e+00,  5.2903e-01,  1.0811e+00,
          1.3182e+00, -6.9245e-01, -8.3266e-01, -1.2601e+00,  1.9603e+00,
          6.3035e-01, -1.9899e+00,  1.1560e+00,  1.1416e+00,  5.4361e-01,
         -4.6951e-01,  1.4494e-01],
        [ 5.2323e-01, -1.4280e+00, -7.9962e-01,  6.6171e-01, -1.6670e+00,
          9.0657e-01, -1.4548e+00,  2.9292e-01,  7.7111e-01, -6.0712e-01,
         -1.5311e-01, -3.1387e-01,  1.2991e-02, -3.4652e-01,  1.3352e+00,
          6.9954e-01,  1.3719e+00,  1.3552e+00, -7.2456e-01, -1.0660e+00,
         -5.3974e-01, -1.8272e-01, -1.8896e+00, -8.6108e-01, -2.9665e+00,
         -1.0020e-01,  8.1776e-01, -9.2533e-01,  1.7863e-03,  6.3931e-01,
         -5.5193e-01, -9.3015e-01]], device='cuda:0')
tensor([[-2.0296e-01, -9.6859e-01, -1.0777e+00, -8.5230e-01,  5.1507e-02,
          1.5295e+00, -1.1014e-02,  4.5059e-01, -2.0057e-01,  2.4880e-01,
          2.0792e+00, -2.8334e-01, -4.2385e-01,  3.1202e-01,  1.0717e+00,
          7.6633e-01,  7.2492e-01, -2.1733e+00, -2.0367e+00, -3.3542e-01,
         -1.1987e-01, -1.1760e+00,  8.3734e-01,  7.7419e-01, -2.6152e-01,
          1.5560e-03, -1.5170e+00, -9.8123e-01, -1.2637e-02,  3.6400e-01,
          1.0829e+00, -1.0424e+00],
        [ 9.4205e-01, -2.5281e-03, -1.8613e+00, -9.4530e-01, -7.8178e-01,
          1.9626e-01,  6.3555e-01, -6.0386e-01,  1.1814e+00, -8.4726e-01,
          4.9714e-01,  7.0708e-01, -8.5001e-01,  9.2977e-01, -1.9113e+00,
          5.1992e-02,  1.3800e-02,  1.9570e-01, -3.7567e-01, -7.4133e-01,
          6.8612e-01,  1.0294e+00, -1.0031e+00, -4.8805e-01,  4.6812e-01,
          8.2087e-01, -6.9892e-01,  3.6355e-01,  7.6070e-02,  8.1340e-01,
          1.6101e+00,  1.5683e-01],
        [-1.1515e-01, -2.2607e-01, -1.8542e-01,  3.4355e-01, -6.0184e-01,
         -1.7120e-01,  1.1187e-01,  1.7161e-01,  1.5364e+00, -5.0678e-01,
         -3.6042e-01,  2.7000e-01, -9.2136e-01,  2.1023e-01,  1.1147e-01,
         -2.8389e-01, -1.2668e+00, -1.2212e-01,  6.0611e-01, -1.4262e+00,
          1.1092e+00,  1.3568e+00,  6.3640e-01, -1.6454e+00, -2.1411e-01,
          1.3157e+00, -1.4605e+00, -6.2865e-01, -2.6750e-01,  9.6798e-01,
         -3.2585e-01, -9.5589e-01],
        [ 7.9071e-01,  6.3376e-01, -8.1419e-01,  2.4610e-01, -1.7308e+00,
         -2.2976e-01,  4.1828e-01,  9.9230e-02,  3.6861e-01,  4.8577e-01,
         -1.2879e+00, -1.8295e+00, -9.4847e-02,  1.2621e+00, -8.3648e-01,
         -7.0132e-02,  1.1145e+00,  4.4581e-01,  1.1388e+00, -5.1898e-01,
         -1.0721e+00, -5.3001e-01,  6.2464e-01, -8.0395e-01,  1.3306e-01,
         -8.3469e-01, -1.5307e+00,  1.8922e+00,  2.6050e-02, -9.2493e-01,
         -5.5902e-01, -4.3600e-01],
        [ 7.7352e-02, -1.1118e+00, -5.1913e-01, -6.9637e-02, -1.0249e+00,
         -5.8392e-01, -1.2219e+00, -7.9858e-01, -3.8634e-01, -5.9240e-01,
         -1.7567e+00,  3.7608e-01,  1.1315e+00, -1.3950e+00, -2.0469e-01,
         -3.5405e-01,  1.6902e-01,  6.8603e-01, -7.3899e-02,  2.7535e+00,
         -1.6717e+00, -6.5564e-01,  8.0735e-01,  1.1132e+00,  1.0635e+00,
         -1.1124e+00, -3.0814e-01, -1.1140e+00,  7.2995e-01,  3.5690e-01,
         -1.0162e-01,  7.2892e-01],
        [-5.8857e-01,  2.0229e-01,  5.9629e-02, -1.8932e+00, -4.7681e-01,
          1.5290e+00, -2.3003e-01,  5.8959e-01, -9.6545e-01, -1.2732e+00,
          3.2945e-01, -1.3679e+00,  1.0072e-01, -2.8537e-01, -8.7798e-01,
         -2.1144e+00, -1.2898e+00,  5.0294e-01,  2.7046e-01,  9.7274e-01,
          5.2323e-01,  6.1430e-01, -3.8265e-01,  9.7365e-01, -4.7112e-01,
         -1.7102e+00,  7.5548e-01,  4.9186e-01,  2.6798e+00, -3.4646e-01,
         -1.6220e+00,  3.2296e-01],
        [-1.3066e+00,  1.7403e+00, -1.9004e-01,  1.1531e+00, -1.3334e-01,
         -1.7225e-01,  2.2857e-01,  5.4837e-01,  1.0921e+00, -4.8124e-01,
         -6.8537e-01,  4.6588e-01, -2.1526e-01, -3.5639e-01,  8.5529e-01,
         -2.2718e+00,  6.4297e-01,  7.4884e-01, -7.9324e-01, -6.3846e-02,
         -1.1684e-01,  1.1617e+00, -2.8114e-01,  6.0368e-01,  2.1456e+00,
          1.9491e+00, -1.1264e+00, -8.4893e-01,  3.9513e-02, -1.7030e+00,
          5.1791e-01, -1.7322e+00],
        [-2.7988e-01,  3.6818e-01,  2.1147e-01, -4.7874e-01,  1.4839e+00,
         -1.9022e+00,  1.5561e+00, -1.7509e-01, -1.3600e+00, -2.7912e-02,
          2.2118e-02,  8.6893e-01, -7.9397e-01, -4.0622e-01,  2.0567e-01,
         -5.0284e-01,  5.9320e-02,  2.3676e-02,  1.9974e-01,  2.2743e-01,
          4.0977e-01, -1.1007e+00,  1.4417e+00, -4.1880e-01,  4.2408e-01,
          1.3778e+00,  1.5854e+00, -6.5313e-01, -4.5753e-01,  1.0803e+00,
          1.1691e+00,  5.5539e-01],
        [ 9.2158e-01,  1.1031e+00,  4.9215e-02, -3.5413e-01,  1.9603e-01,
         -3.3111e-01, -1.5510e+00,  8.2121e-01,  1.0975e+00, -7.5751e-02,
         -3.0646e-02,  2.5174e-02,  6.4586e-01, -1.2206e+00,  2.0117e-01,
         -3.1140e-01,  1.1492e+00, -1.1451e+00, -1.4038e-01, -6.1116e-01,
         -1.1199e+00, -9.8289e-01, -6.4333e-01, -1.5979e+00, -1.4760e+00,
         -6.0314e-02, -9.3953e-02, -1.1030e+00, -2.6219e-02,  6.4502e-01,
          1.2436e+00,  9.5969e-01],
        [-8.7780e-01, -4.6374e-01, -7.1192e-01, -2.7440e-01, -1.7772e-02,
          6.0928e-01, -1.1304e+00,  1.1618e+00, -2.1580e+00,  2.2202e-01,
         -9.8054e-01,  1.3640e+00,  5.5376e-01, -3.3736e-01,  8.6489e-01,
         -7.9170e-01, -4.7666e-01,  1.7354e-01,  2.3322e-01,  1.5933e-01,
          1.0830e+00,  2.6101e-01, -8.3326e-02,  5.1510e-01,  7.9845e-01,
          4.1912e-01,  1.6445e+00, -1.1513e+00,  4.0505e-01, -2.3691e-01,
          3.8287e-01, -1.2890e-01],
        [ 1.2614e+00,  3.8612e-02,  2.4421e-01, -4.5120e-01, -2.1239e-01,
         -6.5739e-02,  1.5743e-01, -1.7018e-01, -2.9757e-01, -3.9874e-01,
          1.0706e+00, -6.2728e-01,  1.3896e+00, -1.3810e+00,  1.1434e+00,
         -6.7156e-01, -1.6683e+00, -7.9864e-01, -5.7085e-01, -5.8197e-01,
         -8.3355e-01, -1.3487e+00, -3.6723e-01,  1.0335e+00, -2.1145e+00,
          2.9535e-01, -8.4178e-02,  7.3897e-01,  1.8200e+00,  7.2119e-01,
          3.3902e-02, -3.8838e-01],
        [-7.9942e-01,  6.0710e-01, -1.2330e+00, -3.6290e-01,  1.3747e-01,
          5.6299e-01,  1.5513e+00,  5.5175e-01,  1.0905e+00,  1.4284e+00,
         -2.1813e+00, -1.0237e-01,  1.7283e+00, -1.0291e+00, -4.0672e-01,
         -4.5256e-01,  1.1391e+00, -1.3382e+00, -2.5474e-01, -1.1685e+00,
         -9.4542e-01,  7.5069e-01,  1.5698e+00, -8.8259e-01,  1.6471e+00,
         -6.4895e-01,  3.8657e-01, -2.3139e-01,  9.7493e-01, -8.3685e-01,
          1.8398e-01, -7.9826e-01],
        [ 1.4286e+00,  4.8775e-01,  8.5087e-01,  1.0994e+00,  7.5041e-02,
         -1.3749e+00,  1.0198e+00,  3.0658e-01, -1.3525e+00, -2.6173e-01,
          2.4711e-01,  1.8687e-01,  1.9732e-01, -4.5591e-01, -2.5709e-01,
         -1.3499e+00, -1.0514e+00,  5.3302e-01, -5.5910e-01,  8.5173e-01,
         -1.3620e-01, -1.7316e+00,  4.7433e-01, -1.5175e+00,  2.5982e-01,
          3.6390e-01, -2.0552e-02,  3.5090e-02,  9.1435e-01,  1.8805e-01,
          3.9676e-01, -1.7833e+00],
        [ 4.3246e-01,  7.4905e-01,  4.2569e-01,  5.3642e-01, -3.8499e-01,
          3.7738e-01,  8.7995e-01, -1.6017e+00,  1.9660e+00,  1.4231e+00,
          8.9244e-02, -1.7429e-02, -4.7150e-01,  9.1569e-01, -1.5874e+00,
          1.1541e+00, -1.4387e-01, -4.5054e-01, -9.6273e-01,  5.9126e-01,
          6.2493e-01,  7.0956e-01, -9.0990e-01,  4.9844e-01,  7.4666e-01,
         -9.8518e-01, -9.1415e-01, -7.3641e-01,  4.2525e-01,  2.6394e-01,
         -1.4339e-01,  5.4705e-01],
        [-7.8047e-01,  6.8255e-01, -8.6443e-01,  1.5441e-01, -1.3698e+00,
         -2.0694e-01,  9.9560e-01,  2.5217e-01, -3.4645e-01,  3.9045e-02,
         -8.0107e-02, -9.0973e-01,  2.1195e+00, -1.6055e+00, -5.3766e-01,
          1.9719e-01, -3.5098e-01, -1.0982e+00,  7.2040e-01, -2.9409e-01,
          1.4660e+00, -1.3213e+00,  1.2438e+00, -1.3796e-02,  1.3610e-01,
          7.6795e-01, -5.3322e-01,  3.1559e-01,  1.1940e+00, -1.1145e+00,
          1.0531e+00,  6.7045e-01],
        [-4.4272e-01,  2.1485e+00, -4.1307e-01,  8.0342e-02,  1.4043e+00,
         -4.3305e-01, -1.3203e+00,  1.5368e-01, -1.2806e+00, -6.5234e-01,
          3.5443e-02,  1.7652e+00,  6.4594e-01,  7.2147e-01, -4.0555e-01,
         -3.2752e-01,  4.4660e-01, -2.3157e-01, -3.5311e-01,  1.2983e-01,
          2.4105e-02, -2.4787e+00, -6.2617e-02,  3.9409e-01,  2.2408e-01,
         -1.3175e+00, -6.7288e-01, -8.8182e-01,  5.0179e-01, -2.7082e-01,
          1.4422e+00,  5.3417e-01],
        [-8.9570e-01, -1.6361e+00, -5.4903e-01,  1.8461e+00,  1.2171e-01,
          1.0915e+00, -2.6184e-02, -1.5867e-01, -2.3661e-01, -1.1564e+00,
          9.3651e-03,  1.1838e-01, -7.1025e-01,  1.9167e-01, -4.6915e-01,
         -1.3330e-01,  5.1716e-01, -1.1505e+00, -1.5367e+00, -4.5776e-01,
          5.9382e-02,  2.0875e+00, -7.0141e-01, -5.1581e-01, -8.9782e-01,
         -3.3759e-01, -4.5856e-01,  8.6672e-01,  3.0284e+00,  1.6368e+00,
          5.4746e-01, -1.7801e-01]], device='cuda:0')
tensor([[ 4.3751e-01,  2.6684e-01,  1.1094e+00,  8.4079e-01,  2.4146e-01,
         -1.1997e+00,  2.0937e-01,  1.8206e+00,  4.1712e-01, -2.3353e+00,
          1.0018e+00,  8.2756e-01, -1.3566e-01,  4.6085e-01,  2.1205e-01,
         -1.2335e-01, -2.0917e-01, -6.7088e-01, -7.9547e-01, -5.3040e-01,
          1.2470e-02,  8.8988e-01, -5.9182e-01,  1.8992e+00, -5.3724e-01,
          6.3526e-01,  1.2503e+00, -3.5412e-01, -3.7523e-01,  4.2749e-01,
          2.3571e-01, -1.6133e-01],
        [ 8.2091e-01, -8.5891e-02, -1.1224e-01,  1.1105e-01,  5.1321e-01,
          4.2521e-01, -1.5172e-01, -4.8663e-01, -5.2039e-01, -3.3175e-01,
         -5.7521e-01, -2.7971e-01, -9.3308e-01,  1.0207e+00, -1.1322e+00,
          1.1873e-01,  1.0724e+00, -1.1593e-01,  3.4436e-01, -1.2335e+00,
          5.5944e-01,  1.9811e+00, -1.1626e+00,  1.8302e+00, -2.0066e+00,
          1.7205e-01,  2.0721e-01,  4.1031e-01, -1.9748e+00, -1.0575e+00,
          1.5376e+00,  3.2140e-01],
        [-4.7655e-01, -5.2036e-01,  8.4543e-01, -6.1876e-02,  8.8657e-02,
         -4.0822e-01, -5.7961e-01,  7.5530e-01, -6.4069e-01,  1.8584e-01,
         -1.8635e-01, -9.5505e-02,  2.0039e+00,  1.8330e+00, -1.7797e+00,
          6.7374e-01, -1.0489e+00, -1.3574e+00,  8.1896e-01,  5.8474e-01,
         -6.0542e-01,  3.1238e-01,  3.9299e-02, -1.1096e+00, -9.2067e-01,
         -4.0383e-01, -5.8276e-01,  2.7030e+00, -1.2373e-01, -1.9076e-01,
         -2.2948e-01, -1.1712e+00],
        [-1.0077e+00,  1.5537e+00, -1.6814e-01,  8.9989e-02, -8.5521e-01,
          7.2623e-01, -7.7835e-01,  4.1866e-01, -7.0136e-02,  1.8524e+00,
          1.4177e+00, -7.6309e-01,  2.0943e+00,  1.2837e-01, -1.0344e+00,
         -2.3749e-01,  1.0079e+00, -1.2950e-01, -2.2946e+00,  8.0747e-01,
          1.3685e+00, -2.5634e+00, -1.8124e-01, -1.8354e-01,  1.4118e-02,
          1.6009e+00, -2.2509e-01, -2.7824e-01, -1.5061e-01,  6.2391e-01,
         -6.4900e-01, -1.0564e+00],
        [-5.0112e-01,  1.0056e-01,  8.6490e-01,  1.7397e-01, -1.1357e+00,
          1.0973e+00,  5.3590e-01, -9.7769e-01,  1.9024e-01,  1.3140e+00,
          1.6840e+00, -1.0335e-01,  1.0248e+00,  5.8375e-01, -9.7344e-01,
          9.8944e-01,  1.7816e+00, -6.4927e-02, -1.8738e+00,  4.4781e-01,
         -1.0997e+00, -2.7968e-01,  1.0318e+00, -4.5230e-02,  6.1070e-01,
         -7.8308e-01,  1.3742e+00, -6.4770e-01,  5.9678e-01, -7.8666e-01,
          1.0382e+00,  2.5742e-01],
        [-1.6286e+00, -6.7993e-01,  7.7745e-01,  3.9352e-01,  6.3129e-01,
         -1.2629e+00,  1.3294e-01,  7.4955e-01,  1.6141e+00, -2.4469e+00,
         -3.0738e-01,  1.7352e+00, -5.9468e-01, -5.0188e-01,  1.4638e+00,
          1.1364e+00, -4.3097e-01, -1.5877e-01,  8.4397e-01,  1.3020e+00,
          9.2259e-01, -6.7606e-01,  6.2792e-01,  9.6372e-01,  1.1875e+00,
          1.6202e+00,  1.3043e-01, -4.5869e-03,  1.2343e+00, -1.5306e+00,
         -1.4750e+00,  1.3162e-01],
        [-1.8023e+00,  9.7675e-01,  5.4518e-01, -3.3234e-01,  1.3918e+00,
          1.4506e-01,  4.2393e-01, -2.0944e+00, -4.0506e-01,  1.0729e+00,
          5.8190e-01,  9.0685e-02,  8.0391e-01,  1.3306e+00,  6.4861e-01,
          1.9354e-01, -3.0450e-01, -1.1413e+00,  5.0127e-01, -1.2143e-01,
          7.3930e-01, -1.4539e+00, -1.5225e+00,  4.2461e-01,  1.0372e+00,
          6.8159e-01,  1.8356e-01,  2.1566e-01,  3.2801e-01, -3.0284e-01,
          1.7890e-01, -1.7900e-01],
        [ 4.2280e-01,  4.6131e-01, -8.4126e-01, -1.3167e+00,  8.7862e-01,
         -8.7839e-01, -1.5308e-01, -9.5053e-01, -4.5742e-01,  9.9717e-01,
         -1.6328e-01, -6.1555e-01, -4.4208e-01, -3.4822e-01,  8.9079e-01,
         -2.6379e-01,  4.8812e-01,  3.1597e-01, -2.4343e+00,  7.9616e-03,
         -1.0743e+00,  1.1683e+00, -2.5805e+00,  8.3673e-01,  7.9848e-01,
          2.9976e-01,  6.9712e-01, -5.9932e-01,  5.9860e-01,  2.4595e-01,
         -5.2747e-01,  1.9202e+00],
        [ 8.1761e-01, -2.8002e-01, -1.5067e+00, -6.9519e-01, -2.5421e-01,
          9.7880e-01,  9.9750e-01, -4.6393e-01, -4.5765e-02, -1.0120e+00,
          8.7695e-01,  2.0944e-01,  4.7027e-01, -1.0151e+00, -5.9902e-01,
          8.2716e-01, -5.9789e-01,  1.9509e+00, -5.1014e-01, -4.5577e-01,
          2.3491e-01,  6.4596e-01,  3.2158e-01, -2.9887e-01, -1.7201e+00,
          5.0114e-01, -4.0816e-01, -2.6691e-01,  1.0375e-02,  1.6712e+00,
          1.0029e+00, -1.1376e-01],
        [ 8.7787e-01,  6.6519e-01, -2.4090e+00,  8.4846e-01,  2.4947e-01,
          1.4507e+00, -5.1272e-01,  2.9572e+00,  6.0696e-01, -1.1255e+00,
         -4.0046e-01,  1.8650e-01,  1.5513e+00,  8.8033e-01, -1.2486e+00,
          2.0768e-01, -7.4937e-01, -2.8194e-01,  7.4355e-01, -5.4875e-01,
         -5.3191e-02, -6.0371e-01,  1.3558e+00, -1.0176e+00, -1.1367e+00,
         -3.3414e-02,  7.2956e-01,  1.4922e+00, -1.4171e-01, -5.7551e-01,
         -1.3294e-01,  8.3235e-01],
        [-9.4466e-01, -4.0657e-01,  8.3201e-01, -2.0403e+00,  5.7219e-01,
         -2.6079e-01,  9.0606e-01,  6.8665e-02,  6.8090e-01,  1.7498e-01,
          1.3523e+00,  1.4929e-01, -4.6726e-01, -4.8858e-01,  1.2240e+00,
          6.5344e-01,  1.7552e+00,  1.7275e+00, -6.5088e-01, -1.1455e+00,
         -2.8420e+00, -8.6422e-01,  1.2103e+00,  1.8896e+00,  2.6555e-01,
         -6.1639e-02,  5.9419e-01,  8.8015e-01,  1.6617e+00,  1.1148e+00,
          9.1274e-01, -1.6177e+00],
        [-1.4899e+00, -7.6686e-02, -1.8170e+00, -1.0115e+00,  1.6771e-01,
         -1.1411e+00,  6.9716e-01, -4.1000e-01, -4.4882e-01, -2.2184e+00,
         -6.3692e-02,  6.3605e-02, -2.4868e-01, -2.2242e+00, -1.1899e+00,
         -1.6655e+00,  1.8407e+00, -3.6347e-02, -5.6392e-01,  8.7626e-01,
         -9.5607e-01, -1.0306e+00,  1.7834e+00,  6.7935e-01, -1.8399e+00,
         -1.6603e-01,  1.9161e-01,  1.3463e+00, -1.7403e-01, -4.7257e-01,
         -1.8101e+00,  1.1065e+00],
        [-3.1172e-03,  5.1821e-01, -1.6507e+00, -5.1655e-01,  9.5435e-01,
          1.0140e+00,  6.2049e-01,  5.7395e-01, -9.6175e-01,  9.5620e-01,
          4.1553e-01, -1.3088e+00, -9.8489e-01,  8.4912e-01,  1.3883e+00,
         -2.0226e+00, -3.8650e-01, -1.2085e+00,  2.7637e+00,  1.5410e+00,
          1.1126e+00, -2.1776e-01,  1.5977e-01,  5.1114e-01, -7.7033e-01,
         -6.9688e-01, -3.1942e-01,  2.1483e-01, -1.7510e-01, -4.3354e-01,
          3.3418e-01,  1.7045e+00],
        [-5.3393e-01, -4.0929e-02,  1.9136e+00, -5.2473e-01,  8.2619e-01,
         -6.4301e-02, -7.7792e-01, -1.1069e+00, -1.4496e+00,  3.1458e-01,
         -2.9272e-01,  1.1025e+00, -7.1961e-01,  1.2242e+00,  9.3018e-01,
          8.1279e-01,  5.4474e-01,  4.4262e-01, -8.6603e-01, -7.7189e-01,
         -1.2889e+00,  6.3482e-01,  5.7719e-01,  2.3364e-01, -1.3678e-01,
          5.3563e-01,  3.2064e-01,  2.6610e-02,  4.6264e-01,  9.0693e-02,
          1.3182e+00,  1.1488e+00],
        [-5.9478e-01,  5.6502e-01,  1.7685e-01,  2.3132e+00, -5.6206e-01,
         -5.3438e-01, -1.7014e+00,  7.7362e-01, -1.3863e+00, -1.1708e+00,
          6.4873e-02,  2.7267e-02,  1.4078e+00, -6.1540e-03,  7.0038e-01,
         -5.7527e-01,  1.0640e+00,  1.8869e+00,  1.1247e+00,  7.6595e-01,
         -4.9159e-01, -1.9415e-02, -1.3873e+00, -1.2702e+00,  2.3520e-01,
         -3.1816e-01,  3.7668e-01, -1.6237e+00,  2.5669e-01,  8.1963e-02,
          2.8287e-01,  5.9827e-01],
        [-2.3789e+00,  8.5941e-01,  6.8809e-01,  2.8457e-01, -2.1974e-01,
          4.4046e-01, -1.9889e+00, -5.5058e-01, -1.5677e+00,  1.1764e-02,
          2.5643e-01, -1.0097e+00,  7.9223e-01,  4.7809e-01,  6.7450e-01,
          1.3519e-01, -9.9061e-01,  4.6501e-01, -1.3909e+00, -4.9840e-01,
          1.2826e+00,  1.2758e+00, -7.0873e-01,  2.4783e-01,  1.3227e-01,
          3.1991e-01, -1.3462e+00, -6.0182e-02, -1.2818e-01,  9.8762e-01,
          3.2493e+00,  6.9490e-02],
        [ 1.3207e+00,  7.2791e-01,  6.2958e-02, -3.6551e-01, -1.4126e+00,
         -2.8668e+00,  1.0120e+00,  4.5213e-02, -1.1927e+00,  2.5324e-01,
         -1.5641e-01, -9.4542e-01, -1.2123e+00,  1.3165e+00,  9.0759e-03,
         -8.6350e-01,  3.1729e-01,  1.5855e-01,  8.0362e-01, -2.1737e+00,
         -6.3061e-01,  1.5350e+00,  2.0108e-01,  3.7485e-01,  6.6826e-01,
          2.2420e+00, -3.8662e-01,  2.2574e+00,  1.9084e-01, -3.9895e-01,
         -5.4980e-01, -4.9800e-02]], device='cuda:0')
tensor([[-1.2977e-01, -4.8711e-01,  1.2652e+00, -1.9986e+00,  5.1671e-01,
          1.9267e-01, -4.9277e-01,  3.7455e-01,  8.5850e-01,  1.0479e+00,
         -1.6021e+00, -7.1519e-01, -1.3275e-03, -9.9002e-01, -5.5954e-01,
         -9.4028e-01, -8.6880e-01, -1.6037e+00,  7.8894e-01, -2.4957e-01,
         -3.1829e-01,  2.4739e-01, -5.7733e-01, -1.4485e+00, -8.9431e-02,
         -1.4584e+00, -4.4415e-01,  2.3020e-01,  7.5901e-01, -2.1422e-01,
          1.2338e+00,  8.6498e-01],
        [ 3.3402e-01,  3.1935e-02, -9.4147e-01, -5.5911e-01,  7.5420e-01,
          4.8572e-01,  8.6574e-01, -1.0205e+00, -1.3875e-01, -9.8765e-01,
         -1.1519e+00,  1.7088e+00,  5.7528e-01, -1.4285e+00,  3.3391e-01,
         -1.2016e+00, -1.0985e+00, -3.6887e-01,  2.0494e+00, -4.0003e-01,
         -1.1857e+00, -1.2251e+00,  7.6376e-02,  2.8880e-01, -1.0140e+00,
         -6.7132e-01,  5.6890e-01, -3.5471e-01,  6.9834e-01,  3.2699e-02,
          1.0357e-01, -1.9002e+00],
        [-2.4413e-01, -6.2857e-01,  2.1958e-01,  6.5650e-01, -2.0592e+00,
          3.5352e-02,  3.1624e-01, -9.8597e-01, -8.6976e-01, -3.5076e-02,
         -8.6310e-01, -1.1638e+00, -2.2754e+00,  7.2645e-02, -9.5372e-01,
          3.1923e-01, -1.4659e-01, -1.6149e+00,  4.5957e-01,  3.7782e-01,
         -5.1767e-01, -9.3487e-01, -1.7904e+00, -1.7154e+00, -1.1826e-01,
         -1.1264e+00,  1.2225e+00, -1.5886e-01, -2.4636e-01,  2.1234e-01,
          4.2695e-01,  2.9866e-01],
        [-2.9251e-01, -2.2296e-01,  8.1222e-01,  2.0139e-01, -9.6053e-01,
         -5.0540e-01,  1.0536e+00, -1.0173e+00, -1.9305e-01, -2.1660e+00,
         -1.6165e+00, -3.0685e-01,  1.3826e+00,  5.0717e-01, -1.5827e+00,
          4.1071e-02, -8.0820e-01, -6.1686e-01, -6.9432e-01,  1.3651e+00,
         -1.0639e+00, -1.4698e+00, -4.8105e-01, -7.0852e-01,  1.3219e+00,
         -9.2005e-01, -8.6315e-01,  1.3693e+00, -7.1058e-01,  1.2174e-01,
         -3.9352e-01, -4.2616e-01],
        [-1.2740e+00, -5.9237e-01,  1.9235e-01,  1.5557e+00, -1.5223e+00,
         -1.4172e-02, -9.1429e-01,  7.9622e-03,  2.5036e-01,  7.0654e-02,
          6.6699e-01,  1.5882e+00, -2.7398e-01,  2.0798e-01,  9.8155e-01,
          1.7645e+00,  6.7338e-01,  3.6507e-01, -8.9506e-02, -2.6470e+00,
         -2.3184e-02, -1.3935e+00,  9.2177e-01, -1.2779e-01,  7.3487e-01,
         -3.8308e-01,  2.0195e+00, -1.1271e+00,  2.7473e-01, -1.2011e+00,
         -1.8275e-02,  9.7403e-01],
        [-9.3080e-01,  2.5606e-01,  4.0645e-01, -2.9715e+00,  3.3321e-01,
          9.7575e-01, -1.5983e+00, -1.4435e-01,  1.3009e+00, -7.4063e-01,
          1.4295e+00, -6.6740e-03, -6.6351e-01, -3.0717e-01,  1.0504e+00,
          1.9893e-01, -1.7552e+00, -4.6069e-01, -9.5224e-01,  4.5831e-01,
         -1.8722e-02,  8.9843e-02,  6.3305e-02, -7.7163e-01, -7.6054e-01,
         -7.7702e-01,  1.3676e+00,  6.4796e-01,  6.8331e-01,  6.8315e-01,
          7.4519e-01, -1.3356e-01],
        [ 3.4749e-01,  8.0126e-02, -7.9877e-02, -4.9951e-01,  1.6698e+00,
         -2.6460e-01, -4.9695e-01,  5.4860e-02,  1.8178e+00,  9.4799e-01,
         -1.5155e+00,  9.7503e-02, -2.3266e-01,  1.5465e+00,  1.6277e+00,
         -8.4303e-01, -1.3109e+00, -3.0675e-01,  1.0450e+00, -2.0543e-01,
          3.2353e+00, -3.3006e-01,  1.3900e+00, -6.9016e-01,  1.7607e+00,
          1.0923e+00,  2.6218e+00,  8.8734e-01, -5.0416e-01, -2.1170e-02,
          6.9695e-01, -2.0700e-02],
        [-7.3195e-01, -5.7906e-01, -1.6862e+00, -1.9463e+00,  8.5096e-01,
          1.2342e-01, -1.7351e-01, -1.7736e+00, -9.2983e-02, -1.0063e-01,
         -6.5628e-01,  4.7454e-02,  8.9247e-01, -1.4511e+00, -2.1486e-01,
         -1.3112e+00, -7.6419e-01, -9.6535e-01, -2.9314e-01,  2.6614e+00,
         -2.1867e+00, -1.1089e+00,  2.4643e-01, -1.7758e+00,  9.4643e-01,
         -7.6219e-02, -1.3145e+00,  1.8760e+00, -5.4805e-01,  2.5460e-01,
         -3.2858e-01,  2.3448e+00],
        [-1.5496e+00, -7.0526e-01, -1.6752e+00, -6.0838e-01, -1.8299e+00,
          1.1799e+00, -4.5054e-01, -8.0727e-01, -2.4192e-01, -1.9177e+00,
         -9.4843e-01,  9.4922e-01, -2.7849e-01,  1.0216e+00,  1.2040e+00,
         -2.0480e+00,  4.4468e-01,  9.3155e-02, -6.1812e-01,  1.0507e+00,
          1.7650e+00,  1.8223e-01,  3.0792e-01,  9.6903e-01,  3.8512e-01,
         -5.9008e-01, -1.8252e-01, -4.4352e-01,  6.7098e-01,  1.4342e+00,
         -6.3847e-01,  6.4424e-01],
        [-1.0348e+00, -2.4333e-01,  4.0404e-01, -3.5956e+00,  6.5123e-02,
          2.2652e-02,  9.2626e-01, -1.4464e+00,  3.5751e-01,  5.4937e-01,
         -8.4565e-01, -7.7990e-01, -6.6270e-01, -3.2745e-01,  4.8084e-01,
          1.0266e+00,  1.5353e+00,  5.0639e-01,  6.8238e-02, -6.1811e-01,
          1.7464e+00, -6.5266e-02,  7.1122e-01, -2.5787e+00, -1.8882e+00,
         -5.5246e-01,  1.1513e+00, -6.0214e-01,  1.2432e+00,  7.5270e-01,
         -9.0721e-01,  1.1486e-02],
        [ 4.9807e-01,  8.1035e-01,  3.1407e-01,  3.1394e-01,  1.6979e+00,
          9.3627e-01,  1.0879e+00,  7.8525e-01,  5.2825e-01,  3.1802e-01,
         -3.9452e-01, -1.7542e-01,  1.0233e+00,  1.0783e+00, -1.3750e+00,
          4.5654e-01,  1.3443e+00,  4.3231e-01, -8.9976e-01,  5.0136e-01,
          6.9239e-02,  4.7477e-01, -1.2380e+00,  3.2622e-01, -7.8012e-01,
          4.3037e-01, -8.3399e-01,  1.0822e+00,  1.0062e+00, -1.4946e+00,
         -3.2239e-01, -1.2667e+00],
        [ 1.1615e+00,  5.3975e-01,  2.1540e+00, -4.2658e-02,  5.9651e-01,
         -2.3612e+00, -1.4662e+00,  3.8657e-01, -1.0167e+00,  9.1783e-01,
          7.3123e-01,  9.7665e-01,  1.9186e+00, -9.5632e-02,  2.6320e-01,
          1.9399e+00,  1.1829e+00, -3.2727e-01, -7.5731e-01, -3.9695e-01,
         -8.7997e-01,  9.3657e-01, -8.8218e-01, -6.3741e-02,  2.5040e-02,
          1.5373e+00, -4.9930e-01,  1.0398e+00,  1.1103e+00,  9.8513e-02,
          1.3952e+00, -1.8258e+00],
        [ 2.4538e-01,  1.8702e+00, -1.4849e+00, -3.8923e-01, -4.8680e-01,
          1.3356e+00,  4.2955e-01, -4.5801e-01, -1.7514e+00,  1.3689e+00,
          1.4977e-01,  7.0077e-01, -3.2186e-01, -9.7022e-01,  8.3711e-01,
         -8.6485e-02,  2.3436e+00, -8.5864e-01, -1.2055e+00,  3.9433e-01,
         -1.2035e+00,  5.6159e-02, -6.6919e-01,  1.2259e+00, -5.9147e-01,
         -6.5531e-01,  8.3349e-02,  4.7548e-01, -2.2572e-01, -5.6595e-01,
          1.5339e+00, -2.7041e-01],
        [-6.5943e-01,  6.9256e-02, -5.2322e-01,  3.6989e-01,  1.8275e-01,
          3.2175e-01, -9.9306e-01, -2.2092e-01,  7.3072e-01, -1.4511e+00,
         -2.6734e-01, -5.0772e-01,  1.3755e-01,  1.2417e+00, -2.5267e-01,
         -2.8190e+00, -4.5584e-01, -8.2164e-01, -7.9458e-01,  1.0707e+00,
         -1.5053e+00, -7.7225e-01, -1.6580e-01,  2.0564e-01,  1.3498e+00,
         -1.6546e-01,  7.3873e-01, -9.5158e-02,  5.3229e-01, -1.9594e+00,
         -7.6723e-01,  9.4715e-01],
        [ 4.1021e-01,  9.0689e-02,  6.1610e-01, -3.2722e-01,  4.3371e-01,
          7.2910e-01,  7.6999e-01,  1.4086e+00, -6.2609e-01, -3.3394e-01,
         -8.0491e-02,  5.2759e-01, -3.1212e-01, -5.8090e-02,  6.2974e-01,
         -9.2261e-02,  4.4494e-01, -5.8011e-01,  4.9120e-01, -4.9551e-01,
         -1.2541e+00, -4.1085e-02, -3.7282e+00, -1.9533e+00,  7.2354e-02,
          6.6044e-01,  2.1020e+00, -4.7405e-01,  5.4982e-01,  1.0329e+00,
         -1.3803e+00, -1.4298e+00],
        [ 6.2490e-01,  8.7494e-01,  3.0531e-01,  9.1098e-01, -1.1252e+00,
         -7.3771e-01,  1.2424e+00,  1.3050e-01, -2.2679e+00, -5.3176e-01,
         -6.1965e-02,  5.2172e-01,  2.1029e-01, -1.3574e+00, -1.9670e-01,
          5.8532e-01, -1.3203e+00, -7.5024e-01,  1.5428e+00, -2.6773e-01,
          1.0101e-02,  7.9747e-01,  6.2716e-01,  1.3806e+00,  9.8484e-01,
          2.4586e-01,  8.0775e-01,  1.2833e+00,  1.2750e+00,  1.7814e-01,
         -5.3727e-01,  1.7733e+00],
        [-7.2289e-03,  1.4332e+00,  2.1361e-03,  1.4266e-01,  7.9414e-01,
          2.2940e+00,  1.6901e+00, -2.0436e-01,  4.6023e-01,  3.5604e-01,
          7.3022e-02,  3.5608e-01,  2.1624e+00,  3.5503e-01, -3.8669e-01,
          2.3217e+00, -1.4662e+00, -7.1612e-01, -3.1530e-01,  4.2149e-01,
          9.0357e-01,  4.8819e-01, -1.7505e+00,  1.2402e+00,  1.4587e+00,
         -6.4109e-01, -1.1537e+00, -3.7366e-01, -4.4914e-01, -2.7374e-01,
          3.3620e-01, -1.6177e+00]], device='cuda:0')
tensor([[-1.7268e+00, -1.5224e+00,  7.9294e-02, -1.8273e-01, -1.3861e+00,
          1.7374e-01,  5.1460e-01,  7.8727e-01, -1.1178e+00,  7.5786e-01,
          1.0170e+00,  2.1420e-01, -3.9799e-01,  1.4014e+00, -7.2696e-01,
         -1.4250e+00,  8.6622e-01,  1.0372e+00,  1.3016e-01, -5.7301e-01,
          1.1678e+00, -7.9152e-01,  7.7237e-01,  6.7652e-01, -7.0728e-01,
         -1.4285e-01, -1.7361e+00,  2.0277e+00, -2.4463e-01, -2.9306e-01,
          5.6786e-01,  5.9905e-01],
        [-8.0415e-01,  4.0435e-01,  3.8348e-01,  2.2235e-01, -4.2286e-01,
          1.7399e+00, -1.5689e-01,  4.4537e-01,  1.7113e+00, -6.4618e-01,
         -1.1040e+00, -1.4424e-01,  8.3239e-01, -8.2571e-01, -3.6821e-01,
          2.6443e-01,  4.9457e-01, -1.8530e+00, -2.1123e+00, -1.1201e+00,
         -6.7916e-01, -6.3886e-01, -8.6709e-01, -1.7489e-02,  1.2134e+00,
          1.0835e-01,  3.5619e-01, -1.7783e+00, -2.2765e+00, -5.2708e-01,
          1.5487e+00,  9.1044e-01],
        [-2.1572e+00,  6.7110e-01, -3.6222e-01, -2.1247e+00,  1.1052e+00,
          2.3597e-01,  3.7370e-01, -2.1618e-01, -1.3407e+00, -5.1417e-01,
         -2.2377e-01, -2.9291e-01, -1.5520e+00, -2.0213e+00, -1.1030e+00,
          8.2957e-01,  1.1913e+00,  1.2947e+00, -1.4546e+00, -3.9003e-01,
         -2.2923e-01, -1.6864e-01, -1.5398e+00,  1.8045e+00,  5.6880e-01,
          8.8958e-01,  6.4183e-01, -6.9838e-01,  3.1629e-01,  1.8718e+00,
          1.7924e-01,  1.4954e+00],
        [-8.2139e-01,  8.7198e-01, -1.1946e+00, -8.0369e-01,  3.6964e-03,
          5.6763e-01,  1.1334e+00, -5.9385e-02,  9.0646e-01,  1.0611e+00,
          1.0805e+00,  3.3893e-01,  3.0999e-01,  1.4261e+00, -5.0077e-01,
         -8.4878e-01,  1.4366e+00, -9.0983e-01, -1.3319e+00, -6.4190e-01,
          2.7113e+00, -5.0695e-01, -8.2604e-01, -7.1984e-04,  2.8490e-01,
         -1.5800e-01,  6.9320e-01, -4.0638e-01,  7.0774e-01,  3.0216e-01,
          1.1561e+00, -1.1047e+00],
        [-8.1630e-01,  2.9711e-01,  5.0146e-01, -1.5858e+00, -1.7684e+00,
         -5.7755e-01, -6.5266e-01, -1.2096e+00,  1.6097e-01,  1.7404e-01,
          2.6793e-02,  3.5560e-02,  6.3216e-02, -1.1700e+00, -1.0418e+00,
          1.8382e+00, -1.1813e+00,  1.7098e+00,  9.3894e-01,  9.6346e-01,
          1.3420e+00, -2.8317e-01, -1.3961e+00, -2.8812e-01,  9.3334e-01,
         -3.3658e-01,  5.1049e-01, -1.3374e+00,  1.4713e+00, -1.2310e+00,
          6.8342e-01, -2.5773e-01],
        [-1.7044e+00,  2.2276e-03,  4.3462e-01, -4.0806e-01, -2.5983e+00,
          9.8702e-01, -1.5404e-01,  8.6671e-02, -5.7148e-01,  2.2222e+00,
         -1.6183e+00,  1.3213e+00,  4.5205e-02, -4.6646e-02,  1.4268e+00,
          5.4200e-01,  2.7941e-01, -1.0779e+00,  1.3716e+00,  3.5995e-01,
          2.2163e-01, -9.6626e-01,  5.6136e-01,  1.2112e+00,  1.6695e+00,
         -5.8396e-01,  1.7498e+00, -1.7636e-01, -1.1019e+00,  7.1260e-01,
          1.2582e+00, -6.6468e-01],
        [-1.4044e+00,  6.7191e-01,  6.1892e-02,  1.0791e+00,  1.8108e+00,
          1.5722e+00,  1.9682e+00, -6.9238e-01, -1.8424e-01, -4.9209e-01,
         -1.5212e+00, -6.8972e-01,  1.1017e-01, -4.1080e-01, -1.0951e+00,
         -3.8469e-01,  1.4065e-01,  4.3593e-01, -2.9747e-01,  4.3895e-01,
          1.0417e+00, -7.8077e-01,  5.7511e-01,  9.8968e-01, -2.5299e-01,
         -8.9000e-01, -7.4429e-01, -2.1329e+00, -1.3324e+00, -8.8615e-01,
          2.4924e-01,  1.3782e+00],
        [-1.2693e+00, -7.0313e-01, -1.0413e+00,  5.5773e-01, -8.8970e-01,
          4.1514e-01,  1.1591e+00,  1.5510e+00, -3.5574e-01, -6.3637e-01,
          5.7083e-01,  1.7767e-01,  3.9121e-01, -6.4457e-01, -4.4978e-01,
         -1.2704e+00, -6.5871e-01,  1.0934e+00, -3.3148e+00, -4.8808e-01,
          3.8648e-01, -1.1242e+00, -7.7113e-01, -4.6745e-02,  8.9944e-01,
         -2.4505e-02,  3.1883e-01,  7.1802e-02,  1.6732e-01,  3.8725e-01,
         -2.4253e-01, -4.5155e-01],
        [-9.9402e-01, -6.9220e-01, -8.1934e-01,  1.4935e+00, -2.1941e-01,
         -4.4935e-01,  4.4216e-01,  1.3993e-01,  1.6076e+00, -1.2481e+00,
          1.7147e+00, -1.3322e+00, -1.3864e-01,  1.4752e+00,  1.2164e+00,
         -1.0356e+00, -5.3425e-01,  1.0560e+00,  1.9259e+00, -1.2799e+00,
         -4.9977e-01, -6.9626e-01,  7.3632e-01,  1.8699e+00, -3.4412e-01,
          1.7238e+00, -6.6791e-01, -1.6539e+00,  8.0119e-01, -8.4346e-02,
         -4.3955e-01,  7.4749e-02],
        [ 3.9984e-01, -2.5672e-01, -5.7510e-02, -1.0163e-01,  2.5327e-01,
         -1.3941e+00,  1.0632e+00,  3.2279e-02,  6.7664e-01,  1.2949e+00,
         -1.1213e+00, -6.2755e-01, -8.7020e-01, -1.1289e+00,  1.2770e+00,
          4.1636e-02, -2.0242e-01,  1.7182e+00, -1.5667e+00, -1.6202e+00,
          8.8644e-01, -6.0202e-01, -1.9558e+00, -1.5590e+00, -1.9446e-01,
          1.0663e+00, -1.5492e+00,  1.0156e+00,  9.0846e-01,  2.9217e-03,
         -1.5023e+00,  8.0622e-01],
        [-3.0557e+00,  1.9113e+00, -3.5591e-01, -4.8557e-01, -6.0835e-01,
          8.3786e-01,  1.0530e+00,  1.4022e+00,  1.6413e-01,  1.1333e-01,
          2.0928e-01, -1.1732e-01,  3.9191e-02, -3.8897e-02, -9.5553e-01,
          8.6345e-01, -9.2174e-02,  5.4715e-01,  2.4495e+00, -5.8613e-01,
         -1.1047e+00,  3.4833e-01,  9.7890e-01,  1.8129e+00,  3.1275e-02,
          2.0217e-01,  8.2366e-01, -3.9372e-01,  1.0992e+00,  2.4973e+00,
         -2.4061e-02,  3.0249e-01],
        [-4.5145e-02, -6.9328e-01, -6.4606e-01, -5.6156e-01,  3.0351e-01,
         -7.8708e-01,  1.8067e+00,  2.2433e-01, -1.8760e-02, -4.2292e-03,
         -3.8834e-01,  2.8474e-01, -1.0616e+00,  3.4917e-01, -9.7913e-01,
          6.2826e-01, -1.2705e-01,  1.5658e+00, -5.5466e-02,  9.4874e-02,
         -1.6128e+00,  7.7785e-01,  8.5924e-01, -1.3342e+00,  5.6155e-01,
         -1.4401e-01,  2.1599e-01,  1.1777e+00, -5.2085e-01, -7.1362e-01,
         -1.1218e+00,  4.6055e-01],
        [ 1.5610e+00, -9.6982e-01, -1.1578e+00, -2.2689e-01,  1.8806e+00,
          7.3222e-01, -2.5658e-01, -1.1342e+00, -3.9180e-02,  6.1475e-01,
         -1.0309e+00,  2.7969e-01, -1.1089e+00, -3.0400e-01, -1.1704e-01,
         -6.3294e-01,  2.4500e-01,  9.2791e-01,  1.0022e+00,  1.8238e-01,
          1.6958e+00,  5.3770e-01, -4.1404e-02, -7.5709e-01,  1.0288e-01,
         -2.4722e-02, -4.6819e-01,  7.0248e-01, -2.5063e-01, -4.8281e-01,
          8.3614e-01, -8.2543e-01],
        [-5.8089e-01,  8.5380e-01, -3.8030e-01,  6.2642e-01,  1.4676e+00,
         -1.0455e+00, -6.0908e-01,  1.7599e-01,  8.3955e-02, -1.7645e+00,
         -2.1029e+00,  1.7654e-01,  2.5514e-01,  2.3046e+00,  3.4923e-01,
         -1.8032e+00,  1.1363e+00, -1.1648e+00,  8.6874e-01,  9.9136e-01,
          3.9347e-01,  2.5669e-01, -7.6142e-01,  8.6425e-01,  4.6731e-01,
          6.6165e-01, -1.1949e+00, -6.2747e-01, -1.9571e-01,  3.1242e-01,
          1.7022e+00,  2.4641e-01],
        [ 3.9177e-01, -1.3211e+00, -1.5586e+00, -2.7077e-01,  5.4639e-01,
         -2.1472e-01,  8.0942e-01,  1.3397e+00, -7.1183e-01, -4.0542e-01,
          1.0153e+00,  1.4179e+00,  6.9783e-01, -3.1266e-01, -4.5430e-01,
         -1.4069e+00,  1.6856e-01,  3.7807e-01, -1.1757e+00, -1.1775e+00,
         -1.6387e+00, -7.5715e-01,  1.5517e+00,  8.7596e-01,  3.9563e-01,
         -1.0227e+00,  1.4998e+00, -4.4631e-02, -2.3807e-01,  3.9027e-01,
         -1.6005e-01,  9.7313e-01],
        [ 1.3490e+00, -7.4729e-01, -6.3041e-01, -1.4024e+00,  2.0660e+00,
         -8.9126e-01, -2.4578e-01,  1.3691e+00, -7.1976e-01, -6.5552e-01,
         -4.2809e-01, -1.6093e-02,  5.0854e-01,  3.5540e-01,  1.7696e-02,
          6.7050e-01,  7.3103e-01,  7.8330e-01,  5.2191e-01, -7.3079e-01,
          8.0732e-02,  5.9430e-01, -8.4487e-01, -8.9955e-01, -1.3665e-01,
         -2.9788e-02, -1.6353e+00, -1.1731e+00, -1.2257e-01,  9.1267e-01,
         -9.1640e-01,  2.6121e-02],
        [ 5.0265e-01,  3.0725e-01,  4.3979e-01,  1.0592e-01,  3.4745e+00,
         -1.2686e+00, -3.3120e-01, -1.1708e+00,  3.9594e-01,  7.0781e-02,
         -1.4726e-01,  5.5777e-01, -1.1808e-01,  8.2083e-01, -1.1503e+00,
          2.3815e+00, -6.3932e-02, -9.1180e-01, -6.1284e-01, -9.2166e-01,
          4.0148e-01,  3.6524e-01, -1.7292e+00, -3.6997e-01,  6.9063e-01,
         -1.2808e+00, -1.3034e+00, -1.1285e+00, -8.2959e-01,  9.3095e-01,
          1.5027e+00, -1.3375e+00]], device='cuda:0')
tensor([[-6.1594e-01,  6.3769e-02,  1.8539e-01, -7.2186e-01, -3.8502e-01,
          1.1318e+00, -1.0600e+00, -2.3954e-01, -6.4907e-01, -4.6563e-01,
         -4.5337e-01,  1.7582e+00,  8.9713e-01, -4.1840e-01,  7.5171e-01,
          7.7187e-01,  5.8087e-01, -1.5490e+00,  7.2463e-01, -1.1712e+00,
          2.5044e-01, -4.4759e-01,  2.0523e+00, -9.3107e-01,  5.1616e-01,
         -4.7551e-01, -5.4954e-01,  1.6251e-01,  1.7906e+00,  2.5769e-01,
         -2.2567e-01,  6.5973e-01],
        [-1.5195e+00, -4.1673e-01, -1.7546e+00, -4.6510e-01, -2.4430e-02,
          1.2811e+00,  3.3882e-01, -2.1221e+00,  2.8847e-01,  5.5282e-01,
          9.3129e-01, -1.6550e+00, -5.1142e-01, -1.3764e+00,  9.2389e-01,
          1.8377e+00, -1.4277e-01,  1.5495e+00,  2.1136e+00,  7.1664e-01,
         -5.0929e-02, -1.7525e+00,  6.4872e-01,  3.9004e-01, -4.1344e-01,
          1.6664e-01, -6.1190e-01,  3.1781e-01, -9.1056e-01,  5.6212e-01,
         -1.7006e+00,  7.3152e-01],
        [-4.4842e-01,  2.3018e-01, -4.4558e-01,  1.3626e+00,  3.9480e-01,
          3.5792e-01,  1.0655e+00, -9.0402e-01, -1.3256e-01,  2.0477e+00,
          3.7817e-02,  1.3176e+00,  2.3643e-01,  1.2457e+00,  1.3942e+00,
         -8.0162e-01,  1.1075e-01, -8.9988e-01,  4.5286e-01, -1.1307e+00,
         -1.9457e+00, -4.9847e-01,  1.0298e-01, -1.5415e+00, -6.1194e-01,
          2.0365e-02,  2.4462e-01, -7.5721e-01,  1.1520e+00,  1.1647e-02,
          1.1162e+00,  1.9428e+00],
        [-4.5093e-01, -4.0534e-01,  1.0535e-01,  2.8772e-01, -8.5873e-01,
          4.6853e-01,  8.8876e-01, -1.0169e-01,  3.7903e-01,  1.0447e+00,
          4.8925e-01,  5.8660e-01,  9.6342e-02,  2.4726e-01, -9.0233e-01,
         -1.8565e+00,  7.7249e-01, -9.8205e-01,  7.0302e-01, -8.1778e-01,
          1.6213e-01,  5.5659e-02,  1.1278e+00, -4.9968e-01, -5.5016e-01,
         -3.4820e-01, -1.0550e+00, -2.6804e-01, -1.7418e-01, -3.1804e-01,
          4.4269e-01,  1.6482e+00],
        [ 5.5659e-01, -2.9364e-01, -7.2443e-01,  2.8888e-01,  1.4791e-01,
          1.0421e-01, -1.1853e+00, -1.2189e+00,  1.1901e-01, -6.8776e-01,
          5.8774e-01,  9.7760e-02,  1.3193e+00,  1.2365e-01, -6.4672e-01,
          1.1483e+00,  4.4094e-02, -8.6916e-01,  4.9361e-01,  1.5402e+00,
          3.0187e-01, -4.7479e-01, -1.2904e+00, -9.2474e-01, -2.7029e-01,
          1.3013e+00, -2.2575e-01,  1.4070e-02, -4.8181e-01,  1.4256e+00,
          1.1536e-01,  7.0173e-01],
        [ 1.0518e+00, -1.7349e-02, -1.5379e+00, -1.1348e+00,  6.8331e-01,
         -1.2375e+00,  1.5314e+00, -3.6983e-01,  1.3969e+00, -7.1223e-01,
          2.4746e-01, -1.4011e+00, -1.2190e+00, -1.0005e+00, -5.4057e-01,
          2.3480e+00, -1.0202e-01, -7.6248e-01, -2.1035e-01,  8.2604e-02,
         -6.7543e-01,  1.0014e+00, -9.2988e-01,  1.1926e-01, -5.8020e-02,
         -3.9076e-01, -1.0540e+00,  1.6291e+00, -1.4678e+00,  1.1272e+00,
          4.5121e-01, -1.3643e+00],
        [ 5.5192e-01,  2.6567e+00, -9.6148e-01,  1.6391e-01, -1.5136e-01,
          6.7102e-01,  1.5903e+00,  1.6253e+00, -5.9162e-01, -1.2858e+00,
         -3.2215e-01, -9.5566e-01, -1.5385e+00,  4.6561e-01,  8.4809e-01,
          1.1284e+00, -4.1859e-01, -9.3495e-02,  6.6062e-01, -1.6732e+00,
         -5.6945e-01, -2.4847e-01, -7.6487e-01,  9.0584e-01,  4.2171e-01,
          2.5385e-01,  3.7505e-01, -7.0780e-01,  2.3166e+00, -2.0573e+00,
          9.6491e-01,  4.6491e-02],
        [-1.8454e-01, -8.8259e-01,  4.1620e-01,  1.6533e+00, -1.0563e+00,
         -1.3541e+00, -9.6975e-01,  3.9974e-01,  2.2184e-01,  8.2926e-01,
          3.9316e-01, -8.3311e-01,  1.2103e+00,  4.6478e-02,  9.6452e-01,
         -6.0165e-01,  2.2980e-01, -1.2941e-01,  1.9743e-01,  9.0291e-01,
          7.5142e-01,  3.9752e-01, -2.3605e+00,  5.7145e-01, -1.0069e+00,
         -6.8449e-01,  7.6996e-01, -1.6684e+00, -2.3921e-02, -1.3880e+00,
          8.0247e-01, -3.3993e-01],
        [ 1.0236e-01,  1.4430e+00, -1.1425e+00,  1.0607e+00,  5.5673e-01,
         -2.4244e+00,  1.6784e+00, -6.0093e-01, -5.0266e-01,  7.7128e-01,
         -4.8321e-01, -1.3065e+00, -1.7221e-01,  2.2155e-01,  9.7188e-01,
          3.9304e-01,  4.8762e-01,  3.1531e-01,  2.8408e-01,  1.1156e-01,
         -8.0734e-01, -3.8477e-01,  1.1560e-01, -9.2272e-01, -5.7651e-01,
         -7.2450e-02,  4.5025e-01, -1.7285e+00,  1.5124e-01, -2.7043e+00,
          8.6596e-01,  5.9846e-01],
        [-7.0316e-01, -3.5809e-01,  1.7972e+00,  2.9861e-01, -5.9403e-01,
          5.8334e-01,  2.7000e-01,  3.6444e-01,  1.4884e+00, -7.8008e-02,
         -3.7411e-01, -6.8769e-02, -1.4178e+00, -9.7706e-01, -1.0728e+00,
          4.7233e-01, -8.3752e-01,  5.1274e-01,  3.6534e-01,  6.8951e-01,
          3.6062e-01, -4.6244e-02, -8.8547e-01,  9.6439e-03, -8.0161e-01,
         -2.8688e-02, -1.3605e+00,  1.1027e+00, -4.4863e-02,  1.8269e+00,
         -1.2694e+00,  3.2702e-01],
        [-3.3136e-01, -6.5534e-02,  4.7662e-01,  4.3997e-01,  5.4902e-01,
          1.1153e+00, -2.2277e+00,  1.3955e-01, -7.0408e-02,  1.9086e-01,
          1.0421e+00,  7.0670e-01,  5.9293e-01,  4.5496e-01,  6.4163e-01,
         -5.5861e-01,  1.3470e+00, -2.5398e-01, -5.6270e-01, -6.0220e-01,
          1.6189e+00, -4.3616e-01,  1.2240e-01,  3.0495e-01,  6.7583e-01,
          2.2930e+00,  1.3090e+00,  5.7838e-01,  8.7728e-01,  1.1082e+00,
          1.3582e+00, -2.9794e-01],
        [-1.5723e+00, -2.9623e-01,  3.5639e-01,  5.9430e-01, -1.4085e+00,
          2.1229e+00,  1.2846e+00,  2.7095e-01,  4.3218e-01,  3.4663e+00,
         -6.6085e-01,  4.1104e-01,  3.9427e-01,  2.8383e-01,  4.0377e-01,
          2.0577e+00,  8.3857e-01, -1.3177e-01,  4.4502e-02, -1.0544e+00,
          1.0294e+00, -3.0840e-01,  6.8671e-02,  3.9174e-01, -1.4097e-02,
          2.0046e-02, -8.5881e-01, -4.1667e-01,  6.2800e-01, -3.8588e-01,
          4.0688e-01,  1.7184e+00],
        [-1.1161e+00, -3.3033e-01, -1.2051e+00, -1.4291e+00,  8.5555e-01,
          1.0717e+00,  2.3360e-01, -3.4676e-02, -5.8545e-01,  1.2602e-01,
          3.1125e-01,  1.3030e+00,  1.4601e+00,  5.0297e-01, -1.4337e+00,
         -9.2649e-01,  7.4938e-01,  6.4150e-01, -1.4198e-01,  1.0718e+00,
         -2.2868e-01, -3.7045e-01,  6.9683e-01, -2.7829e-01, -2.6793e-01,
          1.3098e-01,  2.0247e+00, -3.5421e-01, -2.4971e-01, -3.1744e-01,
          2.6347e-02,  1.4494e+00],
        [ 1.0489e+00, -9.4164e-01, -1.0215e+00, -4.5742e-01, -1.9065e+00,
          5.6008e-01, -1.2907e+00, -1.6399e-01, -1.3569e+00, -3.3128e+00,
          7.4353e-01, -2.0416e+00, -8.4144e-01,  1.3258e+00,  3.7201e-01,
          3.3829e-01, -8.2498e-01,  7.5915e-01,  3.8820e-01,  3.8833e-01,
          4.8882e-01, -1.5780e+00,  8.4108e-01,  1.0821e+00, -2.2246e-01,
          3.1160e-01, -6.7647e-01, -1.5101e+00, -2.0214e+00,  1.5856e-01,
         -1.2681e+00,  9.0735e-01],
        [ 6.2432e-01, -4.2450e-01, -1.6272e+00, -5.2679e-01,  2.6708e-01,
          5.2098e-01,  6.3853e-02, -7.1657e-02, -7.2615e-02,  3.4658e-01,
         -1.9141e+00,  1.5730e+00,  2.0069e-02,  2.4479e-01, -1.4781e-01,
          1.1596e+00, -1.8356e-01, -6.5728e-01,  1.7723e-01, -2.4869e+00,
         -1.9305e+00, -1.8324e-01,  1.3680e+00, -3.0767e-01, -4.5817e-01,
         -2.3564e-01,  9.3067e-01,  1.0948e+00,  7.8703e-01, -2.6999e+00,
          8.2290e-01, -1.9515e+00],
        [ 4.5538e-03, -2.0886e-01, -7.5628e-03,  1.0848e+00, -3.1091e-01,
         -1.4752e+00,  7.2902e-01, -8.8779e-02,  1.4672e+00, -1.4856e+00,
          8.6396e-02, -6.8815e-01,  2.3211e+00,  2.0315e+00, -8.8363e-01,
         -8.1624e-01,  5.4302e-01, -1.4376e+00, -1.1907e+00, -1.2527e+00,
         -2.2409e+00,  1.4900e+00,  9.2041e-01,  2.6791e+00, -1.0629e+00,
          3.4776e-01, -1.3213e+00,  1.0994e+00,  9.6616e-01,  6.9002e-01,
         -1.8442e+00,  1.8440e+00],
        [-7.3847e-01,  1.4888e+00,  6.6617e-01,  1.6488e-01, -2.5877e-01,
          5.6441e-02,  3.9293e-01, -9.8506e-01,  2.6577e-01, -9.5186e-03,
          1.0460e+00, -1.1407e+00, -2.2171e-01,  7.5412e-01, -5.7503e-01,
         -1.1994e+00,  7.5715e-02, -2.1179e-01, -1.1678e+00, -2.2760e-01,
         -7.8721e-01, -1.6278e-01,  1.3547e+00, -4.6753e-02,  6.6475e-02,
         -7.7796e-01, -2.2406e-01,  3.3111e-01,  1.3196e+00, -2.7721e-01,
         -8.8331e-05,  1.5057e+00]], device='cuda:0')
tensor([[ 0.9876, -0.0737, -1.2080,  0.0601, -1.0505,  0.5767, -0.1179, -0.4254,
          0.7123,  0.1259,  1.0602,  0.4918, -1.7522, -1.2866,  0.5553, -0.9158,
          0.9387,  0.6565, -2.0281,  1.8181, -1.2315,  2.8468,  2.4250,  1.2100,
          1.4419, -0.0502,  1.2501,  1.9028,  0.0204,  0.3651, -0.1438, -0.7639],
        [-0.0150,  0.5642,  0.5376, -1.1341,  0.8275, -1.2964, -1.3064, -0.3452,
          0.0067, -0.8876, -0.9012, -0.0339,  0.3781, -1.5872,  1.1427,  1.0431,
         -1.7003,  1.2265,  3.3151, -0.0798,  0.0208, -0.4030,  0.0786, -1.2598,
          0.1156,  0.3589,  0.8050,  0.9582, -1.0840, -1.7686, -1.2496, -0.7256],
        [ 1.7351, -0.0810, -0.1211,  2.4187, -0.9190, -0.5324, -0.3865, -0.6451,
          1.5011, -0.3755, -0.4514, -0.0146,  0.2787,  0.6111, -0.5303, -1.0261,
          1.5972, -0.0125,  1.3173, -1.9051, -0.5373, -1.8369, -0.5444,  0.8490,
          0.4482, -0.1908, -0.2194, -0.7356, -0.1074, -0.2255, -0.0801, -0.0413],
        [-1.7441, -1.3265,  0.6306, -0.8391,  0.7830, -0.0889,  0.9479, -1.3952,
         -0.8880, -0.0721, -0.2047,  0.2031, -0.8868,  0.7806, -1.1706, -0.7617,
         -0.2044, -0.4124, -0.0505, -1.7198,  0.5041,  0.3563, -1.4858,  1.8844,
          0.7759, -0.6853, -1.5706, -0.7845,  0.5181, -0.8884,  0.8896,  0.1451],
        [ 0.0405, -0.5995, -0.6220,  0.6700,  0.2643, -0.5002, -0.2329,  0.7534,
          1.4301, -0.6216, -0.0315,  0.8943,  0.4796, -1.5888,  2.2661, -1.6335,
         -0.8024, -0.9898, -2.6203, -0.5884,  2.4235, -0.2063,  0.6723, -0.9854,
         -0.1264,  1.0276, -0.1821,  0.2591, -2.5384,  0.4717,  0.7177, -0.4704],
        [ 1.3695, -0.1671,  0.2389,  0.5025,  1.2078, -1.5779,  0.7829,  0.1956,
         -0.2539, -0.7003,  0.8117,  1.2325,  0.0801, -1.2357,  0.2162,  1.3843,
         -1.4223,  1.0175,  0.1518, -1.0090, -0.4370, -0.5719,  2.1238,  0.4144,
          1.2499, -0.0779, -1.1522, -2.5719,  1.8476, -0.7622,  1.1773, -1.1361],
        [ 0.0886, -0.1525, -0.9218,  1.3578, -1.5264, -0.4866, -0.4033,  1.2141,
         -0.3597,  1.0454, -1.3788, -0.8447, -0.1051, -0.7734,  2.2102, -0.6187,
         -1.6863, -0.4184, -0.5528,  0.5796,  0.2446, -1.6986,  0.7733,  0.2744,
          1.8347, -1.0436, -0.5912, -0.2887,  0.3190, -0.7502, -1.3515,  1.1445],
        [-0.1387,  0.3260, -1.0844, -1.0983, -0.5399,  0.1221,  0.8799,  0.9250,
         -0.1215,  0.2007, -1.0505,  0.7176, -0.4904,  0.3676, -0.0158, -0.4049,
         -0.9854,  0.8890,  1.3193,  0.1191,  0.5048,  0.4401,  0.1595, -0.9324,
         -0.3116,  0.2994,  0.4006, -0.1220, -0.2897,  0.4153, -1.1023,  0.0192],
        [-1.8508,  0.3273, -0.4455,  0.1696, -0.5012,  0.3660, -0.1432,  2.4741,
          0.2883,  0.4826, -0.2696, -0.2665,  0.0664, -1.2156,  1.7743,  0.2271,
         -1.4607,  1.5244,  0.5323,  0.4580, -0.9531, -0.7759, -0.4016,  1.1451,
          0.0777, -1.0452, -0.7718,  1.5983, -0.1177, -1.1700,  1.5200, -0.9270],
        [-0.4326, -0.2210, -0.4189,  2.0653, -0.7810, -0.8177,  0.0058, -0.9829,
         -1.3259,  0.2587,  0.1086,  2.9041, -0.1408, -0.1139, -2.4729,  0.0375,
          1.6174, -1.1171, -0.1416,  1.0848,  1.6913,  1.5043, -0.8559,  1.5591,
          2.2736,  0.4819,  0.2702,  0.1153,  0.1569,  0.8265,  1.2821, -0.5254],
        [ 0.1732, -0.9680,  0.1558, -0.7071, -1.2121, -0.1451, -0.4938, -0.3069,
          0.5332, -0.5184,  0.1161, -0.3069,  1.9245,  1.8799,  0.1789, -0.0651,
         -1.8342, -0.2787,  0.6681, -0.2362,  1.6399,  0.6472,  1.2988, -0.9888,
          0.7688,  1.6218,  0.5612, -0.1280,  1.4704,  1.7979, -0.3514, -0.6175],
        [-0.1581,  0.3387,  0.4397, -0.8046, -0.2615, -0.2655, -1.1637, -0.3825,
         -0.7815,  1.0633, -0.7888,  0.6024, -0.2801, -0.8469,  1.0340, -1.0444,
          0.2641, -0.5522, -0.1311,  1.2109,  0.3137,  1.2650, -0.0613,  0.9112,
          1.0744, -0.7474,  1.1937,  0.9281, -0.3574,  0.9033, -1.2859, -1.5751],
        [ 0.0590,  0.2095,  0.9901,  0.4819, -0.4689,  0.7333,  1.0608,  0.5094,
          0.5776, -1.8426,  0.1117,  0.7273,  0.7082,  0.6937, -1.2391, -1.1504,
         -0.2944, -0.0644, -0.7297,  0.3102, -0.8230,  1.0584, -1.8485, -0.4652,
          2.2375,  0.7322,  0.7906, -0.8292,  1.0238,  0.6032,  1.6240, -2.4430],
        [ 1.3285,  1.1757,  1.1358,  0.0763, -0.4634,  2.2521, -0.8301, -0.9907,
          1.8954,  0.0860,  0.6908, -0.4671,  1.1048, -0.6268, -1.1377, -0.2359,
          1.0221,  0.3133, -0.8455,  0.5602, -0.6604,  1.7359, -0.2765,  0.2765,
          1.5192,  1.3571,  0.3048,  1.7571,  1.2867, -0.3138, -1.2297, -0.8626],
        [-1.0238, -0.2162,  0.6942, -0.1297,  0.5422,  0.7280, -1.7673,  0.4761,
          0.2962,  0.1650, -0.7187,  0.3931,  0.0339,  0.2234,  1.0457,  0.0782,
         -1.6507,  0.2367,  0.9438,  1.4250,  0.6818, -0.5283,  0.9324, -0.1106,
         -0.0321,  0.5304,  0.5550,  0.0335,  0.1120, -1.3276,  0.7135,  0.3612],
        [ 0.6704,  0.1152, -0.3220, -0.1724, -0.6038, -2.5524,  1.0390,  0.5115,
         -1.3882, -0.3423, -0.4182, -1.9621,  0.6140,  0.5840,  0.9329, -0.3259,
          0.6093,  2.4490, -0.5368,  1.0355,  0.5493,  2.1788,  0.1493,  1.5918,
          0.3114, -0.9081,  0.9179, -0.1140, -0.3388, -0.2099, -2.4099,  0.0378],
        [-1.9644,  1.8962,  1.1794,  0.1679, -0.6676, -0.2699,  1.1341,  0.4441,
         -0.3151, -0.9065, -0.9467,  0.3802, -1.0382, -0.3796, -0.6749,  1.0543,
          1.1884,  0.0257, -1.1675,  0.5911, -0.5178, -1.4182, -0.6807,  0.1397,
          0.0509, -0.7511, -0.3047,  1.2716, -0.4126, -1.1114, -0.4158,  0.5817]],
       device='cuda:0')
tensor([[-1.0428e+00, -1.3889e+00,  1.2213e+00, -7.7541e-01, -5.4943e-01,
         -3.9831e-01,  6.1622e-01, -1.2666e+00,  4.9581e-01,  1.8470e+00,
          4.2354e-02, -1.8248e+00, -2.5613e-01, -6.2198e-01, -1.2502e+00,
         -3.9659e-01,  1.4929e+00,  2.7117e-03,  6.1962e-01,  4.1728e-01,
          9.4380e-01, -1.0451e+00,  1.5594e+00, -9.0935e-04, -9.6858e-01,
          1.7527e+00,  3.0378e-01,  8.0610e-01,  4.1860e-01, -1.0186e-01,
          3.5075e-01, -2.2127e-01],
        [-1.3782e+00, -5.9221e-01, -9.1812e-01,  1.9660e+00,  2.2805e+00,
         -1.8484e+00, -8.9708e-01, -9.5519e-01, -1.1744e-01,  1.7650e+00,
          1.1776e-01,  8.6665e-01, -8.5434e-01, -1.1082e+00, -1.4100e+00,
          1.0198e+00,  1.2627e-01,  2.2220e-01,  6.2362e-01,  1.4282e+00,
          1.8456e-01, -1.3302e+00, -2.2188e+00,  3.4357e-01, -3.0117e-01,
         -6.8211e-01,  1.8310e-01, -5.0168e-01,  8.6680e-01, -1.3243e+00,
          6.2173e-01,  6.2804e-02],
        [ 1.4266e+00, -1.3574e+00,  3.2569e-01, -4.0309e-02,  1.0090e+00,
          3.8181e-01,  2.8212e-01,  7.9381e-01, -4.8703e-02, -1.1083e-01,
         -7.0790e-01,  2.4072e+00,  3.5699e-01,  2.1951e+00,  1.0817e+00,
          7.2924e-01, -8.1397e-01, -2.6186e-01,  1.2456e+00,  1.7068e-01,
          3.1453e-02, -1.0550e-01, -1.3992e+00,  9.2500e-01, -5.5974e-01,
          1.9935e-01,  4.4744e-01, -1.7228e-01,  1.8287e+00, -3.2851e-01,
         -8.1933e-01, -6.7285e-01],
        [ 1.2653e+00,  1.7380e+00,  5.5737e-01,  4.4773e-01,  6.2569e-01,
         -1.0698e-01,  7.3305e-01,  9.5781e-01, -5.4001e-01, -4.1652e-01,
         -5.4151e-01,  3.5131e-01, -3.5035e-01,  8.7186e-02, -1.6304e+00,
         -5.9338e-01, -1.1527e-02, -1.3462e+00,  5.3434e-01,  1.4135e-01,
         -1.5376e+00,  9.9449e-02,  4.0892e-01, -6.4786e-01,  1.5042e-01,
         -2.0373e-02,  9.1674e-01,  7.5143e-02, -1.3169e+00,  5.4475e-01,
          5.8591e-01,  2.2356e-01],
        [-6.3958e-01, -9.5476e-01, -1.3735e+00,  1.7956e+00,  1.2017e+00,
         -1.3988e+00,  5.2975e-01, -1.0589e+00, -8.2807e-01,  1.1012e+00,
         -1.1591e+00,  5.7099e-01, -8.8602e-01, -2.7087e-01,  7.7564e-02,
          6.7462e-01, -2.6119e-01, -7.3010e-01, -7.3847e-03, -2.7146e-01,
          2.0279e+00, -1.8542e-01, -4.7744e-01,  6.2657e-01, -8.9527e-01,
          2.3355e-01, -1.5309e+00,  1.0362e+00,  5.8406e-01, -1.0704e+00,
         -1.9279e+00, -1.1945e-01],
        [-1.5541e+00, -6.2160e-01, -5.2927e-01,  4.5764e-01, -7.2834e-01,
          1.4794e+00, -1.3094e-01, -8.0285e-01,  6.9726e-01,  1.5486e+00,
          1.6988e+00,  4.8880e-01,  1.0545e+00, -3.5443e-02, -1.1288e+00,
         -4.2812e-01, -9.4296e-03,  1.2142e+00, -4.7840e-01, -6.1202e-02,
          8.8992e-02, -1.2246e-01, -1.5827e-01,  3.4768e-01,  9.3544e-01,
          1.6366e+00, -1.0145e+00,  1.9332e+00,  2.6057e-01,  1.5613e+00,
          6.4027e-01,  2.4966e-01],
        [-4.1832e-01,  2.7431e-01, -1.6155e+00,  5.9936e-01,  6.0916e-02,
          4.8312e-01,  3.6449e-01,  9.7177e-01, -1.7059e+00,  3.2268e-01,
          1.4458e+00, -1.2625e-01,  2.7803e+00,  1.4578e-01, -3.3276e-01,
         -1.5086e+00,  1.7923e+00,  9.9484e-01, -1.5786e+00,  3.9185e-01,
         -1.2981e+00, -7.2375e-01, -6.7015e-01,  5.1645e-02, -1.7409e-01,
         -1.9933e-01, -1.7285e-01, -2.8660e-01, -2.4233e+00,  7.8094e-01,
         -4.9108e-01, -7.4143e-01],
        [-2.5861e-01, -1.7657e+00, -7.3830e-02,  1.7505e+00,  1.5797e+00,
          2.1609e+00, -3.5425e-01, -1.2583e+00,  1.8940e-01,  1.1492e+00,
          1.3932e+00, -4.0550e-01, -1.0246e+00,  1.8590e+00, -3.8725e-01,
          8.0356e-01, -2.5478e+00, -5.3835e-01,  1.0327e+00, -5.2548e-01,
         -3.7472e-01, -1.9506e+00, -1.1898e+00, -1.0787e+00,  1.4396e+00,
         -1.4362e+00,  2.9286e-01, -1.1864e+00, -4.3323e-01, -3.1497e-01,
         -1.8881e+00, -9.2561e-01],
        [ 1.4395e+00,  1.6972e-01,  1.7141e-01,  8.5275e-01, -1.5263e-02,
         -7.0083e-01, -1.2349e+00, -4.6372e-01, -2.3789e-02,  9.1640e-01,
         -6.1023e-01, -3.2583e-01,  4.3977e-01, -2.2515e+00,  5.6992e-01,
         -3.7682e-01, -1.6248e+00, -1.0185e+00,  3.8451e-01,  1.0764e+00,
         -2.0185e+00, -4.9205e-01, -2.4732e-01,  7.1103e-01,  9.5593e-01,
         -1.9233e+00, -1.2301e+00,  2.3151e+00, -9.8413e-01, -2.8469e+00,
          1.1102e+00,  3.8972e-01],
        [ 6.3442e-01, -2.5752e-01,  1.8640e-01, -5.1778e-01, -3.2666e-01,
          1.2812e-01,  1.7596e-01, -1.5680e+00,  4.6242e-01, -1.4200e+00,
          7.9538e-01,  2.2967e-01, -2.3936e-01,  8.5577e-01,  1.7556e+00,
         -7.4436e-02, -1.1949e+00, -5.7088e-01, -5.8469e-01, -1.4141e+00,
         -5.0358e-02, -2.5707e-01, -8.9955e-01,  5.8298e-01,  8.1179e-02,
          6.9070e-01, -1.8893e+00, -4.7525e-01,  1.8624e+00, -7.1836e-01,
         -9.5089e-01, -1.6408e+00],
        [-8.5202e-01,  5.7383e-01, -2.2079e+00, -1.1917e+00,  8.3670e-02,
         -1.1490e+00, -2.7644e-01, -1.4982e-01,  5.5409e-01, -5.0060e-01,
          4.7477e-01,  6.3769e-01, -1.3224e-01, -7.7886e-02,  2.2338e+00,
          5.3754e-01,  1.2519e+00, -1.2764e-02,  1.6732e-01, -1.0251e+00,
         -1.2613e+00, -4.4849e-01, -1.3850e-01,  1.2214e+00,  5.3168e-01,
         -1.8602e+00,  1.3500e+00,  1.2068e+00, -1.9443e+00,  3.2714e-03,
         -4.0554e-01, -1.1311e+00],
        [-3.0357e-01,  6.0343e-01,  6.4203e-01, -1.0789e+00,  1.0914e+00,
         -2.2205e+00, -2.8473e-01, -3.7497e+00, -1.2169e+00,  1.6194e+00,
         -8.1543e-01,  2.0310e+00,  3.9326e-01, -4.8562e-01, -1.3005e+00,
          1.1134e+00, -3.6407e-01, -6.5294e-01,  8.0342e-01,  3.7752e-01,
          3.8413e-01,  8.7996e-01, -1.9087e-02,  1.5337e+00, -1.4967e-01,
          1.3718e+00, -5.7459e-01,  1.3946e-03,  7.3736e-01,  9.9510e-01,
          7.4720e-01,  1.5991e+00],
        [-2.4887e-01,  3.7004e-01,  5.6089e-01,  3.4900e-01,  8.2977e-01,
          2.1242e-01,  1.2119e+00,  1.6248e+00, -1.1246e-01,  8.9838e-01,
          7.8384e-02, -9.8680e-01,  7.3578e-01,  1.4597e-02,  1.6158e+00,
         -1.3123e+00, -1.1562e+00, -6.3247e-01,  7.2185e-01,  1.5220e+00,
          1.3434e+00, -1.5489e+00, -7.9194e-01,  2.8017e-01,  8.4483e-01,
          2.6948e+00,  7.1361e-01, -3.9589e-01,  1.2202e+00, -4.2983e-02,
         -5.9904e-01, -1.9566e+00],
        [-6.9146e-01, -5.4180e-01,  6.0365e-01, -7.6269e-01,  1.6320e+00,
         -5.7476e-01,  2.5004e-02, -1.1461e-02, -4.3181e-01,  8.5353e-01,
         -1.4008e+00,  2.4232e+00, -4.6766e-01, -5.2301e-01,  3.6247e-01,
         -6.7494e-01, -3.9123e-01, -6.3066e-01, -1.4406e+00, -6.8261e-01,
         -7.5405e-01,  7.6082e-01, -1.4472e+00,  5.4494e-01, -9.6075e-01,
          5.8442e-01, -3.1423e-01,  1.9643e-02, -1.6068e+00, -1.0636e-01,
         -8.3831e-02,  1.7309e+00],
        [-2.6834e+00,  2.1384e+00,  4.8529e-02,  8.7889e-02, -6.5363e-01,
         -5.8674e-01, -5.7882e-01, -3.7249e-01, -5.3014e-01, -2.0849e-01,
          4.9639e-02,  1.6149e+00,  6.8403e-01,  3.1497e-01,  5.6276e-02,
         -1.0744e+00, -4.0843e-01, -7.1121e-01,  2.4416e-01,  1.5123e+00,
          2.0254e-03, -1.3643e-01,  2.1520e+00, -1.0879e+00,  2.0259e-01,
          8.5339e-01,  2.2851e+00, -1.1836e+00,  1.5019e+00, -2.3568e-01,
         -1.7966e+00,  1.1178e+00],
        [-7.7943e-01, -1.1089e+00, -1.2880e-01, -1.2854e+00, -6.9668e-01,
         -5.4258e-01, -5.9510e-01, -5.4733e-01, -6.7187e-02, -4.3319e-01,
         -4.6348e-01, -1.0111e+00, -2.1979e-01, -1.1304e+00, -1.0930e-01,
         -5.0666e-01, -8.1043e-01,  1.0064e-01,  4.0331e-01, -6.2570e-02,
          8.4448e-01,  1.4376e+00,  9.2239e-01,  2.1066e-01,  1.6613e+00,
          2.2482e-01,  2.1123e+00,  6.3172e-01,  8.6612e-01,  5.2756e-01,
         -3.2933e-01,  6.6270e-01],
        [-8.3220e-01,  8.4342e-01, -8.3408e-01,  1.6811e-01,  7.9338e-01,
          1.5102e+00, -1.1603e+00,  9.7624e-01,  7.1466e-01,  6.8866e-01,
         -2.2925e+00,  4.4613e-01,  3.6435e-01,  7.4787e-01, -1.7027e+00,
          3.0334e-01,  6.2633e-01,  1.1621e+00, -6.0009e-02, -1.7866e+00,
         -1.8106e-01,  2.5103e-01,  4.1161e-01,  5.6215e-01, -9.9735e-01,
          1.7227e+00,  2.0168e-01,  3.1401e-01,  6.8219e-01,  6.7912e-02,
         -7.1672e-01,  3.3630e-01]], device='cuda:0')

 34%|###4      | 11/32 [00:00<00:00, 106.00it/s][Atensor([[ 0.2055,  1.1242,  0.1350, -0.1931, -1.1512,  0.3578, -0.5489, -1.0387,
          1.5649, -0.7568, -1.6341,  0.0498, -0.2514, -1.3011, -0.4643,  0.7466,
         -0.9085, -0.2124,  0.7984, -0.3435,  1.3506, -0.9349,  1.3934,  0.9988,
          0.3870,  1.4099, -1.3628,  0.0269,  0.3004,  0.8266, -0.4799, -1.5347],
        [ 1.4371,  0.4681, -0.1049,  1.4715, -0.9512, -0.0466,  0.0548,  0.8172,
         -0.3365, -0.0774,  0.5503,  0.4395, -1.1023,  1.1941, -0.6743,  0.0890,
          0.0137,  1.6018,  0.7962,  0.5621,  1.0671, -0.8934, -0.8458, -1.2053,
          1.0833, -0.6052, -0.3085,  0.6295,  0.7544, -0.0738,  1.5436,  0.4091],
        [ 0.8936, -1.1463, -1.4111,  0.2700, -0.3846,  0.1849,  0.8311, -0.2280,
          0.3897, -0.6393, -0.8354, -1.9401, -0.1201, -2.1033, -1.2303,  0.6468,
         -0.2367, -0.5250,  0.6921,  0.7695,  0.8997,  0.9699,  2.6157,  0.0682,
          0.4284, -0.1300,  0.5553, -2.9504, -0.3379, -1.6006, -0.1173, -0.3296],
        [-1.5001,  0.7870,  2.1018, -0.4834, -2.7336,  1.6342, -0.7725, -1.1184,
         -0.5484,  1.9256,  2.6860,  0.2557, -0.5999,  0.0098,  1.2408, -0.2097,
         -0.9974,  1.1552, -1.1067,  0.0801, -0.0235,  0.4385, -0.0927,  0.4592,
          1.1666,  0.3544, -1.5612,  0.8511,  0.2154,  2.2645, -0.8466,  0.3754],
        [ 0.6360,  1.2131,  0.8666,  0.9958,  0.2637, -0.4584, -1.2477, -0.4296,
          0.5205,  0.7360,  0.0481,  1.4590, -2.1459, -0.0086,  1.4067,  0.1799,
          0.4504,  2.0231, -0.8222,  1.6073, -0.9361,  1.2297,  0.7497, -0.2540,
         -1.2913, -0.1020,  1.3711, -0.7471, -1.3786, -0.8108,  0.3893, -0.1683],
        [ 1.4640, -1.3699,  0.3315, -0.0868,  0.2302,  0.4563,  0.2048, -0.2270,
          0.4469,  1.8711, -0.5696, -0.6686, -1.5997,  0.6743, -1.0740, -0.9841,
          1.4368, -1.1734, -1.2567,  0.9146,  0.5798,  0.6682,  0.2346,  0.5661,
          2.0890,  1.4287,  0.7674, -0.0592, -0.4165,  0.2277, -0.4731, -0.4107],
        [ 1.9642, -1.1463, -0.2381, -0.0446,  0.0510, -0.1734, -0.1385, -1.7024,
         -0.9637,  0.1687, -1.3530, -1.2721, -0.0429,  1.0471,  0.1010, -0.6995,
          2.7898,  0.6211,  0.6757, -0.1352,  2.0571,  0.3857, -0.0496, -0.7114,
         -0.6968, -0.3148,  2.0262,  0.0324,  0.5641,  0.2600,  0.7480, -0.2345],
        [ 0.1882, -1.4197,  1.1548, -2.3401, -0.3020, -1.9504,  1.4649,  0.2744,
         -0.2978, -0.3555,  0.1746,  0.3841, -1.0557, -0.9968, -1.1508, -1.6785,
          1.2812,  0.5238, -1.0702, -2.7187,  0.7182,  0.6083,  1.7446, -0.6263,
         -0.4407, -0.4360,  0.3413, -0.6545,  0.6230, -0.6169,  0.3757,  0.8570],
        [-0.2410, -1.4243,  0.4100,  0.7172,  0.2709,  0.2129, -0.1076, -0.6499,
         -0.4569,  1.5569, -1.6592, -1.5182,  1.3079, -0.1321, -0.0290,  2.1917,
          0.3281, -1.1889, -0.4469,  0.5425,  2.0966, -0.3512, -0.7059, -0.5241,
          0.1705,  0.8695, -0.1679, -0.0162,  2.2915, -1.5582,  0.3748, -0.1461],
        [ 0.3044, -0.9042,  1.3361, -1.1386, -0.2774,  1.3466, -0.7554, -1.7110,
         -0.0978, -4.0106, -1.5347, -0.6504,  1.1084, -0.6205,  1.8275,  0.5451,
          0.7064,  0.7764,  0.3058, -0.3886, -1.3645,  0.9518, -1.0504, -1.5585,
          0.3643, -0.1048,  0.4510, -0.5299, -0.5984, -0.6121,  0.1871,  0.1866],
        [ 0.8862,  0.6937,  1.7398, -0.7550, -1.2565,  0.0450, -0.7838,  0.1076,
          2.0959, -0.1424, -1.5685, -0.8814, -0.7757,  0.1739,  1.5712,  0.0504,
          1.3574,  0.1131,  0.9410, -0.2139,  0.4055, -0.8591, -2.5068, -1.3842,
         -0.4621,  1.4403, -0.4186,  2.6367, -0.2538,  1.4274, -0.1236,  1.0579],
        [-1.1773,  0.2115, -0.3186, -0.2654, -1.1691, -1.4532,  1.0105,  0.6979,
          0.3733, -0.6504, -0.3022,  0.8850,  0.7881,  0.5944, -0.1745,  0.2462,
         -0.3184, -0.4394,  0.6493, -0.1413, -0.5663,  0.2950,  1.7267,  1.8155,
          0.8385,  0.7606, -0.2335, -0.0321,  1.0310, -1.5654,  0.7649, -0.5265],
        [-0.1559, -0.5345,  0.8629,  0.2310,  0.8520, -0.9666, -1.0624,  1.5940,
          0.3707, -1.9746, -0.1592, -0.6919, -0.2194,  0.3928,  1.5574, -1.4062,
         -0.4038, -1.6131,  0.9648, -0.4760, -0.7527, -2.1563,  0.0320, -0.9543,
         -0.4569, -1.1751,  0.4110,  0.8813, -0.6751,  0.1976,  0.8640, -0.2246],
        [ 0.9788, -0.3245, -0.4367,  0.1253, -2.0993, -0.2963,  0.5958, -0.2984,
          1.6354, -0.1874, -1.7197, -1.0081, -0.8543,  0.5164, -0.6856, -1.3712,
         -0.3967, -1.0917, -1.9549,  0.2163, -1.5152, -0.1072,  1.3111, -0.3729,
         -1.3711,  1.2939, -0.5415,  1.5163,  0.5620, -2.2834,  0.8110,  1.3425],
        [-1.0904, -0.9974,  0.0453, -0.0197, -1.4730, -0.3097, -0.4881, -2.2434,
         -2.2672,  2.2067, -0.5014, -0.1534,  0.1196, -0.3620,  1.9091, -2.3102,
          0.3546, -0.6481,  0.2863, -1.5031,  0.5543,  2.3164, -1.0704, -0.1456,
          0.0817, -0.6859, -0.4971, -0.0557,  1.2193,  1.0048, -0.8511,  1.7749],
        [ 0.7754, -1.6077,  1.3067, -0.4459, -0.8439,  0.4990, -0.4206, -1.2154,
          0.0974, -0.2840, -0.5445,  0.1072,  1.7882,  0.0520,  0.5967, -0.9919,
         -0.7741, -0.9850,  0.7985, -0.4058, -0.3788,  0.8522,  0.0600,  0.0653,
          1.3578, -0.9838, -0.3367, -0.5076,  0.2645, -0.9300, -1.1466,  0.1056],
        [ 0.6652, -1.1607, -0.0225,  1.5539,  1.5252, -0.2877, -0.2142,  1.6490,
         -0.3944,  1.7994, -0.4659, -1.0470, -0.1232, -0.7170,  0.3762, -1.5040,
          0.0225, -1.3430, -0.2272,  1.0589, -0.1516, -0.0769, -1.6444, -2.3315,
         -1.9009, -0.2162,  0.5760,  0.5694,  1.0732, -0.3882,  0.7027, -1.4911]],
       device='cuda:0')
tensor([[-2.4049,  0.2474,  0.8811,  0.8595, -0.8623,  0.4890,  0.4546,  1.5962,
          0.8334,  0.9155, -0.0558,  2.7193, -0.4234,  0.2173, -0.9022,  0.6156,
          0.4918, -0.1165, -0.5019,  0.6821, -1.4367, -0.5561,  1.7512,  1.0834,
          0.7164,  1.9471,  0.2879,  0.0690, -1.6493, -0.0520, -0.9933,  1.7835],
        [ 0.4622, -1.0074, -0.4945, -0.8376, -1.8620,  0.4552, -1.0220, -1.0230,
          0.5654,  2.7844,  0.3610,  1.5142, -0.2292, -0.0470, -1.1793,  1.6954,
         -0.8969, -0.3572,  0.8160,  0.6764,  0.0813,  0.5823, -0.9173,  1.2886,
         -0.3239, -0.2509,  0.5466,  0.7023, -0.3267, -0.5359, -0.7316,  0.9262],
        [-0.4267, -0.5543, -0.0380,  1.0488,  0.8635, -0.4113,  0.2246,  0.3610,
          0.7165, -0.3652,  0.7818,  0.6545, -1.1503,  0.7562,  1.1893,  1.4847,
          0.9785,  0.7551,  0.8702,  0.6194,  2.0732, -1.4184,  0.7852, -1.4270,
         -0.2391,  0.5193,  0.6410,  0.5654,  0.2079,  0.5641, -0.6525,  1.4249],
        [-0.0231,  0.3557,  0.2737,  0.4313,  0.8939, -0.0813, -1.7557,  0.3357,
         -0.2805, -2.0734,  0.5185,  1.7564, -0.6259, -0.1614,  0.4645, -0.8036,
          0.6993,  0.0316, -0.6173,  0.5026,  1.0796, -1.4377,  0.5200, -0.0726,
          1.3671, -0.3651,  0.0141, -2.0840,  1.0627, -1.6102,  0.4607, -1.4960],
        [ 1.1788,  0.3363, -1.3659, -1.5402, -0.5618, -0.9775, -0.3297,  2.0848,
         -0.1187, -0.9005,  1.2204,  0.9327, -0.4308, -1.6236,  1.2148,  2.1911,
          0.3065,  2.2573, -3.0403,  0.9358, -0.3623, -0.7135, -0.9999, -0.6602,
          0.4856, -1.0645, -0.8221,  0.9306, -0.1799, -0.6195, -0.1520,  0.5433],
        [ 0.5859, -0.2892, -0.4639, -1.8104,  0.4546,  0.5683,  1.2247, -0.7958,
          1.9239, -0.7328, -1.5833,  0.4880, -0.1559,  0.4877, -0.4986,  0.5040,
         -0.6933, -0.1929, -0.2377, -1.0947, -1.0182, -0.1019, -1.4977, -0.8419,
         -0.9468,  0.1449,  0.9389, -0.9000, -1.6793,  0.9456,  0.3692, -1.1078],
        [-0.1957,  0.6251, -1.1773, -3.0598, -0.3907,  1.8613,  0.9330, -1.3871,
          0.4201,  0.8130, -1.0150, -0.4226, -0.8949, -0.1739,  0.4519, -0.9960,
          1.1405, -0.0730,  1.2321, -0.7086,  0.1557, -0.3670, -0.0644,  0.1108,
         -0.8737, -0.4840, -1.1558,  1.0856, -0.4398,  0.1909,  1.3261,  0.1031],
        [ 0.7268,  0.8710, -0.6038,  0.5300, -0.5664, -0.9114, -0.7333,  2.3721,
         -0.1578, -0.7066,  1.2628,  1.8518, -0.3164, -0.6408,  1.5126, -0.6912,
          1.9698,  1.8992, -1.5288,  0.6968, -1.3529,  0.9311,  1.0279, -0.4672,
         -0.3033, -0.0903,  0.0118, -0.2224, -0.1878, -0.0209, -0.4641,  0.2449],
        [ 0.2345,  0.4092, -1.5085, -1.2305,  0.4900,  0.2382, -0.6962,  1.0663,
         -2.6728, -1.0004,  0.4968,  1.5830,  1.3211,  0.2064,  0.1222,  0.6114,
         -1.0558, -0.0496,  0.4204, -1.4189, -2.9545,  0.4514,  0.3188,  0.5956,
         -0.1517,  0.7520,  0.2523,  0.2476, -0.0808, -0.9796, -0.5189, -0.6649],
        [-0.0952,  1.1315, -0.2957, -0.7351, -2.0779, -0.5706, -1.4670, -0.6047,
          0.6009, -1.5653,  1.6858,  0.1926, -0.9594,  2.1726,  0.4592,  0.7434,
         -0.2191, -0.5008, -1.5439, -0.4040,  2.0187, -1.0499,  0.8454,  0.2827,
         -0.1150,  1.9276, -0.6629,  0.8032,  1.0073,  0.9825,  0.6694,  1.0470],
        [-0.4137, -0.0316, -0.6087, -0.9826, -1.5610, -0.0286,  1.2922,  0.5906,
         -0.3783, -0.6722, -0.9046,  0.4960, -0.3605, -1.5466,  0.5342,  0.6923,
          1.0237, -0.0146,  0.2066, -0.6367, -1.0130,  1.0248,  0.2289,  0.3646,
         -0.6805, -0.3034, -1.0525,  0.6010, -0.4004,  0.7690, -2.1228,  1.2426],
        [ 0.9075,  0.6121,  1.1476,  0.5724, -0.4463,  0.3577, -0.1591,  0.1797,
         -0.7101,  0.8182, -0.1066,  0.2268,  0.2547,  1.3517,  0.8842, -1.8261,
          0.4433,  0.2406, -0.1617, -0.1263,  0.4742, -1.1519, -0.9431, -0.5151,
         -2.0691,  0.6953,  1.1145, -0.3747, -0.9718,  1.1112, -0.5270, -0.2576],
        [ 0.3487, -0.0847, -0.5503, -1.0088,  1.0798,  0.3561, -1.1210,  0.7774,
         -0.8774,  1.2475,  2.8637, -0.5533, -1.2801,  0.0358, -0.8324, -0.9390,
          2.3912,  0.1724, -1.0309, -1.1539,  0.3211, -0.1069, -0.5082,  0.5571,
         -0.3508, -0.8739, -0.1306, -0.2416, -1.9499, -0.6694, -0.3739, -0.9798],
        [-0.2122, -0.9547,  0.4190, -0.2831, -1.2709, -1.2813,  0.2074,  0.5068,
         -0.1053, -0.8539, -0.5662, -0.1735, -1.4126, -1.0781, -0.1414,  0.6585,
         -1.7524, -0.1603, -1.4492, -0.7424, -1.1706, -0.6067, -1.6643, -0.5395,
          0.4462,  1.2282,  0.4433, -0.5041,  0.4643,  0.4809, -0.1659,  0.2807],
        [-0.8667,  0.3110,  0.5526, -0.7941,  0.9270, -0.2312, -1.3169,  1.1817,
         -0.7868, -1.2321,  0.3328,  0.0797, -0.9458, -0.7486, -0.5022, -1.0840,
          0.7032, -0.8894,  0.0764,  1.0566,  2.7938,  0.0031, -1.6524, -1.0420,
         -0.3063,  0.3551,  0.8628, -0.5955,  0.0522, -1.7343, -0.1590, -1.9592],
        [ 0.3666,  1.8084,  1.7390,  0.7104,  1.2822, -1.6354, -1.5662,  0.0429,
          0.1812, -0.4001, -0.2381,  0.7762, -0.4325, -0.4113, -0.2614,  0.7995,
         -1.1884,  1.2402,  0.9228, -0.8644,  0.1555,  0.1759,  0.0259,  0.3162,
          0.3660, -1.8765,  0.1737,  1.9084, -0.3705,  0.9561,  0.0421,  1.2573],
        [-0.9451, -0.8911,  0.0304,  0.3723, -0.3093, -0.4232,  0.7164,  2.1750,
          0.7609, -1.1600,  0.2937,  1.4286,  1.1174, -0.2325, -0.2568,  0.6358,
         -0.7213,  0.0521,  0.2758, -0.7591,  0.2455,  0.8992, -0.2364,  0.2587,
          0.6808, -0.1532, -0.1923, -1.0384,  0.5326, -1.1796,  0.3347, -0.7447]],
       device='cuda:0')
tensor([[ 1.2808e+00,  1.7090e+00,  8.6766e-01,  1.2052e+00, -9.6414e-01,
          6.1265e-01,  1.1503e+00,  1.0434e+00, -5.7943e-02,  9.9288e-01,
          6.4896e-01,  2.9797e+00,  3.7299e-01, -7.4131e-01,  3.2090e-01,
         -7.4858e-01, -5.0234e-01, -5.1814e-01, -2.9355e-01,  1.0568e-01,
         -6.6122e-02, -1.6284e+00, -2.0064e-02, -6.7152e-01, -5.2146e-01,
         -3.3258e-01, -1.1863e+00, -7.8077e-01, -6.9845e-01,  5.9734e-01,
          2.4563e-01,  8.4919e-02],
        [-4.4972e-01,  6.3528e-01, -2.6933e-01, -2.4417e+00,  1.8417e-01,
          1.6408e+00,  1.0562e+00,  1.0428e-01,  1.0052e+00,  8.2960e-02,
          1.1759e+00,  6.0304e-01,  1.1540e+00,  2.3481e-01, -9.0945e-01,
         -6.9803e-01,  8.2712e-01, -1.5445e+00, -7.2147e-01, -3.6431e-01,
         -9.7763e-01,  6.3894e-02,  3.5379e-01,  1.0640e+00,  6.6827e-01,
         -2.4047e-01,  4.5743e-01,  9.7100e-01,  9.6642e-01, -1.7028e-01,
         -1.4844e+00, -1.9471e+00],
        [-1.0995e+00, -4.9236e-01,  2.4078e-01, -7.8615e-01, -1.0829e+00,
         -8.4871e-01,  1.2910e+00, -1.1530e+00, -3.8314e-01,  1.6270e+00,
          6.1942e-02,  7.8750e-01, -3.9493e-01,  1.0721e+00, -1.3525e-01,
          1.0271e+00,  1.7125e+00, -2.9587e-01, -6.8516e-02, -1.4181e-01,
          7.9921e-01,  1.0976e+00,  1.9848e+00, -4.8001e-01,  1.3834e+00,
          1.1805e+00, -3.0427e-01,  1.1967e+00,  1.7104e+00, -1.2423e+00,
         -3.2303e-01,  2.1776e-01],
        [ 8.3220e-01, -2.6444e-01, -5.3659e-01, -4.8611e-01, -1.7405e-01,
         -7.2980e-01,  1.6294e+00,  1.0980e+00,  1.2556e-01,  4.4362e-03,
          3.2079e-01,  6.3570e-02, -6.6691e-01, -6.2458e-02,  5.7767e-01,
          2.8405e-01,  1.0078e+00, -1.8673e+00,  1.0157e+00, -1.1908e-01,
          1.7474e+00,  9.1851e-01, -1.9045e-01,  1.0836e+00, -6.7902e-01,
          8.6191e-01,  2.2194e-01, -1.0778e+00, -7.7293e-02,  9.1011e-01,
         -6.3836e-01,  1.3426e+00],
        [ 1.1084e+00,  9.8926e-01,  5.0681e-02,  1.3956e+00,  8.4146e-01,
          8.1180e-02, -2.0113e+00,  4.2399e-01,  3.2807e-01,  8.9289e-01,
         -8.8337e-01,  1.1601e+00, -3.8070e-01, -9.6770e-01, -3.7218e-01,
          8.9131e-01, -1.4926e+00, -1.3673e+00, -1.7929e+00,  1.0438e+00,
          6.5885e-02, -4.4107e-01,  1.5804e+00,  1.7728e-01, -4.4408e-01,
          4.3417e-01,  4.0053e-01,  3.5110e-01,  1.5485e-01,  1.4516e+00,
          2.3852e-01,  3.4985e-01],
        [ 5.6860e-01,  9.8507e-01,  4.0309e-01,  1.0689e+00, -1.0462e+00,
          1.4873e+00, -3.8026e-01, -1.9747e+00,  2.8461e-01,  1.5061e+00,
         -1.6572e+00, -7.0171e-02, -2.8348e-01, -1.5881e+00,  6.1435e-01,
         -1.6298e-01, -1.0980e+00, -1.6803e+00,  6.5305e-01,  4.1863e-01,
          1.1662e+00,  1.6085e-02, -1.4137e+00,  1.0413e-01,  2.1528e-01,
         -4.6227e-01,  6.2142e-01, -1.6759e-02,  1.0723e+00, -3.4343e-01,
          2.2024e-01,  2.5664e+00],
        [ 1.1359e+00, -9.6538e-01,  9.9679e-01, -5.8826e-02, -1.2804e+00,
          1.7420e-01,  3.9078e-01, -1.1667e+00, -6.0340e-02, -6.2627e-01,
         -1.5887e+00,  7.4622e-01,  1.1483e-01, -9.0136e-01, -2.2068e-01,
         -4.8923e-01, -7.1552e-01, -3.0481e-01, -1.5066e+00, -9.1201e-01,
          2.9692e+00,  8.0167e-02, -6.1991e-02, -2.0087e-01, -2.7571e-01,
          6.5984e-01,  3.8306e-01,  4.8404e-02,  4.5831e-01, -9.1560e-01,
          4.1648e-01,  8.6169e-01],
        [ 5.6624e-02,  4.4476e-01,  1.0703e+00,  7.3946e-01,  1.6420e-01,
         -6.4210e-01, -1.9678e+00, -3.9178e-01, -9.5939e-01, -2.0556e-01,
          1.0168e-01, -6.4428e-01, -1.2097e+00,  5.6784e-01,  4.1443e-01,
          8.3154e-01,  8.2421e-02, -2.1743e-01,  1.2281e+00,  8.6086e-01,
         -4.0645e-01, -4.6371e-02, -6.2683e-01,  1.2690e+00, -1.1584e-01,
         -5.8627e-01,  1.8609e+00, -6.5064e-01,  1.2025e+00, -9.4985e-01,
          4.2868e-01, -2.7796e-03],
        [-3.4833e-01,  3.5907e-02,  5.5080e-01,  1.6980e+00,  1.0743e+00,
         -4.6811e-02, -6.2003e-01, -7.9321e-01,  6.9702e-01, -5.5813e-01,
          9.5862e-01, -7.1813e-01,  1.2795e+00,  2.0856e-01,  2.0280e+00,
         -7.6237e-01,  1.0029e-01,  1.2707e+00,  1.2995e+00, -7.4145e-01,
         -1.2835e+00, -8.1977e-01, -6.7716e-01, -2.5113e-01, -6.8195e-01,
          4.3523e-01, -9.6725e-01, -9.6911e-01, -7.8435e-01, -8.1212e-01,
         -5.4747e-01, -1.4813e+00],
        [ 1.4513e+00,  2.2258e-03,  1.2799e+00, -4.6077e-01,  5.7668e-01,
          1.1345e-01,  6.3025e-01, -2.6230e+00, -6.6823e-01,  1.3618e+00,
          8.9660e-01, -1.4607e+00, -1.6327e+00,  1.1777e-01,  5.9252e-01,
         -1.4433e+00, -1.1954e+00,  6.4452e-01,  1.6197e+00,  3.1763e-01,
          2.3151e+00, -1.5626e+00, -2.0155e+00,  3.8626e-01,  7.6124e-01,
         -2.1601e+00,  2.1363e+00, -1.0673e-01,  7.2587e-01,  3.4582e-01,
         -4.0525e-01, -1.3681e+00],
        [ 1.4771e+00,  9.9916e-01, -1.5669e+00, -1.0441e+00, -1.2105e+00,
          1.0482e+00, -1.1142e-01,  6.5109e-02,  4.9247e-01,  4.3891e-01,
         -7.2102e-01, -1.0802e+00,  1.5654e-01, -4.0336e-01, -3.1232e-01,
          9.5587e-01,  2.7823e-01,  3.7129e-01, -2.0397e+00, -5.2047e-01,
          6.8362e-01,  1.2582e+00, -6.8589e-01, -7.7019e-01,  5.8715e-01,
          4.4764e-01,  1.2449e+00, -5.7928e-01, -1.9186e+00,  1.1248e+00,
         -2.4502e-01,  3.3204e-01],
        [ 9.9903e-01,  6.3477e-01,  1.0653e+00, -1.2958e-01,  5.0646e-01,
          8.1926e-01, -4.0679e-01,  1.7071e+00, -1.8928e-01, -1.0047e+00,
          4.1705e-01,  7.9900e-02,  6.2226e-01,  9.4699e-01, -5.6563e-01,
          8.1665e-02, -7.8161e-02, -1.3386e+00,  1.6972e-01, -5.7344e-01,
         -8.1610e-01, -9.9857e-01, -2.8435e-01, -1.3069e+00,  1.3868e-03,
          2.0987e+00, -8.4398e-01,  4.1046e-01, -7.9414e-01,  1.6238e+00,
          2.7730e-01, -5.4225e-01],
        [-1.3824e-01,  8.9995e-01,  1.1727e+00, -1.1862e+00, -1.4273e+00,
         -4.6541e-01, -2.4938e-01,  1.5940e+00, -1.0111e+00, -6.1491e-01,
          3.0168e-01, -1.1594e+00, -8.2580e-02, -1.2761e+00, -1.1790e-01,
         -3.1541e-01,  1.5128e+00,  1.3127e+00, -1.4618e-01, -3.1850e-01,
          6.4184e-01,  1.0595e+00,  1.5740e-01,  1.1064e+00, -1.5569e+00,
          2.1232e-01,  1.1762e+00,  8.3994e-01,  6.0611e-01,  6.7455e-01,
         -1.0489e-01,  6.4692e-01],
        [-6.0433e-01,  7.7074e-01, -5.8640e-01,  1.2468e+00,  1.0748e+00,
         -4.7540e-01,  1.7767e-01, -3.6770e-01,  5.9642e-01,  7.4193e-01,
          2.3436e+00,  6.7829e-01,  7.0125e-01, -1.1771e+00,  9.9099e-01,
         -9.5198e-01, -8.6314e-01, -9.5852e-01,  1.1927e+00, -1.7665e-01,
         -1.6030e+00, -2.0307e+00,  1.1689e-01,  5.2729e-01,  3.8517e-01,
          1.2322e+00,  4.6891e-01,  1.1883e+00,  5.2858e-01, -1.7310e+00,
          7.9676e-01, -1.0690e+00],
        [ 1.8549e-01,  1.0378e+00,  1.7712e+00,  4.1414e-01, -7.7138e-01,
          1.1822e+00, -3.4232e-02, -4.4508e-01,  4.4880e-03,  2.3064e+00,
         -7.9935e-01,  1.0201e-01,  1.0677e+00,  1.0636e+00,  5.2191e-01,
          5.8172e-01,  6.4848e-01, -7.4828e-01, -5.0103e-01,  1.9520e+00,
          8.0687e-01, -1.5390e+00,  2.0564e-01,  1.6249e+00,  2.8974e+00,
          1.9890e-01,  1.4044e+00,  2.9790e-01,  6.5935e-01,  1.0556e+00,
          2.3268e+00, -1.1808e+00],
        [-3.3850e-01,  1.3293e+00,  4.2446e-01,  1.1118e-01, -2.8652e-01,
         -1.8987e+00,  8.4116e-01,  1.6643e-01,  1.3620e+00,  3.1827e-01,
          4.0494e-01, -1.1517e-01,  3.7420e-01,  7.3842e-01,  8.5050e-01,
         -2.5537e-01,  1.2542e+00, -1.2484e+00, -1.1159e+00, -3.2265e-01,
          9.7562e-02, -4.0932e-02, -7.2436e-01, -1.1040e+00, -6.0621e-01,
         -1.5893e-01,  3.2380e-01, -2.0062e-01,  1.6102e-01, -2.0877e+00,
         -3.7923e-02,  5.0835e-01],
        [-4.8931e-01, -4.3534e-01, -2.6508e-01, -7.9885e-02, -1.6934e-01,
          5.2987e-01, -6.9810e-01, -1.0746e+00, -1.4773e+00,  7.0657e-01,
         -1.3317e+00, -5.4929e-01, -4.6279e-01,  4.8831e-01,  1.3102e+00,
         -5.7689e-02, -7.7329e-01, -5.4428e-01, -3.4297e-01,  1.5274e+00,
         -1.0109e+00,  4.5992e-01,  4.5752e-01,  8.9271e-01,  5.1131e-01,
         -7.9019e-01,  4.2793e-01, -9.4371e-01, -3.8211e-01,  4.4724e-01,
         -1.3875e+00,  9.0590e-01]], device='cuda:0')
tensor([[ 4.2567e-01,  1.0824e-01,  1.1500e+00, -1.7408e+00, -1.0258e-01,
          1.0367e+00,  2.0498e+00,  1.3069e+00, -1.1770e+00,  3.6631e-02,
         -1.0603e+00, -1.6332e+00,  5.3703e-01, -1.1831e+00,  8.0142e-01,
         -4.6780e-01, -9.5963e-01, -5.8797e-01, -2.7162e+00, -6.2961e-01,
          2.3753e-01, -3.0121e-01,  8.7274e-02,  4.8999e-01,  1.5542e+00,
         -5.1137e-01, -3.2480e-01,  3.7696e-01,  7.9303e-01, -4.5533e-02,
          1.0451e-02,  3.9578e-01],
        [ 1.9277e+00, -1.1885e+00,  6.8675e-01, -5.8948e-01, -1.2728e+00,
         -3.4937e-01,  4.6466e-01,  9.3076e-01,  3.5717e-02,  9.5881e-01,
          1.8466e-01, -1.3458e+00, -4.4151e-01,  3.4375e-01, -2.3498e-01,
          1.3256e+00,  3.8385e-01,  5.5317e-02,  3.3870e-01, -8.4750e-01,
          5.2002e-01, -7.9503e-01, -1.3924e-01,  1.3088e-01, -1.0014e+00,
          9.3583e-02,  6.6594e-01,  1.0117e-01, -1.1219e+00, -3.9972e-02,
         -8.1004e-02,  2.0167e+00],
        [ 6.4688e-01, -1.2345e-01,  1.3313e+00,  2.9651e-03, -9.4881e-01,
         -1.2267e+00, -1.2872e+00, -1.8337e-01, -1.1308e+00, -1.3726e+00,
         -9.4573e-01,  6.3842e-01, -2.3323e-01, -5.6411e-01, -1.5053e+00,
         -1.0328e+00, -8.2629e-02,  1.0411e+00, -4.0208e-01, -2.1840e-01,
          9.7582e-01, -1.0482e+00,  9.9846e-01,  1.3277e+00, -3.3056e-01,
          7.3309e-01,  1.1554e+00, -9.2924e-02, -4.0212e-01, -1.0978e+00,
          1.5508e-01,  4.8794e-01],
        [ 4.9817e-01, -4.7061e-01,  1.0035e+00, -7.4297e-01, -8.9424e-01,
         -3.7206e-01,  7.3365e-01,  2.4004e-02, -1.3518e+00, -1.8446e-01,
          5.3541e-01, -2.1252e-01,  1.2825e+00, -4.1656e-01, -4.5740e-01,
          2.6484e-01,  5.8409e-01,  3.8932e-01, -4.9813e-02,  1.0254e-01,
         -2.2718e-01, -3.3671e-01, -6.3362e-01,  1.0744e+00,  2.2684e-01,
         -9.0270e-01,  1.6035e+00, -2.6294e-01,  1.3449e+00, -8.7300e-01,
          3.8614e-01,  3.1606e-01],
        [-9.7571e-01,  7.8603e-01,  1.8559e-01, -4.7629e-03,  1.4586e+00,
          2.6450e-01, -2.5926e-01, -2.5836e+00, -1.3242e+00,  4.8097e-01,
         -1.7096e-01, -1.9397e+00, -5.4893e-01,  7.8726e-02, -1.0359e-01,
         -4.4195e-01,  1.5666e-01,  9.6987e-01,  1.6743e+00, -1.1211e+00,
         -1.4249e+00, -6.6860e-01, -2.4465e-01,  1.3088e+00,  9.6117e-01,
         -4.8421e-01, -2.3751e-01, -2.0581e-01, -4.2138e-01,  6.7008e-01,
         -7.6076e-01,  1.1868e+00],
        [ 8.8196e-01,  1.9732e+00, -5.0314e-01,  9.0149e-01, -2.8488e-01,
         -1.8532e-02, -4.2290e-01, -5.9359e-01, -3.5288e-01, -1.1542e+00,
         -3.6113e-01,  1.6378e+00,  1.1689e+00, -4.6317e-01,  1.1376e-01,
         -1.1013e-01,  5.4117e-01,  1.1224e-01,  7.7133e-01,  1.2093e+00,
          8.6933e-02,  3.1984e-01,  2.9195e-01, -2.1171e-01,  4.3360e-01,
          4.3958e-01,  3.8190e-02,  1.4963e+00, -1.5328e+00, -6.3713e-01,
          1.2212e-01, -8.2342e-01],
        [-2.5813e-01,  1.1143e+00, -1.2169e+00, -8.7527e-01,  1.5957e+00,
          8.3881e-02,  1.0371e+00,  2.0202e+00, -1.6494e-01,  9.8377e-01,
          1.3580e-01,  4.0958e-01, -5.6746e-01, -1.5007e+00,  8.8421e-01,
          2.0958e-01, -6.5293e-01, -1.2989e+00, -4.1733e-01,  3.3510e-01,
         -6.0582e-01,  7.5765e-01,  1.5395e+00, -4.8336e-01, -5.4169e-01,
          1.1506e+00,  9.7086e-01, -9.4551e-01, -2.1320e-01, -1.6041e+00,
          1.0669e+00, -2.8655e-01],
        [ 6.6996e-01,  1.0434e+00,  1.0333e-01, -1.7088e+00, -9.7288e-01,
         -1.2552e-01, -2.3441e-01, -2.3838e-01, -7.6653e-01, -1.2179e+00,
         -6.8608e-01, -9.4864e-03,  5.8034e-01,  1.1595e+00, -1.7173e+00,
         -2.9219e-01,  6.2090e-01,  3.7041e-02,  1.4057e+00, -1.9240e+00,
         -1.6184e+00, -1.8407e-01, -1.1189e-01,  2.0535e+00, -7.4819e-02,
         -6.2782e-01,  9.6153e-01, -1.7141e+00,  1.8208e+00, -4.5726e-01,
         -1.5952e+00,  2.6292e-01],
        [ 5.6248e-01, -7.8537e-01,  6.3710e-01,  3.6482e-01,  1.4108e+00,
         -1.3081e+00, -1.8227e+00,  3.3205e-02, -1.8451e+00,  4.4216e-01,
          3.6328e-01,  1.2140e+00, -4.9921e-01,  1.2385e+00, -5.4684e-01,
         -2.6700e-02,  9.2045e-01, -5.5265e-01, -1.4886e+00,  3.6441e-01,
          1.0479e+00,  6.7981e-01, -7.9251e-01, -5.6025e-01,  4.4634e-02,
          1.2789e+00,  6.3333e-01,  7.0322e-01, -1.0545e+00, -5.3498e-02,
          7.0651e-01, -6.5377e-01],
        [ 3.6193e-01, -9.5107e-01, -4.7507e-01, -2.9284e-01, -1.2428e+00,
         -5.2565e-01,  6.5485e-01,  6.6287e-01, -1.4560e+00,  2.0733e+00,
         -4.4053e-01, -6.9067e-01,  1.0516e+00, -5.1787e-01, -2.1657e+00,
         -8.1989e-01, -3.5884e-01, -1.7755e-01,  1.6591e-01,  2.2194e+00,
          1.4610e+00,  5.3724e-02,  2.0367e+00, -7.7706e-01, -9.2807e-02,
          1.3102e+00, -1.1200e+00, -4.5403e-01, -1.1792e+00,  4.8872e-01,
         -7.9078e-02, -1.6535e+00],
        [ 4.8214e-01,  5.0760e-01, -2.5088e-01, -1.2676e+00,  2.1845e+00,
         -1.0329e+00, -1.1081e+00,  4.2239e-02, -3.4593e-01,  2.2437e-01,
          1.1658e+00,  2.2223e+00, -3.2257e-01,  3.2862e-01, -1.7728e+00,
          6.1926e-01, -1.5610e+00,  1.4322e+00, -8.1164e-02,  1.1261e+00,
         -4.7608e-01, -1.2028e+00,  1.1194e+00, -5.9198e-01, -6.2640e-01,
         -3.1930e-03, -4.2565e-01, -2.5972e-01, -3.6366e-01,  1.6345e-01,
          1.3180e+00, -5.9661e-01],
        [-1.2402e+00,  2.6096e+00,  1.6227e+00,  2.4989e-01,  1.8282e+00,
          1.5479e-01,  3.1519e-01,  8.6314e-01, -1.4658e+00,  9.9616e-01,
         -1.2787e+00, -6.4881e-03, -1.8249e+00,  1.0149e+00,  9.5619e-02,
         -1.0510e+00, -6.2994e-01, -1.5804e-01, -1.0456e+00, -3.3335e-01,
          2.2060e+00, -1.1686e+00, -9.8077e-01, -1.7672e+00,  4.2947e-02,
         -4.3141e-01, -1.4792e+00, -7.0110e-01, -9.0550e-01,  7.7173e-01,
          1.6457e+00,  6.0188e-02],
        [ 1.9900e-01, -1.5614e+00, -1.7973e+00,  6.6974e-01,  5.6978e-01,
          1.7203e+00, -5.6543e-01,  7.7570e-01,  1.6470e-01,  1.1564e+00,
         -5.2795e-03,  7.2363e-01, -8.6806e-01, -2.9651e-01,  1.3576e+00,
         -8.2336e-01, -6.4328e-01, -1.4347e+00,  2.6617e+00,  3.7349e-01,
         -5.1826e-01,  4.9836e-01,  2.7503e-01,  6.8888e-01,  5.6330e-01,
          1.8143e-01, -6.9579e-01, -4.2847e-01, -5.4902e-01, -1.0509e-01,
         -1.3513e+00, -7.5203e-01],
        [-1.4873e+00, -4.2213e-01, -1.8861e-01,  1.0911e+00,  7.2592e-01,
         -7.1921e-01, -2.8337e-01,  6.0742e-01,  6.7272e-01, -6.3210e-01,
          1.0345e+00, -1.5258e+00,  1.6824e+00, -1.5203e-01, -2.2677e+00,
          1.0332e-01, -2.9664e+00,  9.3795e-02, -4.9369e-02,  9.2099e-02,
          9.1166e-01, -1.1701e+00, -1.8169e-01,  3.5635e-01, -4.7233e-01,
         -3.5069e-01, -1.1052e-01, -3.2275e-01,  3.6279e-01,  4.0249e-01,
         -1.1234e+00, -4.4842e-02],
        [-1.4683e+00, -6.7247e-01, -9.7838e-01, -1.1245e+00, -2.2546e-02,
          1.2674e+00,  7.6800e-02, -1.9484e-01,  8.3852e-01, -1.0706e-01,
         -8.5177e-01,  1.1350e+00,  4.6822e-01,  8.8258e-01, -1.8283e-01,
         -6.1980e-01, -6.1986e-01,  1.6385e+00, -4.9409e-01, -7.0689e-01,
         -1.2939e+00, -9.2280e-01,  1.8103e-01,  2.6435e-01, -6.0680e-01,
         -4.8092e-01,  7.1434e-01, -9.4378e-01, -1.4533e+00, -7.2848e-01,
          2.5795e-01,  8.0950e-01],
        [ 9.9559e-01,  1.1653e-01, -1.4778e-01, -4.6942e-01,  2.0221e-01,
          2.2251e+00, -1.3295e-01,  6.4755e-01,  9.1215e-01, -4.4741e-02,
         -1.1590e+00, -2.8099e-01, -1.0824e+00, -1.0043e+00,  1.5853e+00,
         -7.4214e-02, -9.8665e-01,  5.0583e-02,  2.8891e-01,  5.6511e-01,
         -9.2188e-01,  9.8528e-01, -6.0099e-01,  5.1692e-01, -1.2680e+00,
          9.9564e-01, -1.8180e+00, -8.0645e-01, -8.2444e-01,  9.8237e-01,
          1.2863e+00, -4.5876e-01],
        [ 1.6825e+00,  3.7173e-01, -9.7151e-01, -2.2586e-01,  3.4422e-01,
          7.5382e-01, -1.3264e+00,  4.7798e-01, -2.5197e-01,  4.7863e-01,
          1.8333e+00, -1.7607e+00, -9.1318e-03, -1.5075e+00, -8.2251e-01,
          5.9565e-01,  7.6592e-01,  1.7312e+00, -1.1191e+00, -9.3619e-01,
          7.1484e-01,  1.3585e-01,  8.3694e-01, -3.3168e-01,  1.8951e+00,
         -9.5053e-01, -1.6884e-01,  3.7511e-01,  2.6321e-01,  1.4505e-01,
         -4.0446e-01, -4.6527e-01]], device='cuda:0')
tensor([[ 9.6903e-01,  3.5553e-01,  6.8793e-01, -5.5068e-01,  1.0400e+00,
          1.7212e-01,  1.8714e+00, -3.2570e-01,  7.5353e-01, -3.1976e-01,
         -5.7959e-02, -3.8466e-01,  1.0894e+00,  3.7268e-02,  1.3307e+00,
         -1.4104e-01, -3.3917e-01,  9.4638e-01,  7.7006e-01,  2.8843e-01,
         -1.2743e-01, -1.0051e+00, -1.0796e-01, -1.8639e+00, -4.2704e-01,
          1.6616e+00, -1.5116e+00, -1.5673e-01,  7.8165e-01, -2.4647e-01,
         -2.4052e-01,  2.3429e+00],
        [ 1.1416e+00,  1.8003e+00, -1.3151e+00,  2.0068e+00,  5.0794e-01,
          1.4003e+00,  7.3024e-02, -7.3487e-01,  4.7838e-01,  1.0550e+00,
         -4.4799e-01, -7.1886e-01, -2.1231e-02,  1.3717e+00,  3.1079e-01,
         -5.4189e-01, -1.1991e+00,  4.1712e-01, -8.4162e-01, -1.1365e+00,
          7.4852e-01, -1.9807e-01,  3.1313e-01,  1.4264e+00,  1.4548e+00,
         -3.4892e-01,  3.0638e-01,  1.7180e+00,  1.1018e+00, -2.5527e-01,
          2.1538e-01,  6.0034e-01],
        [ 2.6558e-01,  2.4013e-01,  7.4136e-02, -1.8882e+00,  9.4773e-01,
          2.0213e-01,  6.7403e-01,  9.4062e-02,  1.7715e-01,  6.3191e-01,
         -1.9818e+00, -8.7875e-01, -1.2624e-01, -3.5836e-01,  3.5143e-01,
         -8.9932e-01, -5.4424e-01, -4.5856e-02,  7.0980e-01,  8.9070e-02,
          1.6109e+00,  1.4385e-01,  1.6933e+00, -2.2324e+00, -1.0746e+00,
         -5.8395e-02,  5.4039e-01,  1.9965e+00, -1.2890e+00,  5.0587e-02,
          9.8894e-01, -1.6721e+00],
        [ 8.9631e-01,  1.7275e+00,  1.2477e+00, -6.3728e-01,  1.5123e+00,
         -2.9092e-01, -1.3597e-01, -1.0316e+00,  2.0681e+00,  1.0605e-01,
         -7.8889e-01, -1.0371e+00, -8.7694e-01,  5.6985e-01, -1.8015e-01,
         -1.2634e+00,  4.8959e-01,  3.1827e-01,  5.3740e-01,  1.1181e+00,
         -1.9356e+00, -8.3522e-01, -8.5320e-01, -7.2760e-02,  1.4884e-01,
          1.1456e+00,  1.0493e+00, -1.1064e+00,  1.2668e+00, -3.7843e-01,
         -1.3240e+00,  8.3946e-01],
        [-5.7196e-01, -1.7228e-01, -5.5566e-01, -5.2405e-01,  7.5916e-01,
          1.2866e+00,  6.5673e-02,  4.2468e-01, -1.1709e+00, -1.8148e-01,
         -4.6441e-01, -2.4549e-01, -8.7233e-01,  4.4260e-01, -7.5964e-01,
          5.4784e-01,  1.9004e+00, -3.6854e-01, -2.1556e+00, -1.2987e+00,
          5.9361e-01, -1.2604e+00,  1.1419e+00, -8.4470e-01, -9.1162e-01,
          4.6580e-01,  9.3322e-01,  1.1650e+00, -8.3704e-01,  5.9069e-01,
          9.0521e-02, -4.3024e-01],
        [-8.2497e-01,  1.7457e-01,  1.0830e+00, -2.2504e-01,  5.9449e-01,
         -2.4787e+00,  2.3288e+00, -4.0858e-01,  1.3011e+00,  1.5046e+00,
         -4.4190e-01,  9.9166e-01, -1.9474e-01,  9.3875e-01,  1.3629e+00,
         -6.5845e-01,  3.9274e-01,  1.9100e+00,  4.5324e-03,  8.8976e-01,
         -1.2300e-01, -4.0884e-01,  9.2947e-01, -6.8527e-01, -1.5517e+00,
         -4.1099e-01,  9.3175e-01,  3.0225e-01,  1.1891e+00,  3.1448e-01,
         -1.0059e+00, -6.7017e-01],
        [ 1.2549e+00, -1.1195e+00,  4.5622e-01, -2.5492e+00, -8.4683e-01,
          5.1155e-01, -2.2999e-01, -6.6500e-02, -7.5402e-01,  3.9327e-01,
          1.2799e+00, -7.3467e-01,  1.4991e+00, -6.4350e-01, -5.2673e-01,
         -9.2310e-02, -4.2587e-01, -3.1155e-01,  1.3373e-01, -2.3011e+00,
          1.4698e+00,  4.8973e-02, -5.7544e-01,  8.1908e-01,  6.4825e-01,
         -1.5625e+00, -3.3970e-01, -5.3067e-02,  6.8178e-01,  1.5696e+00,
         -7.7700e-01,  7.7605e-02],
        [ 6.0092e-01,  3.0252e-01, -7.2599e-01,  4.4867e-01, -3.8772e-02,
         -3.3910e-01, -5.1967e-01, -5.1084e-01,  9.8447e-01,  5.4845e-01,
          1.6988e-01, -6.1620e-01,  2.3616e+00, -3.1210e-01,  6.4255e-01,
          2.3920e-01, -1.0977e+00,  3.9114e-01,  8.8354e-01,  5.7368e-01,
          1.8982e+00,  1.0003e+00, -1.8822e+00, -1.1429e+00, -2.3649e-02,
         -3.9498e-01,  5.9378e-01,  6.1151e-01,  1.5238e-01, -1.4260e+00,
          1.7658e+00,  1.2570e+00],
        [-8.8819e-01, -7.7835e-01,  1.5507e+00,  1.1545e+00, -1.7457e-01,
         -7.8556e-01,  1.2323e+00, -9.1844e-01, -1.4510e+00, -5.8295e-01,
         -1.2620e+00,  8.1065e-01, -6.6966e-01,  7.5151e-01,  1.6836e+00,
         -7.7884e-01, -1.2822e+00, -7.1561e-01, -2.6095e+00, -3.2157e-01,
          1.2429e-01,  1.1217e+00, -1.5834e+00, -1.1525e+00, -5.7169e-01,
          1.5836e+00, -8.7637e-01, -4.4810e-01,  6.2947e-01,  1.6244e-01,
          7.9248e-01,  1.0478e+00],
        [ 5.3519e-01,  9.6260e-01,  2.2550e-02,  1.1744e-01,  1.0840e+00,
         -3.7225e-01, -1.8197e+00,  6.8567e-01, -1.6357e-01,  1.4179e-01,
          6.0837e-01,  1.2780e+00,  3.1058e-01, -8.3200e-01, -1.1618e-01,
          2.1048e-01, -1.2903e+00,  3.0127e-01, -6.5446e-01, -1.5049e+00,
         -3.9944e-01,  6.2241e-01, -2.4863e-01, -2.5752e-01, -2.8270e-01,
         -1.6850e-01,  1.2069e+00, -1.2624e+00,  2.6871e+00, -9.4159e-01,
          1.8065e+00, -4.6583e-01],
        [-2.2149e+00,  2.1086e-01,  1.4972e+00, -1.6946e+00,  1.8720e-01,
          1.9585e-02, -1.6504e-01, -1.0143e+00,  3.3790e-02,  3.5742e+00,
         -4.4882e-01,  1.3731e-01,  9.1054e-01, -1.3964e+00,  3.4038e-01,
          9.8803e-02, -1.0664e-01,  1.3208e+00,  9.7896e-01,  1.4369e+00,
          3.0853e-01, -1.3442e+00,  5.6198e-01,  4.0158e-01,  5.2373e-01,
          1.3937e+00, -6.9962e-01, -2.0481e+00,  4.8052e-01,  5.3536e-01,
          1.3127e+00,  1.4500e+00],
        [-1.7141e-01,  2.8942e-01,  4.2962e-01,  2.0073e+00,  2.7323e-01,
          1.8132e-01, -7.1392e-01,  1.3618e-01,  8.9175e-02, -2.3050e+00,
          9.5536e-02, -3.9464e-01,  9.2868e-01,  1.7038e+00,  1.6776e-02,
          2.9443e-01,  5.3125e-01, -1.9722e+00,  1.6053e-02, -2.6525e-01,
          1.9485e+00, -8.0892e-01,  1.4560e+00,  2.3004e+00,  4.7042e-02,
          2.4504e-01,  4.2682e-01, -4.5002e-01, -1.4116e-02,  5.4929e-01,
         -5.5594e-01, -6.7520e-01],
        [-7.2541e-01, -1.4224e+00, -1.4515e-02,  1.2715e+00, -3.3725e-01,
          6.2525e-01,  1.6407e+00, -9.2980e-01,  4.7029e-01,  4.2955e-01,
         -6.7715e-01,  6.5996e-01,  1.1069e-01, -7.7718e-01, -1.9951e-01,
         -2.4175e+00, -4.2909e-01, -1.3565e-01, -8.5306e-01, -1.0207e+00,
          2.2947e-01, -7.0309e-02, -8.6388e-01, -1.6468e+00,  1.6530e-01,
          9.0741e-03,  1.0520e+00, -9.0559e-01, -9.2415e-01, -9.7781e-01,
          1.8934e+00, -8.2360e-01],
        [ 5.0720e-01,  2.3552e+00, -1.6119e+00,  8.1232e-01, -9.9401e-01,
          4.0951e-01, -1.5633e+00, -4.7506e-01, -6.2380e-01, -3.6856e-01,
          1.1445e+00,  1.5641e-01, -1.6437e+00, -2.0697e-01, -2.9999e-01,
         -1.7832e+00, -9.6324e-01, -6.4563e-01,  1.0178e+00, -6.2074e-01,
         -3.9392e-01, -7.3774e-01, -1.1612e+00, -4.8863e-01,  7.1461e-01,
          5.0389e-01, -1.3895e+00, -3.9621e-01, -7.5969e-01, -1.0347e-01,
         -9.9359e-01, -4.1561e-02],
        [ 4.6253e-01,  1.1747e+00,  8.4857e-01, -4.6861e-01,  1.6821e-01,
         -4.5265e-02,  4.8130e-01,  8.6389e-01,  1.7149e+00, -8.6409e-02,
          6.4537e-01, -2.1301e+00,  6.7186e-01, -1.3716e+00,  4.2210e-01,
          1.0355e+00, -2.1333e-01,  9.4557e-02,  1.2591e+00, -2.8312e+00,
         -1.9850e-01,  1.5596e-01,  1.2216e+00,  5.1724e-01,  8.0569e-01,
         -8.7229e-01,  3.1070e-01,  7.9111e-01,  4.2452e-01, -1.5302e-01,
         -1.5199e+00, -1.0972e+00],
        [-7.0786e-01, -1.6190e+00,  1.6321e+00, -1.4187e+00,  6.9595e-01,
         -8.8896e-01, -1.7349e+00,  1.1569e+00,  1.0587e+00, -1.4044e+00,
          2.2510e+00,  1.2105e+00,  1.7117e+00, -4.1981e-01,  8.6375e-01,
         -1.2999e+00,  1.4954e+00, -8.7016e-01,  9.1128e-01, -7.7467e-02,
          1.0306e+00,  1.1645e+00, -1.4803e+00, -7.2268e-02,  3.6453e-01,
          2.4339e-03, -2.5068e-01,  1.1782e+00,  6.8651e-01,  8.2307e-02,
          9.5419e-02, -8.2665e-01],
        [ 4.4500e-01,  1.0860e+00,  1.9124e-01, -5.5663e-01, -8.2459e-01,
         -1.0532e-01, -1.5953e+00, -9.9499e-02, -4.4959e-01, -2.1460e-01,
          1.9663e+00,  6.7300e-02,  1.6389e-01, -1.4617e-01,  1.2524e+00,
          2.0042e-01,  5.5407e-01,  2.3845e+00, -8.6177e-01, -3.5198e-01,
          2.4003e-01,  1.3579e+00,  8.6814e-01,  1.5175e-01,  1.6461e+00,
         -7.9572e-01, -1.3837e-01,  5.7530e-01,  4.9472e-01,  4.9688e-01,
         -1.2965e+00, -1.3353e-01]], device='cuda:0')
tensor([[-1.2086, -0.6340, -0.8002, -0.7233, -0.7043,  0.0919, -0.5437,  2.3361,
         -0.0351, -0.0076, -0.3619,  0.8541,  0.4134, -0.2780, -0.0162, -1.5907,
          0.1764, -0.2639,  0.5771,  0.1651,  0.3818,  0.6525,  0.5468,  1.4142,
          0.4448, -1.4281,  0.9667,  1.3868, -0.4670, -0.0050,  0.2537, -1.0711],
        [ 0.3014, -0.5039,  0.8244,  0.1509,  1.8236, -1.8312,  1.2113, -0.3629,
         -0.9993,  0.2651,  1.6526,  0.4422,  1.4572, -1.4544,  0.4063,  0.9213,
         -1.0089, -1.5426, -1.0299,  2.3628,  0.5659,  1.5206,  2.0763, -0.1245,
          1.7114,  0.3547,  0.0766,  0.7476, -1.6347,  1.4127, -0.3863, -2.5859],
        [ 0.1960,  0.2756,  1.0945,  2.2996,  0.5414,  1.0020,  0.2948, -0.4388,
          1.2689,  0.6546, -0.3008,  0.4745,  0.3236,  1.0484,  0.2265,  1.6484,
          0.6868, -0.6589, -2.6250, -1.6274,  0.8742,  0.0971,  0.6268,  0.3048,
          1.1245, -1.0702, -0.4833,  0.2885, -0.8380, -1.0390, -0.1760,  1.2013],
        [ 0.5400, -0.3006, -0.2063,  0.5574, -1.5709,  0.5979, -1.0623, -0.4021,
         -2.5707, -0.9476,  1.1817,  1.2021, -0.2404,  0.3423,  1.2919,  1.3967,
         -1.7588, -0.3336,  0.7337,  1.8180, -1.6749, -0.0574, -0.1274,  0.6842,
          0.4110,  1.7896,  0.4791, -2.0146,  1.3977,  0.7288, -1.6343,  0.2999],
        [ 2.0561,  0.2946,  1.0056, -0.2194,  0.2154,  0.9573, -0.2565, -0.6407,
         -0.4680,  0.4334,  0.4772, -0.9214, -0.6969,  1.6267,  0.4605, -0.1997,
          0.9516, -0.5319,  0.1427,  1.0079,  1.0813,  0.9806,  0.2972,  0.5485,
         -0.0867,  0.0646, -0.1889, -0.2683, -0.1825, -1.6911, -0.5564,  0.0654],
        [ 0.0258, -0.2838, -0.8575, -0.6796,  0.6249, -0.5785,  0.0510,  0.6002,
         -0.3025, -0.1260,  1.8469,  1.6514,  1.6005, -0.5487, -0.3410, -0.0391,
         -0.0145,  0.0362, -0.1667,  0.8677, -1.0743,  2.7092, -0.9592, -0.4589,
          0.5017,  0.9641, -0.3047, -1.5570,  0.5908, -0.4741, -1.2851, -0.2762],
        [-0.2065, -0.1780,  0.4186,  0.3434, -1.7684,  0.4449,  0.3946,  1.4139,
          1.2615, -1.0026,  0.3175,  0.0432,  1.9799,  0.8419, -0.1215, -0.6849,
          0.0609,  1.0519, -0.1794, -0.4113, -0.7897,  1.4896, -0.3585, -0.6004,
          2.1063,  0.0095,  0.3471, -0.4157, -0.2793, -0.0090,  0.5392, -0.4226],
        [ 1.3605, -0.3016,  1.1533, -1.5352, -1.2117, -1.5966, -0.4000,  2.1299,
          0.1321, -0.5081, -0.1301, -0.2601,  0.6182,  0.5338, -1.1445,  1.8312,
          2.1254, -0.1851,  0.0842,  0.1771, -0.9221,  2.0419,  0.2849, -1.9627,
          0.9103,  1.9473,  1.0016, -1.8217,  1.0990, -1.5083, -0.4298,  0.2004],
        [ 1.0768,  0.4924, -0.6593, -0.2227,  0.3141, -0.3944,  0.4211, -0.5632,
         -0.0166, -0.4444, -1.0392, -0.6702,  0.0229, -0.1577,  0.7661, -1.5159,
          0.6363, -1.3148, -0.1014, -0.7123,  1.3250,  0.1066, -0.1344, -0.6725,
          0.5650,  1.7452,  0.2511,  0.6372,  2.6781, -1.4169, -1.3194, -1.1402],
        [-1.0015,  0.0772, -0.6774, -1.2981, -1.4400, -0.1452,  1.5148,  0.2048,
         -1.0138,  0.2910,  1.2120, -1.2560, -0.1781, -0.5437,  1.1144,  1.1387,
         -0.1198, -0.4031, -0.3358,  0.5498,  0.5445,  0.3108,  1.7475,  0.5450,
          1.2765,  1.3675, -0.6495, -2.3822, -2.0284, -1.3928, -0.2175, -0.1097],
        [-2.0227, -0.0352,  0.5126, -0.7395, -0.1817, -2.0219,  0.3028,  0.3257,
         -0.2176,  1.2486, -2.2046,  0.3013, -0.0088, -0.3497,  0.7604,  0.5690,
          0.6381,  1.2321, -0.2636, -0.4288, -0.7652,  0.2209,  1.7138,  0.5466,
         -1.0726, -0.0159,  0.5738,  1.1042,  2.0547,  0.8273,  0.2293, -0.8762],
        [ 0.9695,  0.6400, -1.0134,  0.6877,  2.5827,  0.7735, -1.4579,  2.3480,
         -0.0884,  0.8135,  0.4246, -0.5625, -0.7826,  0.4650, -0.7666,  0.6297,
          1.3483,  0.0568, -0.9716,  1.2803, -0.7819,  0.7883, -1.7195,  0.4577,
          0.1000,  0.3128, -1.6257,  1.8224, -0.9733,  0.4147, -1.5270,  0.6259],
        [-0.0064, -0.1921,  1.9637,  0.3978,  0.2513,  0.4299,  0.0910, -1.1033,
          2.3092,  0.1905,  0.5367,  0.5549, -0.5492,  0.6837, -0.3546, -0.6743,
         -0.2282,  0.9301, -0.5237, -0.8603,  0.6568, -0.5531, -0.3210, -0.1775,
         -0.3371,  0.0057, -0.6327, -0.1704, -0.5242, -0.6624, -0.6161,  1.2805],
        [ 1.9063, -0.1111,  0.1712, -0.1946,  0.8271, -2.0145,  1.0390, -0.1519,
          2.8153,  0.5829, -1.2354,  0.4614, -1.1832, -0.5881, -0.4778,  0.4509,
          1.7977,  0.4599, -0.7635,  1.4066, -0.0938,  0.3880,  1.1165,  1.2908,
          1.1235, -1.4934,  0.5653, -1.5653, -0.6838,  0.8767, -0.4804,  0.0668],
        [-0.3090,  1.8146, -0.0300, -0.1596, -0.8255, -2.0738, -0.5062,  1.1078,
          0.7359,  0.1531, -0.5811, -0.0536,  0.7914,  0.1800, -1.2344,  0.0592,
          0.5208, -0.7345, -0.0881, -0.0209, -0.1985,  0.5561, -0.2193, -2.2276,
          0.4341,  1.0245,  0.6455, -1.4214, -0.1555, -1.2022, -0.2622, -0.2372],
        [-0.6730,  0.1848,  0.2415,  0.2049,  0.6993, -0.2941,  0.1220, -0.8439,
          0.2284,  0.6013, -1.1004, -0.2931,  1.4091, -0.6195, -1.7496, -0.4634,
          0.2625, -0.6282, -0.3093,  0.4281, -0.4035, -1.8410,  0.1537, -0.3731,
         -0.1795,  0.5209, -1.1796, -1.2877, -0.2722, -0.5481, -0.2042,  0.6581],
        [-0.7359, -1.0902,  0.1406, -0.6325,  0.6193, -0.1564,  0.6467, -0.1648,
          0.6210,  1.0614, -1.3057,  0.1712, -0.1195,  0.3864,  1.4776, -0.1325,
          0.2179,  0.7130,  0.1022, -0.9397, -1.5979,  1.7549,  0.2641, -1.0805,
         -1.7460,  3.4214, -1.1378, -1.8709, -0.9437, -1.2478, -0.3047,  0.5602]],
       device='cuda:0')
tensor([[ 0.5233, -0.6834,  1.7672,  0.8269, -0.4882, -1.4937,  0.7645,  0.8744,
          0.8065, -1.4684, -2.3679, -1.4963,  1.4939,  0.1037,  1.5914, -0.3711,
          0.6202, -2.2325, -1.5866, -1.0578,  2.0394,  0.4757, -0.1314,  0.2477,
         -1.7845,  0.8715,  0.4127, -0.2336,  1.9429,  1.0340,  1.4520,  0.4617],
        [-0.3599,  1.3515, -0.5877, -1.4121,  0.3267,  0.5652,  0.2502, -0.9421,
          0.5431,  0.7328, -0.2894,  0.8980,  0.0067,  2.2562, -1.2575,  0.7812,
         -0.1100,  0.5583,  0.6727, -0.0912, -0.2394,  0.1587, -0.3995, -1.0127,
          0.5286,  1.0135,  0.3105,  0.2189, -0.8359,  0.5839, -0.5817,  0.1768],
        [-1.2064, -0.4049, -0.6353,  0.5532, -0.1213, -0.6686,  1.2805,  0.6335,
         -1.0588,  0.5263,  1.3188, -0.0701, -1.0108,  0.6710,  0.3299,  1.4778,
          0.6547,  1.2555, -1.9948,  0.5000, -0.5881,  0.6202, -0.0547,  0.0066,
         -0.9477,  1.7406, -0.7394,  0.4644,  0.6095,  1.2488, -1.1290, -0.1124],
        [-1.7127,  1.1524,  0.0386, -0.7909,  0.2813,  1.1129,  1.5982,  1.0675,
          0.2621, -0.4601, -0.2255, -1.0969, -2.4780, -0.3873, -0.1325, -0.6773,
          0.1443,  0.6770, -1.4277,  0.4582,  0.7931, -0.9478, -0.2295,  1.8592,
         -1.1323, -1.0371,  0.3775,  0.5318,  0.1299,  0.2428,  0.2133, -0.1971],
        [ 0.0397,  1.8086,  2.7986, -1.0027,  0.9607, -0.5966,  0.3720,  1.1214,
         -0.9830, -0.3414,  1.6053,  0.6538,  0.1676,  0.6295, -0.4999,  0.2154,
         -1.5791,  0.2745,  0.0880,  1.6959,  0.7605, -1.1725, -2.4876,  0.8496,
          1.2842, -0.0932,  0.0434,  1.1675,  0.2373,  0.1357,  0.5551,  1.0523],
        [ 1.7578,  0.3746, -1.0765, -1.8654,  0.2210,  0.8421, -0.7272, -0.6362,
          2.6363,  0.6733, -0.0862, -0.1249, -1.1869, -0.9256,  0.2013, -0.4494,
          0.4789,  0.0275, -1.6348,  0.2648,  0.8842,  0.0075,  1.3974, -1.2266,
         -0.1768, -1.4276,  1.2211, -0.7714,  1.5003, -1.6562,  1.9789, -0.0727],
        [-0.5224,  1.2993, -1.7861,  1.0630, -0.5687,  0.5584, -0.5357, -0.8376,
          0.5419,  0.9412,  1.0511, -0.3235,  1.3230,  0.9543,  1.6290, -0.0120,
         -0.6465, -0.6592, -0.6503,  0.0889, -0.4533, -1.7083, -1.8784,  0.4080,
         -0.6623,  0.5524, -0.4478, -2.2625,  1.8360, -0.5206, -1.0835, -0.7931],
        [ 0.0363, -0.8157,  0.3167,  1.3044,  0.6495,  1.8447,  0.1117,  0.7275,
         -0.2069,  0.3938, -0.0334,  3.5151,  0.5499, -0.7411, -0.5269,  0.6863,
         -0.6118,  0.3380,  0.2538,  1.8499,  1.3429, -0.9653,  0.0338, -0.3181,
         -0.7444, -0.5712,  1.2410, -0.0923,  0.2959,  0.5455,  0.4017, -0.9389],
        [-0.2952, -0.4185, -0.6275,  0.0457, -0.2003,  2.9814, -0.9519, -0.2498,
          1.1369,  0.6014, -1.2138,  0.4152, -0.2675, -2.1525, -0.8965, -0.3959,
         -0.3125, -1.0185, -1.1290,  0.2738, -0.7112,  0.4916,  0.7867, -0.3885,
         -0.5680,  1.4727,  1.0385, -1.1191,  0.6674, -0.7168, -2.0329, -0.8590],
        [-0.0911, -1.5605,  1.3616, -1.2956, -1.2653,  0.1921,  1.0196, -1.2028,
          1.9977,  1.1626, -0.4204, -0.6480, -0.2754,  0.5690,  0.9077,  0.0988,
         -1.5828,  0.7609, -0.5046, -0.1968, -0.6180,  0.1620,  0.2396, -1.2452,
          0.3774, -1.4825, -0.2624,  0.9647, -0.3156, -0.2827,  0.5422, -0.2023],
        [-0.9900,  0.3074,  0.2756,  0.6566,  0.5577,  0.5498, -0.0526,  0.4539,
          1.0526, -0.9952,  0.4569,  1.6699,  0.3684,  0.6912,  4.0736, -2.0913,
          1.0615, -1.4306,  0.3306, -0.1906, -2.0156,  0.2507, -0.3794,  0.1475,
          0.0484, -0.3479, -0.7747,  1.0341, -0.9277, -1.1641,  1.4294, -0.3461],
        [-0.0238,  1.6734, -0.1223,  1.3094, -0.8009,  0.0668, -0.8741,  0.0857,
         -0.2032,  0.2216, -0.4603, -0.0512, -0.4137, -1.4404, -0.1034,  1.7599,
         -1.1302,  0.2198, -1.1767,  1.0047,  0.6201,  0.0963, -0.8655, -0.2156,
         -0.9130, -1.4884, -0.3297, -0.1924,  1.3354, -2.8394,  0.8396, -0.9441],
        [-1.1035,  0.7635,  0.5755,  0.5873,  0.2390,  0.8089, -2.4847, -1.2907,
         -1.2033,  0.9720,  0.1085, -2.5856, -1.5443,  0.5685, -0.4357,  0.1238,
          0.2608,  0.3761, -0.0525,  0.3922,  1.0090,  0.0982, -0.0488, -0.7334,
         -0.5629, -0.5902, -0.3264, -0.4615, -0.6258, -1.2358, -0.4194, -0.3366],
        [-0.8922, -2.0467, -1.4794, -0.2151, -0.4776,  1.2330,  0.2213, -0.7790,
         -1.2221, -0.2382, -0.7183,  0.5310,  1.0342,  0.4232,  0.4060, -0.8131,
          0.3394,  0.2971, -0.6778, -1.0299, -0.6508,  0.7933, -0.0277, -1.8339,
          1.7173, -0.4951,  0.2929, -1.0545, -1.3734,  0.3274,  0.1843, -0.3110],
        [-0.9043,  2.3587, -0.2412,  0.2855, -1.5633,  1.0980,  0.1911,  0.1152,
         -0.5761,  0.0200,  0.9789, -0.7723, -0.2812,  0.7289, -0.5315,  0.7386,
         -0.1440,  0.5868,  0.8589, -0.4535,  0.6785, -1.3695, -0.3803, -0.0673,
         -0.0596,  0.7897,  0.7557, -1.5461, -0.6598,  0.8064,  0.4183,  0.4162],
        [ 0.5788,  0.2158,  0.4429,  1.0283, -1.3779,  0.5418, -0.7392,  0.1607,
          0.5970,  0.1991,  0.4830, -1.5039,  0.0886,  0.6820,  0.7260, -1.5926,
         -0.4656,  0.5725,  1.2601,  1.4673,  0.5503, -1.1064, -0.8934, -0.2602,
          0.2689, -1.0150, -0.9746,  0.0104,  0.1791, -0.7025,  0.1313, -1.7261],
        [-0.1352,  0.9506,  0.2997, -0.8007, -1.9926,  0.1917, -0.6357, -2.0413,
         -1.9468, -0.1095,  2.5779,  0.2874, -0.1589,  0.2232, -1.1985,  0.2894,
         -0.7471, -0.1941,  1.0757,  0.8353,  0.7937, -1.4499,  1.1461,  0.2716,
         -0.4086, -1.1404, -2.7183, -0.3689,  1.3912, -0.2144, -0.7610,  1.2721]],
       device='cuda:0')
tensor([[-1.0996e+00, -5.9535e-01,  1.6182e+00,  1.1108e+00,  2.1093e-01,
          5.3923e-01,  1.1104e+00, -5.5747e-01,  1.0552e+00, -1.7091e+00,
          3.1219e-01,  7.5475e-01, -2.0867e-01,  1.0456e+00,  1.0501e+00,
         -3.0855e-01, -8.2049e-01,  6.8912e-01, -1.3886e+00, -1.1624e+00,
         -6.9554e-01, -6.0303e-01, -1.1748e+00,  1.2196e+00, -2.4947e-01,
         -1.0021e-02,  2.9713e+00, -7.7746e-01, -9.0924e-01, -5.8012e-01,
          2.7313e-01, -6.4215e-01],
        [-1.1874e+00, -1.2317e+00, -2.7030e-01,  2.6949e-01,  1.0629e+00,
          2.7571e+00, -1.2802e+00, -1.3369e+00,  9.3221e-01,  1.2397e+00,
         -5.6089e-01,  1.1958e+00, -1.3573e+00,  1.5310e+00,  3.6934e-01,
          1.4249e+00,  6.9427e-01, -7.1980e-01,  6.2345e-01, -1.8481e+00,
          7.8679e-01, -1.0098e+00,  2.1314e+00,  9.5884e-01,  2.1069e-01,
          4.9127e-01, -4.1199e-03,  9.3165e-01,  1.0946e+00,  1.5306e+00,
         -2.9701e-02,  2.2479e-02],
        [-5.7628e-01, -9.0149e-01, -2.8165e-01, -4.3090e-01, -8.4775e-01,
          2.0191e+00, -9.6819e-01,  1.2549e-01,  2.1808e-01, -1.1450e+00,
         -1.9368e-01,  4.5798e-01,  4.0561e-01, -4.0937e-01, -3.5976e-03,
         -2.3411e+00, -2.1584e+00,  8.3981e-01,  1.7804e-01, -5.2725e-01,
         -2.6246e-01,  4.0733e-01,  1.8419e-01,  1.2378e+00, -3.8035e-02,
          8.9161e-01,  9.3535e-01,  4.5502e-01,  1.5214e+00, -2.1449e+00,
         -3.7003e-01, -1.0452e+00],
        [ 3.7710e-01, -1.1230e+00,  4.0254e-01, -1.1285e+00,  5.5907e-02,
         -3.1542e-01, -1.2162e+00, -1.7523e+00,  2.1192e+00,  3.1923e-01,
          6.9872e-01, -1.4483e+00,  3.9689e-01, -7.6778e-01, -1.5535e-01,
         -6.1853e-01, -9.0949e-01, -1.2623e+00, -5.2195e-01,  1.7473e-01,
          2.4902e+00, -1.4681e-01,  7.8873e-01,  1.7332e-01, -5.7892e-01,
         -4.5659e-01,  3.7718e-01, -4.7688e-01,  4.5090e-01, -7.5475e-01,
         -7.4370e-01, -1.1763e+00],
        [ 1.9353e+00,  3.1751e-01, -1.1916e+00, -9.2604e-01,  1.1656e+00,
          9.6954e-01, -3.8656e-01, -7.8801e-01, -5.9449e-01,  5.6995e-02,
          9.1452e-02,  3.9238e-01, -3.2552e-01, -9.7052e-01, -8.1607e-01,
          1.8789e+00,  1.9478e-01,  1.3035e+00,  7.1437e-01,  4.7522e-01,
         -4.5035e-01,  8.1517e-01, -2.2466e-02,  1.9553e-01,  8.4737e-02,
         -2.9561e+00, -1.1490e-01,  7.6025e-02,  1.3110e+00,  1.0340e-01,
          1.0189e+00,  2.9739e-01],
        [-3.7170e-01, -4.7085e-01, -1.9028e-01, -4.8638e-01,  2.4734e-01,
          2.2009e+00, -2.4768e-01,  9.5998e-02,  1.3246e+00,  8.7460e-01,
         -1.3394e+00, -1.5709e+00, -1.6222e-01, -6.4105e-01,  3.5160e-01,
          1.5036e+00,  1.0565e+00,  6.9198e-01,  2.4611e-01,  6.5122e-01,
         -8.8442e-01, -7.7833e-01, -1.1878e+00,  7.4520e-01, -1.5779e+00,
         -4.5095e-01, -5.4442e-01, -1.6188e+00, -1.1416e+00, -1.1132e+00,
         -4.1944e-01,  2.2229e+00],
        [ 4.5133e-01, -4.6823e-02, -9.6739e-01,  1.1443e+00,  8.5431e-01,
         -1.9467e+00, -9.8177e-01, -1.6095e+00,  8.3722e-01,  6.2203e-01,
          1.3622e+00,  2.4917e-01, -6.6170e-01, -1.4188e+00,  1.8418e-01,
          7.2135e-01,  9.2702e-01,  3.7086e-01,  4.1859e-01,  7.4695e-01,
          1.0916e+00, -9.5763e-01, -9.2077e-01,  5.5399e-01, -1.3528e+00,
         -1.7397e+00,  5.7953e-01, -2.7216e-01, -5.2573e-01, -6.4877e-01,
         -9.2271e-01, -1.7238e+00],
        [-7.5625e-01,  9.7417e-01, -8.9677e-01,  1.7104e-01, -4.1846e-01,
         -3.1354e-02,  2.5165e-01,  7.9919e-01, -4.0298e-02, -1.4975e-02,
          1.9512e+00,  1.8150e+00, -1.3688e+00,  2.6282e-01, -1.0255e+00,
          7.2499e-01,  3.3277e-02, -1.2660e+00,  1.0045e+00,  1.5692e-01,
         -4.1588e-01, -1.5493e+00,  3.1756e-01, -1.6053e+00, -3.5927e-01,
         -5.5616e-01,  1.6532e-01, -5.0482e-01, -1.8322e-03,  3.7907e-01,
         -7.3362e-01,  9.7782e-01],
        [-1.6781e+00, -2.3219e-01,  7.7833e-01, -1.8163e+00,  1.9157e+00,
          9.8830e-01,  1.3786e-01, -1.3220e-01, -2.3376e+00, -1.4271e-01,
         -9.4373e-01,  1.8610e-01, -1.3969e+00, -1.2024e+00,  1.8203e-01,
         -1.0034e+00, -2.1033e+00,  1.1408e+00, -7.8555e-02,  1.8481e+00,
          4.2233e-02, -1.5495e+00, -6.3342e-01,  9.8026e-02, -5.4414e-01,
          1.2443e+00, -3.8987e-01, -9.4773e-01,  1.9154e+00, -6.1182e-01,
         -1.4023e-01, -1.9287e-01],
        [ 1.1348e+00, -4.5053e-01, -1.5698e+00,  1.5985e+00, -6.1037e-01,
         -1.0635e+00,  9.7842e-01, -4.3485e-01, -1.4100e-01, -1.9333e+00,
         -3.2856e-01, -1.1911e+00,  3.0142e-01,  2.6775e-01, -3.5531e-01,
          2.9168e-01,  1.3286e+00,  3.8472e-01, -2.7963e-01, -2.5181e+00,
          7.5176e-01,  2.1244e-01,  7.3442e-01,  1.1530e+00, -9.0221e-01,
         -1.0802e+00, -8.7202e-01,  2.0948e+00,  3.1287e-01,  2.7943e-01,
          1.4207e+00, -1.9893e+00],
        [-1.3855e-01, -1.9252e+00,  7.6851e-01,  9.7338e-01, -5.5148e-01,
          1.6551e-01,  4.8389e-01,  2.0094e-01, -3.2017e-01, -1.1810e-01,
          1.3099e-01,  1.4288e+00,  6.0312e-01,  1.5260e+00,  3.2462e-01,
          1.8206e+00, -4.8538e-02, -4.6517e-01, -9.7801e-02,  6.8828e-01,
         -9.1221e-01,  4.1954e-01,  6.0928e-01, -7.9708e-01,  1.5009e+00,
         -1.7893e-01,  1.1827e-02,  9.6434e-02,  2.8164e-01,  1.4991e-01,
         -2.6322e+00, -8.3573e-01],
        [-1.0047e+00, -1.7486e+00,  1.3895e+00,  1.2732e+00,  8.4334e-01,
         -8.2444e-01, -5.0359e-01, -7.2220e-01,  6.7843e-01, -4.0618e-01,
         -1.5137e-01, -6.9456e-01,  8.2799e-01, -3.8747e-01,  6.7883e-01,
         -3.9666e-01, -6.6421e-01,  4.7681e-01,  8.5860e-01, -5.8062e-01,
          2.8412e-01,  1.1135e+00,  4.5856e-01, -1.7402e+00, -1.4321e+00,
          5.3149e-01,  1.2340e+00,  4.8151e-02,  3.6504e-01,  5.2050e-01,
         -1.3645e+00, -5.4846e-01],
        [ 1.6608e+00, -6.2274e-01,  7.7208e-02, -7.0617e-01, -9.7084e-01,
          1.0473e+00, -1.6334e+00, -1.3432e+00,  5.5948e-01,  1.1863e+00,
          1.8554e+00,  3.1678e-01, -9.8216e-02,  1.8981e-01, -5.3413e-01,
          1.0300e+00,  9.1302e-01, -6.4157e-01, -7.0838e-01,  4.6748e-02,
         -8.4229e-01, -2.6600e-01,  4.7007e-01,  1.7889e+00,  1.3558e+00,
          6.5339e-01, -5.0617e-01, -8.7310e-01,  2.2211e+00,  6.3078e-01,
         -5.6187e-01, -4.1169e-01],
        [ 1.8650e+00, -7.8595e-02,  1.1640e+00,  3.9841e-01, -6.9002e-01,
         -7.0000e-01, -5.5805e-01, -1.7344e-01, -5.5821e-01, -7.6558e-01,
          2.4303e-01,  1.3383e+00, -8.1961e-01, -2.3897e-01,  7.7357e-01,
          1.7103e-01, -3.1137e-01, -3.1803e-01,  1.4644e-02, -1.2256e+00,
          1.9006e+00, -1.4134e+00, -9.0789e-01,  6.6457e-01, -1.1388e+00,
          3.1661e-01,  7.6553e-01,  2.2209e+00, -2.2696e-01, -2.7600e-01,
         -1.9850e+00, -8.1454e-01],
        [ 1.3607e+00,  1.1576e-02, -9.1870e-01, -1.4015e+00, -7.8363e-01,
          1.2743e+00, -1.0649e+00, -1.5940e+00, -9.8882e-01,  7.2120e-01,
          2.4298e+00, -1.3848e+00, -1.0185e-01,  1.0075e+00,  1.2874e+00,
         -3.0598e-01,  8.0372e-02, -2.2400e-01,  7.7656e-01,  1.4348e+00,
         -2.4030e-01,  1.3701e+00,  1.1354e+00,  9.0342e-01, -1.3828e-01,
         -4.6603e-01,  1.0790e+00, -1.7579e-01,  1.3170e+00, -1.7509e-02,
          1.2992e-02, -8.5394e-02],
        [-5.2375e-01,  4.2015e-03,  1.8358e+00, -1.7506e+00, -2.4233e-01,
         -1.1788e+00,  1.6026e+00, -1.7077e-01, -3.1059e-02, -5.7497e-02,
          1.7130e+00, -5.8423e-01,  2.7390e-01,  1.4105e+00, -1.1052e+00,
          8.1034e-02,  1.7336e+00, -1.8099e-02,  1.0945e+00, -2.5038e-01,
         -1.7080e+00, -3.0734e-01,  3.3999e-01,  2.8143e-01,  3.8634e-02,
          8.1180e-01, -7.4165e-02,  1.1536e+00,  2.1235e-01,  7.6054e-01,
         -2.9825e-01, -7.3720e-01],
        [-6.8337e-01, -1.8649e+00,  7.1520e-01,  3.6472e-01, -1.7065e+00,
          9.6624e-01, -9.0735e-01,  4.0909e-01,  5.4563e-01, -6.4903e-02,
         -6.3422e-01,  1.1297e+00, -6.0253e-01,  9.9284e-01, -4.4854e-02,
          8.0819e-01, -1.0254e+00,  7.0155e-01,  1.3881e+00, -2.6825e-02,
         -9.7910e-01,  1.5133e+00,  4.6258e-01, -9.7481e-02,  1.1192e+00,
          8.2629e-01, -9.1867e-01, -3.9189e-01, -4.3744e-01,  4.8523e-02,
         -9.5202e-01, -7.1832e-03]], device='cuda:0')
tensor([[-0.6713, -1.6667,  0.5396, -0.3948,  1.8203, -0.3624,  0.0693, -0.1693,
         -0.8352,  0.0149,  0.6747,  0.6029,  0.6509,  0.8474, -1.0116, -2.0824,
         -0.7162, -0.0488,  0.4863, -0.7639, -0.1077,  0.4701,  0.3321,  1.4367,
         -1.0898, -0.5269, -1.6337, -0.6595, -0.1775,  0.8977, -1.1476,  0.3414],
        [ 0.2275, -0.0104, -1.4531,  2.6507,  0.9411, -0.3079, -0.8424,  0.9720,
         -0.2541, -0.7824,  0.8246,  0.8764,  2.1536, -0.1266,  0.3728, -0.2869,
          0.9527,  0.5974, -0.9452,  1.5383,  1.0484, -1.5816, -1.1794, -0.4067,
          0.1850,  0.7275,  0.4390, -0.5423,  0.3070, -2.2144,  0.8079,  1.0558],
        [ 0.7481, -0.7980,  0.4539,  1.4664,  0.5775, -0.0933,  0.6172, -0.1382,
         -0.5176,  0.0100, -0.7898, -2.0069, -1.2763,  1.9198, -0.0153,  1.2744,
         -0.2452, -0.3822, -0.4664, -1.0095, -0.0139,  0.8879,  0.1789,  0.2975,
          1.0606, -0.2731,  0.1321,  0.4483, -1.1366,  0.2818,  0.6148,  0.3321],
        [-0.3415,  0.5474,  0.2744, -0.1605, -0.0239,  0.9214, -0.2860, -0.5975,
          0.5265,  0.7570, -0.1080,  0.1606, -0.2688,  0.0443, -0.9622, -0.2913,
         -1.2826, -0.4328,  0.1539,  0.2530,  0.9013,  0.4833,  0.2985,  0.0860,
          0.6772, -0.2064, -1.5029,  0.2433, -1.2437,  0.3916,  0.6848, -0.5441],
        [ 0.7102, -0.0752, -1.8067, -0.4487, -1.0182, -0.9357, -0.1664,  0.5745,
         -0.7098,  0.5570,  0.8630, -1.0219,  0.3906, -1.2430,  0.9005,  0.2770,
         -0.0572, -0.4590, -2.6076,  2.3024,  0.5018, -1.0322, -0.3567, -0.2614,
         -1.6175,  0.7609,  0.0516, -0.9862, -1.8461, -0.0925,  0.1754,  1.1831],
        [ 0.7508,  0.8413,  1.4745,  0.2582,  0.1742, -1.9406,  1.6408, -1.2304,
          0.1347, -1.3930, -0.1738, -0.9856,  0.8116, -0.1219,  0.2406,  0.7303,
         -1.3185, -0.3527, -0.5171, -0.8386, -0.2259,  0.4584, -1.2218, -0.4437,
         -0.8124, -1.2476, -0.3961,  1.3168,  0.3231, -1.1661, -0.8535, -1.1994],
        [-2.7523,  0.6567,  0.0814,  0.3724,  0.2241, -0.7365,  0.6555, -1.0913,
          0.1933, -0.9805, -0.2365,  0.4931,  1.0227, -0.8210, -0.6962,  0.3992,
          0.3052, -1.4649,  1.2676,  1.7636,  0.6293, -0.0632,  0.5486, -1.4304,
          1.6255,  0.6909, -1.0054,  0.3225, -1.1734,  0.2390,  0.1461,  0.6428],
        [ 0.4833,  0.0805,  0.5799, -1.8891,  0.2889, -0.4095, -2.3561,  1.1575,
          1.0309, -0.5609,  0.8761, -0.4301, -0.0732,  0.8851,  0.0835,  0.3947,
          0.2452,  1.3041, -0.7492,  1.8262, -1.4625, -0.5715, -1.1764,  0.7062,
          0.9150, -0.2744, -0.7834, -0.3691, -1.1140,  1.7363,  0.6808, -0.4682],
        [-0.0302,  0.3883, -0.1991,  0.6416, -1.5108, -0.3815,  1.0496,  0.1610,
         -0.2437, -0.4428, -0.0787, -1.5711,  0.4430,  0.4353, -1.3873, -0.6153,
         -1.1575,  0.3799,  0.1828, -0.1472, -0.3403,  0.2259, -0.4673,  0.0712,
         -1.5497, -0.9386,  0.5412,  2.0049, -1.1820, -1.4915, -1.1318,  0.2440],
        [-1.5114, -0.6626, -0.3736,  1.5189, -1.1294,  1.2530, -1.1276,  0.7607,
          0.4483,  0.4837, -0.7924, -1.3483,  0.3893, -2.0232, -1.0261,  0.3911,
         -1.8578,  0.4963,  1.3756,  0.1216, -0.2911,  0.1800, -1.3775,  1.0103,
          0.2828,  0.9035,  0.3564, -0.1733, -0.8172, -0.4354, -1.0818, -0.9192],
        [ 0.1966, -0.8573,  2.7415, -0.0895,  1.1151, -1.0897,  0.4138, -0.5911,
          0.1301, -1.0188,  0.2544, -0.4993,  0.2447, -1.3479,  1.3606,  0.5413,
          0.3536,  0.5315, -0.0934,  1.1042, -0.5748,  2.0096,  2.6471, -0.5695,
         -1.3450, -1.5421,  0.0753, -0.5095, -0.1332,  0.3307, -0.0799, -1.5134],
        [-0.5543,  0.4719, -0.8911, -0.6594, -1.9025, -0.7385,  0.5462, -0.9241,
         -0.2671, -0.4741,  0.7621, -0.2258, -0.5145, -0.5786, -1.4421,  0.4412,
          0.8150, -1.7966,  0.5422,  1.0241, -1.2691, -0.3576,  0.4603,  0.0475,
          1.6759,  0.6945,  1.4787,  0.6351, -0.9816,  0.4505,  0.4417,  0.4563],
        [ 0.3622, -0.3255, -0.7689,  1.0517,  0.1640,  0.0917,  0.4127, -0.6165,
         -1.4029,  1.9028,  0.7342, -1.3978, -1.3041,  0.5748,  0.3525, -0.0285,
         -0.4779, -1.0120, -1.1824, -3.0004,  0.4849, -2.2533,  0.7217, -0.7897,
         -0.8751, -1.1043, -1.3593,  1.0817, -0.4032, -0.0805, -0.6054, -1.4289],
        [-1.3038, -0.9153,  1.4179,  0.0089, -0.3803,  1.2150,  1.3962, -1.3583,
          0.3614,  0.0678, -0.6628,  0.3684, -0.4972,  0.3097, -0.0779, -0.5796,
         -0.0381,  0.2957, -1.9592, -0.6159,  2.1377,  1.5988,  1.0378,  0.4872,
          1.0451,  0.4577, -0.0822, -1.7856,  1.6040,  0.3055, -0.4680, -1.3068],
        [-1.3011, -1.5798, -0.1956,  1.4077,  1.3129, -0.6843,  1.7927, -1.3248,
          0.1425, -0.1428,  0.5150, -1.3147,  1.5172, -0.9672,  0.9702,  0.1556,
          1.4474, -1.3069,  0.7553, -0.8508,  0.6757,  0.2404, -0.2308, -0.2872,
          0.3256, -0.5566,  0.0525, -0.7965,  0.0314,  0.8493,  0.4603, -0.3217],
        [-0.4997, -0.9647, -2.2259, -1.7235, -0.3654,  0.0082,  1.7135,  0.2533,
         -1.3112, -0.2954, -1.3614, -0.7365, -0.6441,  0.3407,  0.2990, -0.4425,
         -0.0225, -0.6529,  0.6725,  0.7929, -1.0453,  0.6525,  1.1763,  0.8626,
          1.7682, -0.4070,  0.8522, -0.4116,  0.0842,  0.5492,  0.8697, -0.2772],
        [ 0.3224, -0.6046,  0.2412,  0.9606,  0.7761,  0.5261,  1.4614,  1.8518,
         -0.8563,  1.2792,  0.7351,  0.6296, -1.1073,  0.1459, -0.5790, -0.8751,
         -1.1012,  1.9943, -1.2908,  0.8232, -0.0990,  0.4789, -0.8078,  0.1567,
         -2.1157,  0.5915,  1.0348,  1.2038, -0.3574, -2.0532,  1.6469,  0.8360]],
       device='cuda:0')
tensor([[ 1.6237e+00, -2.6433e-01, -4.9638e-01,  4.2938e-02, -1.9242e+00,
         -1.8840e+00, -2.5750e-01, -6.9515e-01, -2.8028e+00,  9.1663e-01,
          4.9867e-01,  5.5531e-02, -1.2273e+00, -2.2625e-01, -3.4268e-01,
         -5.2638e-01,  2.2272e+00,  1.6127e+00, -1.2934e+00,  8.0844e-01,
          4.6300e-01, -2.2129e-01,  9.5280e-01,  1.4913e+00,  7.5847e-01,
         -4.4289e-01, -8.1159e-01, -1.1659e+00, -6.1879e-01,  1.6290e-02,
         -9.9049e-01, -5.1842e-02],
        [ 4.5671e-01,  7.8247e-01, -4.8359e-01,  1.2503e+00,  3.4043e-01,
         -1.6098e+00, -6.1074e-01,  1.9485e+00, -8.1325e-01, -8.2845e-01,
          1.0086e+00, -1.0136e+00,  6.2065e-01,  4.8638e-01, -9.1377e-01,
          6.3022e-01, -1.9868e+00, -1.4602e+00,  8.6382e-02,  6.3277e-01,
         -7.9788e-01, -2.8028e-01,  7.8265e-01,  1.5772e+00,  1.1797e-01,
         -2.0251e+00,  1.1781e+00, -4.0770e-01, -9.1755e-01, -2.2841e-01,
         -9.6882e-01, -9.0559e-01],
        [-1.2259e+00,  3.5683e-01,  3.6082e+00, -2.0223e-01, -2.0860e-01,
          2.4331e-02, -2.9481e-01,  7.2583e-01, -9.2094e-01, -2.0661e+00,
         -8.8991e-01,  4.5135e-01,  4.7144e-01,  9.6651e-01,  9.7058e-01,
         -1.0047e+00, -2.3845e-01, -1.6959e+00,  5.3884e-01,  2.2559e-01,
          4.4941e-01,  1.0149e-01, -1.4944e+00, -2.4956e-01, -1.9335e+00,
          2.8486e-01, -8.5153e-01, -1.5088e+00,  5.7802e-01,  9.0113e-01,
          1.9621e+00, -5.8105e-01],
        [-1.1054e+00,  7.5899e-01,  6.5797e-01, -5.2723e-01, -9.7271e-01,
          9.1368e-01, -1.7229e+00,  8.4160e-01,  1.3085e+00,  9.3696e-01,
          5.5750e-01, -6.1303e-01,  2.7531e-01,  4.0920e-01, -4.5200e-01,
         -3.8609e-02,  4.6930e-01, -4.2659e-01,  8.0227e-01,  9.3245e-01,
         -8.7219e-01,  5.4149e-01, -1.9446e+00,  1.0146e+00,  7.0792e-01,
         -5.6946e-01,  1.1529e+00, -1.2595e-01, -8.5366e-01, -1.9237e+00,
         -2.5560e-01,  1.9787e+00],
        [ 2.2702e-01, -9.7031e-01, -6.5067e-01,  6.7816e-01,  7.7413e-01,
          5.5447e-01, -7.6115e-01, -1.3053e+00, -1.8719e+00,  1.9717e-01,
         -1.0449e+00, -1.9129e+00,  6.0213e-01, -4.8062e-01, -1.1118e+00,
          6.2552e-01, -1.1477e+00, -8.9322e-01,  2.3123e-01,  1.2009e+00,
          1.2058e-01,  1.1074e+00, -1.1948e+00,  1.2758e+00,  5.3422e-02,
          1.3228e-01, -4.4955e-01,  9.5190e-01, -9.0401e-01, -5.9837e-02,
          1.5770e+00,  5.2142e-02],
        [ 6.0271e-01, -4.9180e-01,  3.5981e-01,  2.3177e+00, -8.0058e-01,
         -2.1487e-01,  9.1475e-01,  1.7198e+00, -6.1259e-01,  1.1454e+00,
          8.8049e-01, -7.8496e-01, -6.9935e-01, -2.6307e-01, -6.7224e-01,
          7.5503e-01, -4.0106e-02,  4.9787e-02,  2.9562e-02,  1.8044e+00,
          1.7080e+00, -2.6314e-01,  1.1277e+00,  3.9772e-02, -1.7416e+00,
          1.0714e-01, -2.8817e-02, -6.4788e-01, -1.3522e+00, -1.4512e+00,
          1.8064e-01, -4.7850e-01],
        [-1.8384e-01, -1.1566e-01,  1.9556e+00,  5.7377e-01, -1.1277e+00,
          3.2238e-01,  5.3177e-01, -3.6945e-01, -6.8532e-01,  8.0860e-01,
          5.3662e-01, -1.3035e+00, -3.1950e-01, -5.2672e-01, -1.7966e-01,
          1.3546e+00,  1.2891e+00, -1.3088e+00,  2.6954e-01,  9.5005e-01,
          5.7931e-01,  6.9748e-01,  6.6724e-01, -1.0602e-02, -3.2133e-02,
         -9.9435e-01,  1.8426e+00, -8.1322e-01,  1.7061e+00,  2.0390e-04,
         -7.6181e-01, -1.0980e+00],
        [ 1.0838e+00, -7.5520e-01,  1.1091e-01, -1.7367e+00, -9.3969e-01,
         -3.2491e-01, -3.3362e-01, -2.3847e-01, -1.1120e+00,  2.0975e+00,
          3.8971e-02, -3.0829e-01,  7.0687e-01, -6.1852e-01,  1.4167e+00,
         -5.4190e-02,  7.2906e-02,  3.6595e-01, -2.0229e+00, -4.7219e-01,
         -1.4845e-01, -9.3015e-01, -1.3246e-01,  3.9146e-01,  8.9330e-01,
         -6.0848e-01, -2.3382e-01, -4.6863e-01, -8.3312e-01,  1.2627e+00,
         -1.7966e+00, -5.4326e-01],
        [ 8.6112e-01, -5.7521e-01,  1.7385e-01, -1.1051e+00, -2.2000e-01,
          6.3657e-01,  7.5247e-04,  1.7926e+00,  8.6658e-01,  3.8582e-01,
         -1.0837e+00,  7.7132e-01, -1.9598e-01, -6.1705e-01,  1.1223e+00,
          1.5317e-01,  5.2825e-01,  3.6365e-01, -4.2095e-02,  1.5956e-01,
          5.4891e-01, -8.5689e-01, -1.1257e+00, -1.2973e-01, -5.5373e-01,
          1.6702e+00, -2.2737e+00, -2.0541e+00, -4.8604e-01,  2.6905e-01,
         -1.3918e+00,  5.1437e-01],
        [-5.3594e-01, -1.1479e+00, -6.3545e-01,  7.1512e-01,  4.3013e-01,
          1.4558e+00,  1.1744e-01, -4.1820e-01, -9.8970e-01,  9.2835e-02,
          6.5231e-01,  5.1745e-01,  2.4660e-01,  1.5832e+00, -3.5528e-01,
          1.1797e+00, -7.4733e-01, -1.5858e+00, -4.3516e-01,  1.6658e+00,
          9.0102e-02, -1.0798e-01, -8.4548e-01, -1.1234e+00,  8.5479e-02,
          7.5307e-01,  1.9722e-01,  7.2543e-01,  4.1950e-01, -1.5614e+00,
          1.4755e+00,  3.2880e-01],
        [-4.2880e-01, -1.0344e-01, -5.8861e-02,  1.5227e+00, -9.2947e-01,
         -1.4913e+00,  5.0068e-01,  7.2422e-01, -8.5306e-01,  9.7849e-01,
          5.4886e-02, -5.6944e-01,  7.7630e-01, -6.7347e-01,  1.5986e-01,
          6.3491e-01,  1.5328e+00, -6.0708e-01,  1.5633e+00,  7.4976e-01,
          1.3561e+00,  1.1192e+00,  7.2510e-02, -1.5121e+00,  4.4752e-01,
         -4.1073e-01,  1.1779e+00,  3.3232e-01,  4.0984e-01, -1.3573e+00,
          3.9995e-01, -5.3373e-01],
        [ 1.1524e+00, -1.5875e+00,  5.8046e-01,  2.8032e-01,  5.5754e-01,
          5.9187e-02, -1.4419e+00,  5.2446e-01,  1.1469e+00, -1.6538e-01,
          6.4042e-01, -5.0016e-01,  9.5554e-01, -1.0054e+00, -1.0111e-01,
         -2.2841e-01, -7.9699e-01,  1.4669e+00,  4.0683e-01,  4.0884e-01,
         -1.3075e+00, -1.1260e-01,  8.0898e-01,  4.6824e-01, -1.3532e+00,
         -5.9911e-01, -4.1791e-01,  3.1395e+00,  4.9535e-01, -8.2995e-01,
          2.2566e-01, -3.8676e-01],
        [-1.4669e-01, -6.6662e-02, -1.8137e-02, -3.5122e-01, -9.0931e-01,
         -1.2529e+00, -3.1252e-01,  1.7547e+00,  1.2379e+00, -8.9433e-03,
          1.9864e-01,  1.1388e+00,  1.9949e+00, -6.3152e-01,  1.4111e-05,
         -5.1258e-01, -1.6755e+00,  1.9304e-01,  1.7439e+00, -1.4024e+00,
         -1.8136e+00, -9.9139e-02,  3.7294e-01, -2.3718e-01, -5.0642e-01,
         -1.6170e+00, -4.6594e-01,  8.3542e-01, -2.4651e+00, -5.4242e-01,
         -6.8924e-01, -1.1177e+00],
        [-2.0106e-01,  1.5623e+00,  4.2418e-01, -1.6897e+00,  1.5568e-01,
          4.4494e-02, -9.1962e-01,  4.9679e-01,  1.3618e+00, -2.9208e-01,
          3.5704e-01,  6.1808e-01,  1.8843e-01, -1.4963e-01, -1.4283e-01,
         -3.3666e-02,  9.6850e-02, -1.2624e-01,  1.4744e-01, -2.3375e-01,
         -8.9859e-02,  2.7263e-01, -1.9913e-01, -1.6069e-01, -9.3870e-01,
         -3.6302e-01, -3.1959e-01, -3.5669e-01, -2.2458e-01, -1.5541e-01,
         -1.4878e-01,  1.1093e+00],
        [-7.5970e-01, -1.1314e+00, -1.8528e-01, -1.3600e+00,  5.8264e-01,
         -2.8236e-01, -1.0231e+00,  1.1029e+00,  5.8543e-01, -2.7244e+00,
         -2.3388e-01, -2.7891e-01, -1.6104e-01,  1.7494e+00,  1.3508e+00,
         -1.5422e+00,  2.1858e+00,  3.3779e-01, -5.2398e-01,  2.5251e+00,
         -1.5347e-01,  6.0330e-01, -2.2505e+00, -8.0015e-02,  1.0583e+00,
          1.0930e+00, -1.3153e+00, -4.2358e-01,  1.9416e+00, -1.4213e-01,
         -9.8978e-01, -2.0680e+00],
        [-4.0751e-01,  2.8368e-01,  1.9249e-02, -8.5456e-01,  7.3671e-01,
          1.5418e+00, -2.3502e+00,  1.3824e+00,  3.2569e-01, -5.5175e-01,
         -3.7100e-01,  7.3574e-02,  1.2840e+00,  6.0614e-01, -5.8045e-01,
          7.3553e-01, -1.0456e+00,  2.5519e-01,  3.3073e-01,  1.3860e+00,
          1.0665e+00,  1.3251e+00, -1.0768e-01,  5.6481e-01,  8.9596e-01,
         -4.2573e-01,  3.2153e-01, -1.6373e+00,  8.5130e-01, -1.6699e-01,
          1.3530e+00, -1.0287e+00],
        [ 2.8222e-01,  1.3211e+00, -1.0806e+00,  3.2137e-01, -2.8022e-01,
         -9.9184e-02, -1.0464e+00,  2.2383e-01, -6.1510e-01, -1.9934e+00,
          2.8522e-01,  1.4768e+00,  5.8787e-02, -3.1834e-02,  1.0657e-01,
          1.4169e+00,  1.6023e-01, -6.9573e-01, -4.1192e-01,  2.2603e-01,
         -2.9432e-01,  1.1354e-01, -6.7091e-01,  9.1108e-03, -1.6929e+00,
          5.7575e-01,  4.2156e-01, -5.8497e-01,  2.0344e+00,  2.5800e-01,
         -1.0005e-01,  2.5523e-01]], device='cuda:0')
tensor([[-0.6407,  1.4720,  0.1230,  1.6603, -0.0300,  0.8115, -1.2586,  0.1424,
          1.5969, -1.0552,  0.6065, -1.7742,  0.1400,  1.0546, -0.1735, -0.1709,
          0.4596, -1.7638, -0.9623, -0.0386,  1.1969, -0.5528,  0.3447, -2.0559,
          0.1459, -1.2389,  0.0238, -1.2711,  0.0562, -0.3568, -0.7905, -0.0047],
        [ 0.3491, -1.8948, -0.1842, -0.3568,  0.2768, -1.8886,  0.8836, -0.3580,
          1.4272, -0.7615,  0.1098, -0.5176,  1.0596,  1.4884, -1.5821, -0.6137,
         -0.0906, -0.0216, -0.0033,  1.4928,  0.7456,  0.8439, -1.9953,  1.6164,
         -1.7636,  0.1372,  0.0241, -0.7988,  0.6043, -0.2389,  0.2089,  1.3338],
        [-0.6920,  0.1198,  0.9468, -0.5937, -1.6169,  0.8651,  0.5511, -1.4137,
         -1.3691,  1.2255, -1.1243, -0.1322,  1.1960, -0.0495,  0.5746, -0.0676,
         -0.1643, -0.3622,  0.7112,  0.4849,  0.6683, -0.9454, -0.1902, -0.0846,
         -0.5551,  1.2545, -0.5214, -1.5621, -0.6624,  0.7157,  2.8713,  0.2717],
        [-0.3395, -0.2055, -0.1870, -0.2384,  0.6071,  1.2401,  1.1767, -0.1885,
         -0.5264,  0.0286,  2.2004, -0.5361,  1.2113, -0.3526, -1.2197,  0.8288,
         -0.0529, -1.0865, -0.1988, -0.2457, -0.2679, -0.1894,  1.6416, -0.1707,
          0.6304, -1.3843,  0.5226,  0.3615, -0.1295,  1.4946,  0.1318,  0.0856],
        [-0.2735, -0.6040, -1.0838,  0.1926, -1.1222,  0.8111,  1.4654, -1.1668,
          0.3938, -1.3594, -0.3801,  1.7831, -0.0919, -0.3677,  1.3859,  0.9372,
          0.0072,  1.7454,  0.4287, -0.1677, -0.0895,  0.7328, -1.0679,  0.8040,
          0.6438,  2.6847, -1.8139, -1.3031,  0.7917, -0.6760,  1.6225,  1.0457],
        [-1.5190, -1.1001,  0.4106,  0.1330,  0.6469,  1.8122, -0.5285, -0.5938,
         -0.5075, -0.2433,  0.0266,  0.3606, -0.1613,  0.1478, -1.1404,  0.4588,
         -1.6231, -0.8287, -0.9420,  0.3374,  0.4935,  1.0609, -0.4985, -1.3599,
         -0.8528,  1.1081,  0.7868, -0.6403,  0.2354,  0.6344, -1.4117, -0.3947],
        [ 0.5939, -0.4709, -0.6785,  1.6110, -0.2791, -0.5084,  0.2291,  1.3300,
          0.6158,  0.2625,  1.6442, -0.6313,  0.3941, -1.4379, -1.5869, -0.1248,
         -0.9686, -0.2518, -0.0788, -1.2424,  1.3726, -0.2928, -1.4571, -0.0689,
          0.0498, -0.5238,  0.7824, -0.4404, -0.5135, -0.6143, -0.7083,  0.2173],
        [-0.0264, -0.5576, -0.2437,  2.1123,  0.0484, -2.0707,  1.5019,  0.3430,
         -1.4879, -0.6971, -0.3547, -0.6620, -1.2557,  0.0174, -0.0460,  1.1275,
          0.4262,  0.8141,  0.4722,  0.0634,  1.6111, -0.7349,  0.6270, -0.3720,
         -1.3577,  0.5396, -0.8257, -0.7813, -1.4606, -0.1640, -0.6388,  1.0273],
        [ 0.9848,  0.8241, -0.5667, -0.0326, -0.1867, -0.5388, -0.9599,  0.4451,
         -1.6954, -1.4216, -0.9065,  0.5981,  0.4615, -0.5329, -0.4632,  0.1541,
         -1.6742,  0.0111,  0.0488,  1.0121, -0.2764, -0.4702, -1.1072, -0.5599,
          1.6345, -0.1060, -0.3320,  0.0574, -1.6494,  0.2846,  2.2317, -0.1324],
        [-0.6987,  1.5337, -0.5685,  1.1676, -2.1905,  0.4171, -0.8160,  0.9035,
         -1.6719, -0.1719, -1.6728,  2.2482, -0.8161, -0.3740, -1.1160, -0.7072,
          1.4098, -1.1043,  2.2115,  0.8801,  0.0375,  0.3103, -1.5000,  0.7959,
         -0.0221,  0.9929, -0.9616,  0.5289, -1.2371,  0.1402, -0.7823,  0.5783],
        [-0.3372,  1.4589,  0.4611, -0.1599,  1.4449, -0.4455, -0.1033, -0.9980,
         -0.4731,  1.7837, -1.1839, -0.4309,  0.2088,  1.4377,  0.8110,  1.2838,
         -0.1773,  0.5572, -0.0258, -0.6177,  1.3615,  1.2812,  0.2146, -0.7783,
          2.4299, -0.0485, -0.0519,  0.6330,  0.5848, -0.8863,  1.1127,  0.2637],
        [ 0.6902, -0.1848, -1.3806,  0.0074,  0.4275,  0.8191, -0.5137, -0.2535,
          0.9989,  0.4507, -0.6104, -0.1164, -0.2235, -2.0286,  0.4987, -0.5367,
         -1.2820, -0.3245, -0.0227, -1.6106,  0.7981, -2.0938,  0.3823,  0.3845,
          0.5003, -0.0813,  1.2388, -0.5312,  0.6410, -1.2049,  0.4773, -0.4039],
        [-1.0919,  0.2798, -0.0570,  2.2089,  0.0181, -0.5284,  1.0811,  0.1263,
          0.3233,  0.2269,  0.6840, -0.5189, -0.8728, -0.0692, -1.6461, -2.5824,
          2.0042, -0.3565,  0.6834,  1.9240, -0.1091,  0.7625, -1.1973,  0.9073,
         -0.2649, -0.0582, -0.0704,  2.1507, -0.3799, -1.0237, -1.6327,  0.4339],
        [-0.2616,  0.1973, -0.8631,  1.2288,  0.6646, -0.5683, -0.7883, -0.0229,
          0.0850,  0.4151, -2.1547,  0.5284, -1.4203,  2.9478, -0.7285, -0.6558,
         -0.5431,  1.0412,  1.1428, -0.5016, -0.2987, -0.4212, -0.6099, -1.2681,
         -0.1652, -0.1500, -0.7226,  1.4505, -0.2218,  0.0639, -1.8832,  1.8315],
        [ 0.3162, -2.4288, -0.3707,  1.2395,  0.7483, -0.4278, -2.9098,  0.5063,
          1.1072,  0.1434,  0.5416, -0.5296,  0.7482,  0.4098, -0.9204,  0.2309,
         -1.0026,  1.2674, -1.6643,  0.9268,  1.1914,  2.1491, -0.5013,  0.8081,
         -0.3334, -1.9698, -0.3068, -1.8300, -1.0720,  0.6927,  1.0748,  0.4030],
        [ 0.9721,  0.5116, -1.2259,  1.0483,  0.3403, -0.4335,  0.7541, -0.0413,
          0.4183,  0.3271,  0.7031, -0.1141, -1.5846, -1.2394,  0.6472,  0.3235,
         -2.5252, -0.1983, -0.9498, -2.3750, -0.0161, -0.8447, -0.4338, -0.2299,
         -1.8570, -0.1217,  1.2486,  0.0875,  0.3274, -0.2660, -0.7214,  0.0260],
        [-0.1528, -1.3807, -1.4812,  1.0732,  0.2725, -0.7167,  0.5711, -0.5173,
          0.7454, -0.9698, -2.6336,  0.8483,  1.5422,  0.3191, -0.4303,  0.0627,
          0.1538, -0.1446,  0.9767, -1.6562,  1.7525, -0.0608,  2.6048, -0.5361,
         -0.1435,  0.1800, -2.9218, -0.8788, -0.1868,  0.6488, -1.0627, -0.0805]],
       device='cuda:0')

 69%|######8   | 22/32 [00:00<00:00, 107.48it/s][Atensor([[-8.0279e-01,  1.9395e+00, -1.7540e-01, -8.2371e-02, -1.7826e+00,
          1.4387e-01,  2.6384e-02,  2.3497e-01,  9.6538e-01,  6.0717e-01,
          1.2477e+00,  6.2385e-01,  1.0072e-02, -1.1900e+00, -5.7028e-01,
         -1.4033e+00,  4.0902e-01, -1.3769e+00, -9.1369e-01,  5.1495e-01,
          4.0052e-01,  9.7433e-03, -1.2469e+00,  2.0056e+00, -4.4231e-01,
         -6.6318e-01, -9.4198e-01, -7.7269e-01, -8.5921e-01, -1.4888e+00,
          4.8829e-01, -4.7613e-01],
        [ 2.4446e+00,  8.5558e-01, -8.0149e-01, -8.9534e-01, -3.6390e-01,
         -1.8005e-01, -1.2942e+00,  1.0018e-01,  3.0202e+00,  1.3262e+00,
         -6.9258e-01, -1.4888e-01, -2.0591e+00, -2.0253e-01,  2.0724e-01,
          1.1967e+00, -4.8069e-01,  1.8432e-01,  6.7120e-01,  1.8389e+00,
          3.0617e-01, -6.8791e-02,  1.0013e+00,  2.7806e-01, -3.9741e-01,
          5.8329e-01,  8.1143e-01, -7.2691e-02, -4.2330e-01, -1.5514e+00,
         -2.5174e+00,  6.5576e-02],
        [ 8.3864e-01,  3.5660e-01,  3.2796e-01, -1.7624e-01, -2.4305e-02,
          1.1792e+00, -8.6384e-01,  4.7040e-01, -8.2617e-02, -3.2367e-01,
         -4.0195e-01, -2.1617e-01, -1.9083e-01, -6.7976e-01, -1.7483e+00,
          1.0327e+00,  2.4719e+00, -1.5120e+00,  4.7681e-01,  1.0416e+00,
         -6.5711e-03,  1.4456e+00,  1.0214e+00,  1.0549e-01, -1.0538e+00,
          8.4957e-01, -3.7401e-01,  1.4824e-01,  1.9362e+00, -8.1917e-01,
         -9.3636e-01, -1.3515e+00],
        [ 7.5723e-01,  3.3951e-01, -6.7581e-01,  2.0979e+00, -1.6338e+00,
          3.7677e-01,  4.3956e-01,  2.2003e+00,  1.4134e+00, -1.2296e+00,
          1.6393e+00, -9.4632e-01, -9.4195e-01,  1.1217e+00,  1.0280e+00,
          1.7131e-01, -2.3150e-02,  7.1285e-01,  1.2126e+00, -9.0179e-02,
         -1.3791e+00,  1.0597e+00,  1.7122e-01,  2.4129e-01,  4.3723e-01,
         -1.2748e+00,  2.2317e+00, -1.7982e-01, -1.4071e+00, -2.0011e-01,
         -7.9479e-01, -9.3007e-01],
        [-1.7640e+00, -2.2818e-01, -1.1251e+00,  1.6389e+00, -1.6297e+00,
          1.2805e+00,  1.7031e+00, -1.0439e+00,  2.2391e+00, -1.8351e+00,
          6.7521e-02, -4.2772e-01,  2.6541e-01,  8.4333e-02,  1.3938e+00,
         -2.5146e+00, -7.9983e-01,  4.3671e-01,  1.9807e-01,  1.3119e+00,
         -8.9347e-02, -1.3598e+00,  2.4571e-01,  1.7774e-01, -2.0571e-01,
          1.4394e+00, -7.7557e-02, -8.4882e-01,  1.7673e+00,  1.4557e+00,
          3.5089e-01, -1.2949e+00],
        [-2.8162e-02,  1.0007e+00, -9.0083e-01, -1.0881e+00, -1.6578e+00,
          5.8976e-01, -1.7553e-01,  1.6641e+00, -1.8387e+00, -1.4110e+00,
         -5.7946e-01,  3.0307e-01,  1.4992e+00,  3.9434e-01, -1.2028e+00,
          3.1422e-01, -4.9496e-01, -2.4591e-01,  1.8898e+00, -1.9826e+00,
          9.4509e-01,  1.8971e-01,  2.7010e-01, -6.5476e-01,  1.1781e+00,
          1.0474e+00, -1.8118e-01, -3.1287e-01,  1.8740e-01, -1.3427e+00,
          2.7376e-01, -1.4851e+00],
        [ 2.8051e-01, -1.0315e-02,  7.6570e-01, -1.9888e+00, -2.2315e+00,
          3.8659e-02, -5.1198e-01, -4.6561e-01, -1.0229e+00,  7.2211e-01,
         -1.2700e+00,  1.6543e-01, -9.7840e-01, -8.7629e-01, -1.6957e+00,
          1.3693e+00,  1.6329e-02,  1.2214e+00, -2.2787e+00,  7.3284e-01,
          1.0174e+00, -4.3955e-01, -4.5918e-01,  2.0364e+00, -2.4120e+00,
         -8.0045e-01,  5.7401e-01, -2.6150e-01,  3.0583e-01, -1.4741e+00,
          6.3757e-01, -4.3257e-01],
        [ 1.2145e+00, -1.9933e-01, -1.3690e+00, -1.9032e+00,  2.1870e-01,
         -9.9086e-01,  7.6774e-01, -1.6036e+00, -4.3720e-01,  1.8917e-01,
          4.1921e-01,  3.2484e-01,  1.7391e+00, -1.6617e+00, -6.8739e-01,
          2.6638e-01,  3.5537e-01, -5.5433e-01, -1.9846e-01,  4.3674e-02,
          2.4409e-01, -9.4200e-01,  8.4550e-01,  8.8832e-01,  9.3035e-01,
         -1.6277e+00,  1.8487e-01,  1.4608e+00, -3.6965e-01,  2.5222e-01,
         -5.5586e-01, -1.1105e+00],
        [-7.9889e-01, -4.2972e-01,  1.0587e+00,  2.0804e+00, -4.3215e-01,
          6.7279e-02, -1.3731e-01,  1.0674e+00,  6.9984e-01,  3.7052e-01,
          1.3158e+00,  1.7198e-01,  1.5642e+00,  2.7073e-01,  6.4040e-01,
         -3.3340e-04, -1.0638e+00, -3.6461e-01,  6.7109e-01,  5.3558e-01,
          8.7239e-01, -1.8959e-01,  1.6315e+00,  7.7133e-01, -1.9770e-01,
          3.2949e-01,  3.0580e-01,  4.7252e-01,  1.1828e-01,  4.1386e-01,
         -2.5515e-01,  6.0148e-01],
        [-2.1202e+00,  4.8924e-01,  6.4263e-01,  1.0361e+00,  2.0101e+00,
         -3.0048e-01, -1.3938e+00,  5.8457e-01, -6.3802e-01, -2.6267e-01,
         -1.2913e+00,  4.4261e-01,  1.2516e+00, -1.2387e-01, -5.6832e-01,
         -4.4840e-01,  9.6297e-01, -9.8265e-01,  9.4980e-01, -3.8850e-01,
         -2.6674e-02, -5.5961e-01,  9.9462e-02,  1.8715e+00, -7.3933e-01,
         -1.9117e-01, -3.6143e-01,  1.3906e+00,  1.8069e+00,  8.5428e-01,
          3.2978e-01,  1.4001e+00],
        [ 2.7063e-01,  4.6263e-01,  1.6416e+00, -3.4278e-01,  3.1036e-01,
          1.0253e+00,  6.2412e-01,  1.1521e+00, -1.1977e+00, -1.6491e-01,
          1.3407e+00,  8.8188e-01,  1.7949e+00, -8.2172e-01, -4.4668e-01,
          1.7478e+00, -5.0095e-01,  7.4904e-01, -1.0183e+00, -1.4766e+00,
          1.0827e+00, -1.6375e+00, -1.1085e+00,  7.5525e-01,  1.0658e+00,
         -5.3492e-01,  6.9616e-02,  1.6659e-01,  1.0495e+00, -1.6115e-01,
         -2.5609e-02,  1.1629e+00],
        [-5.9098e-01, -7.6755e-01, -1.3493e+00,  2.3792e-02, -9.7636e-01,
         -1.9148e+00, -8.5234e-01,  1.2088e+00,  6.4388e-02,  3.2060e-01,
         -2.1599e-01,  6.9145e-01, -1.2038e-01,  2.7939e-02, -9.7727e-01,
          1.6730e+00, -1.7326e+00,  1.6618e+00,  9.8671e-01,  9.8610e-01,
          4.4319e-01, -1.2071e+00, -1.1247e+00,  2.6015e+00,  6.0290e-02,
          6.1103e-03,  6.0552e-01,  6.8710e-01,  1.2248e+00,  9.9570e-02,
         -1.5353e-01,  1.7363e+00],
        [ 1.9077e+00, -1.2394e+00, -2.0860e+00, -3.0515e-01, -5.8072e-01,
         -1.6487e-01,  7.7053e-01, -5.0341e-01,  5.1028e-02, -1.1584e+00,
          4.4354e-01, -9.5256e-01,  6.5398e-01,  5.4140e-01, -8.8559e-01,
          1.6944e-01,  9.1603e-02, -4.2997e-01,  5.3935e-01,  5.3862e-01,
          7.6750e-01,  1.0594e+00, -4.5919e-02, -1.4413e+00, -8.2506e-01,
          1.7434e+00,  4.2707e-01, -1.8881e+00, -3.5640e-01,  6.0367e-01,
          1.4346e+00,  1.0123e-01],
        [-7.0394e-01,  2.2706e+00,  3.0948e+00,  1.2316e+00,  1.4987e+00,
         -1.7778e-01,  5.9275e-01, -3.1616e-01,  6.3505e-01,  8.7541e-01,
          1.1096e+00, -1.4275e+00,  4.7565e-01, -1.9690e+00,  9.2802e-01,
         -9.8625e-01, -2.4278e+00, -6.6623e-01, -5.3910e-01, -1.8003e-01,
          2.6368e-01,  2.5308e-02,  7.0422e-01, -1.5150e+00,  8.4175e-01,
         -7.9844e-01, -4.9524e-01, -9.4354e-01,  3.8855e-01,  1.0113e+00,
         -1.0731e-02,  1.2544e-01],
        [-1.4238e+00,  1.4640e+00,  7.1292e-01,  1.5069e+00,  8.5065e-01,
          1.4599e+00,  5.1593e-01, -4.5104e-01, -1.6144e+00, -8.9117e-01,
          3.1239e-01, -1.3854e+00,  1.6215e+00, -1.7058e+00, -1.6918e-01,
         -1.8640e+00,  1.1477e+00,  1.0339e-02, -4.8130e-01,  4.2532e-02,
          2.0116e+00,  9.3160e-01,  1.3759e+00, -1.1738e+00, -1.2845e+00,
         -4.9618e-01,  1.8888e-01, -1.8121e-01,  4.1346e-02, -7.1551e-01,
         -8.8761e-01, -2.6145e-01],
        [ 7.9162e-01,  3.4965e-01,  2.3083e-01, -3.3065e-01,  5.5392e-01,
         -5.6562e-01,  1.5923e+00, -3.3244e-01, -1.3250e+00,  1.8956e-01,
          1.6977e+00,  1.8547e+00,  6.6424e-01,  2.1843e-01, -4.2224e-01,
         -8.8734e-01,  1.1468e+00, -5.2654e-01,  1.1831e+00,  1.2406e+00,
         -1.4093e-01, -6.4528e-01, -6.6774e-01, -6.3770e-01, -1.2641e+00,
         -3.9714e-01,  1.1724e+00, -1.5385e+00, -9.6325e-01,  4.1919e-01,
         -3.3284e-01,  2.0429e+00],
        [ 3.4348e-03,  1.4234e+00,  5.7186e-01,  1.7046e+00, -8.8055e-01,
         -5.8811e-01, -1.0212e+00,  6.3843e-01,  7.3584e-01, -2.1639e-01,
         -5.5793e-01, -8.1845e-01,  4.7561e-01, -3.8324e-01,  2.2677e-01,
         -4.1815e-02,  3.9533e-01,  1.0321e+00,  1.5882e+00, -8.9568e-02,
         -2.7174e-01,  1.8265e+00, -1.4472e+00,  2.6280e-01,  1.0956e+00,
          7.7422e-02, -6.1038e-01,  3.7985e-01, -3.9680e-01,  1.3741e-01,
          6.4877e-01,  8.9653e-01]], device='cuda:0')
tensor([[ 1.4856, -0.1385,  1.4618,  0.4517, -0.7401, -0.8025, -1.0678,  1.4353,
          1.0927, -0.5964,  0.0242,  1.0903,  1.1404,  1.1025, -0.3440,  0.4750,
         -0.4448, -1.4543,  1.1043,  0.3590, -1.2085,  0.9751,  1.5523, -0.2766,
          0.4331, -0.7612, -2.0349, -0.6223,  1.7371,  0.4843, -0.2301,  0.7264],
        [-2.1369, -0.3789, -1.0809,  0.2958, -0.2969,  0.7290, -1.1441,  1.0348,
         -0.0943, -0.3221,  0.0739, -0.9273,  1.3969, -0.5159,  0.7157,  0.8338,
         -0.7690,  0.1924, -0.1286,  1.1131,  0.3761,  0.7498, -0.9970, -0.1044,
          0.3794, -0.4619, -0.4008, -0.4369, -0.3479, -0.0263, -0.0335,  0.0516],
        [-0.1861,  0.3824,  0.2779,  2.0840,  1.2496,  0.3422, -0.0122,  1.4616,
          0.4425, -0.9544, -0.2486,  0.0715,  0.5669, -1.7868,  0.2311,  1.1718,
         -1.0506,  1.2978, -0.0352,  0.0669,  1.1582, -1.0265,  0.1904, -0.8953,
          2.1963, -0.8716, -0.2515,  0.5202,  1.0366,  0.9919, -0.3144, -0.3059],
        [-1.1008,  0.0653,  0.0073, -0.5423,  0.1220, -0.4816, -0.2353, -0.3197,
         -0.2781, -1.7705, -0.8476,  0.9323,  0.7164, -0.8328, -0.9248,  1.6022,
          2.2771,  0.4802, -0.7601, -0.4891, -0.8708,  0.3326,  0.7334,  1.2106,
          2.0551,  0.1638,  0.1263, -0.3417,  1.2856, -0.5861, -0.4198, -0.4592],
        [-1.5397, -1.3160,  1.1210, -0.8036, -0.0779,  0.0353, -0.7508,  1.1851,
         -3.2836, -1.1597, -0.9964,  0.4913,  0.8256,  0.2802, -0.8777, -0.2743,
          0.6229,  0.7794,  0.4055,  0.1453,  0.7459,  0.5947, -1.8698,  1.1381,
          0.8916, -0.3966,  1.2598,  0.2420, -1.7521,  0.5628,  0.7266, -0.6735],
        [-0.5468, -0.2314, -0.3277,  0.3506, -0.8294, -1.3337, -1.6663,  1.2728,
          0.3458, -0.2372, -1.6262,  0.4069,  0.9190, -2.6553,  0.9769,  1.2845,
         -0.0400, -1.0470, -0.3337,  1.2160,  0.4043,  1.2349, -0.6842,  1.9062,
         -0.2589, -0.5765,  1.1383,  0.3204, -0.9892,  1.3471, -0.2965,  0.7007],
        [ 0.3822, -0.3739, -0.7918, -1.8920, -0.3299,  1.6466,  0.1771,  0.1652,
          1.0929, -0.0817, -0.8542, -1.3586, -0.6801,  2.4755,  0.0255, -0.4764,
         -0.4126, -1.0101,  0.1615, -1.6208, -0.3396,  2.1588, -0.7646, -0.0894,
          1.6972,  0.5081,  0.9623,  0.4997,  0.9955,  0.8497, -0.9262, -0.1485],
        [-0.2717,  0.7648, -0.2522,  0.7995, -0.5543, -0.1130,  0.1069, -0.5964,
          0.9694,  0.0677, -1.9240,  1.6082,  1.3614, -0.7855, -0.4225, -0.7712,
          1.2357, -0.6486, -0.9516, -1.0925, -1.2532,  0.5689, -0.5676, -0.6622,
         -1.0080, -0.2079, -1.3075,  0.2625,  0.4415,  0.3807,  0.2815,  0.7843],
        [ 1.2138,  0.5257,  0.9610,  0.6033,  0.2766, -0.0415, -0.5203,  1.1405,
         -0.0974, -0.7720,  1.1696,  0.6338, -0.4604, -0.1850, -0.4499, -0.0132,
         -0.3403, -0.5597, -1.8196,  0.2759, -0.6051, -0.5859, -0.1452,  0.8758,
         -0.1653, -0.3171, -0.9987,  0.2160, -0.7532,  1.5882, -1.5737, -0.5311],
        [ 1.8352,  0.6038, -0.4563,  0.0693, -1.5649, -0.2937, -0.1633, -0.0933,
         -0.4588,  1.1895,  1.5054, -1.3273, -0.7313,  0.2600, -2.3237, -0.5045,
          0.6961,  1.9059,  0.2716,  0.7587,  0.1620,  0.8838,  1.9229, -0.4388,
          0.3119,  1.1313, -0.2166, -2.6350,  0.8359, -0.9418,  0.4552, -2.8456],
        [ 0.2398,  0.0542,  0.2695,  0.4497,  0.6795,  1.4061,  0.0846,  2.2972,
          0.2748,  0.0500,  1.0323,  1.4008, -1.8912, -1.7628, -1.2396,  0.0722,
         -0.2665, -0.6421, -1.1561,  0.1924, -0.4004,  0.3314,  0.6169, -0.3143,
          0.4752, -1.0408, -0.6945, -0.5462, -0.8898,  1.2722, -1.1674, -0.2017],
        [ 1.8116,  1.7381, -0.5343,  1.2310, -1.5612, -0.9580, -0.7178,  1.4941,
          0.3081,  1.8953, -0.2854,  0.1731,  0.5443,  0.0480, -0.3785,  1.2481,
          1.1874, -0.0060, -0.1614, -0.0159, -1.6033, -0.7471, -0.3109,  0.9182,
         -0.3021, -1.5616, -0.7702,  0.7190,  0.0361,  0.5119, -1.8837, -0.5568],
        [-1.2993,  0.4122, -1.6167,  0.1353, -0.1733, -0.1826,  1.5824, -0.0575,
         -0.4845, -1.1089,  1.4310,  0.2402, -0.1116,  0.6723,  0.7935,  0.5304,
         -1.4792,  0.2658,  0.5560,  0.4921, -1.1226, -0.3022, -0.3671, -0.5756,
         -0.0469,  0.6627,  1.3763,  0.1097, -0.1167,  0.0224, -0.0432, -1.5134],
        [ 1.4910, -0.2108, -2.0043, -0.9661, -2.2330, -0.3162,  1.5786,  0.5046,
          0.2463,  0.6482, -0.0463,  0.5239,  0.1285,  0.1640,  0.2779, -0.0834,
         -1.3494,  1.0685,  1.4327,  0.1770, -0.6673,  2.4321, -0.2956,  0.7887,
         -0.4065, -0.2982, -0.1289,  0.2225, -1.6288,  1.2838,  0.8727,  1.5522],
        [-1.2510,  0.7572,  0.5062, -1.0472,  0.6392, -2.6665, -0.2936, -1.1489,
         -0.9793, -0.7152, -0.3152, -0.7394, -0.3214,  0.7289,  0.5479, -1.4349,
          1.4233,  0.0772,  1.0784,  1.0502, -1.6464, -1.8659, -0.3340, -1.1643,
         -2.8911, -0.1648, -0.1412, -0.5600, -0.5254, -0.4172,  0.4563, -0.5301],
        [ 0.3185,  0.5909,  0.0895,  0.5123, -0.1279,  0.5963, -1.9811, -0.1557,
          0.0682, -0.8016,  0.0927, -0.7258, -1.1710, -0.0661, -0.8418, -0.9007,
         -1.2783, -0.1025, -1.4374,  0.3744, -0.2191, -0.2267, -0.9138,  0.0597,
          0.0932, -0.4254,  1.0799, -0.4620,  1.4439,  0.5154, -0.4260,  0.0334],
        [ 0.1307, -1.0204, -0.1459, -0.3029, -1.1977,  0.9814,  2.5757,  0.2826,
          0.8950, -1.2440, -2.3129, -0.0844, -1.4117, -1.5599, -0.2546, -0.1820,
          1.1223, -1.0319, -0.0960,  0.0600, -0.9908,  0.2212, -0.4846, -0.1929,
         -0.7735,  0.0256, -0.1373, -0.8966, -0.6588,  0.2096,  1.0821, -1.1521]],
       device='cuda:0')
tensor([[-1.5426e-03,  3.9633e-01,  7.0366e-01,  9.0150e-02,  5.2555e-01,
         -2.1849e-01, -6.3937e-01, -8.9195e-01,  5.2651e-01, -1.3617e+00,
         -3.6823e-01, -2.9794e-01,  1.2327e-01,  5.4588e-01,  1.2523e+00,
         -1.0274e+00,  3.3038e-01, -4.7897e-02, -2.3499e-01,  9.0595e-01,
         -6.2825e-01, -1.2672e+00,  1.3536e+00, -8.0155e-01,  6.9925e-01,
         -1.3583e+00, -5.1261e-01, -2.5780e-01, -1.6635e-01,  7.7825e-01,
          1.1359e+00,  2.0841e+00],
        [-4.9158e-01, -2.0162e-01, -1.2969e+00, -1.5054e+00,  1.1651e+00,
         -8.3193e-01,  8.0110e-01,  5.0839e-01,  1.5175e+00,  4.9740e-01,
          1.4980e-01,  6.1178e-01,  1.0958e-01, -5.0029e-01, -2.3131e+00,
         -2.1744e+00,  3.5993e-01,  3.1659e-02,  2.4009e+00, -1.0348e-01,
          1.9485e+00,  2.8347e-01,  6.0785e-01, -2.6992e-01,  1.3664e+00,
         -3.2413e-01, -2.2254e+00,  3.1576e-01, -2.3374e-01,  3.5587e-01,
          4.8257e-01,  1.0404e+00],
        [-1.9411e+00, -6.5227e-02, -1.1711e+00,  5.9842e-01, -6.4198e-01,
         -1.0320e+00,  1.5722e+00, -1.0352e+00,  5.6843e-01, -1.8544e+00,
          1.0138e+00, -1.0691e-01, -1.0486e+00,  1.9339e+00, -1.8290e+00,
          4.9629e-01,  1.4784e+00, -8.1731e-01,  2.0835e-01, -1.2908e-01,
          5.3797e-02,  2.1594e+00, -5.0608e-02, -9.0490e-02,  2.0834e-01,
         -1.6702e+00,  1.4918e-01,  1.1046e+00,  6.0454e-01, -3.3076e-01,
          5.8818e-02, -1.1299e-01],
        [-9.8256e-01,  1.5594e-01,  8.0577e-01, -5.3651e-01, -8.7410e-01,
          1.2060e+00,  2.1580e-01, -1.8498e-01, -2.0730e+00, -5.0000e-01,
          6.9202e-01,  5.5832e-01,  3.6722e-01,  2.0542e-01,  4.5180e-01,
         -2.5512e+00,  1.5069e+00,  1.7303e+00, -1.1049e-01, -1.8747e+00,
          1.1207e+00,  6.7787e-02,  7.1680e-01, -8.5748e-01, -1.1396e-01,
          2.2561e+00,  7.1101e-01, -6.6337e-01,  4.4440e-01, -1.7454e+00,
         -2.1278e+00,  3.1036e-01],
        [ 1.0115e+00,  5.9648e-01, -7.0196e-01, -3.8351e-02, -7.0240e-01,
         -8.2602e-01,  1.2641e-01, -7.1669e-01, -1.2278e+00,  1.1379e-01,
         -1.2133e+00,  5.4219e-01, -1.3882e+00,  1.7925e-01,  1.6169e-02,
         -4.9602e-01,  6.6786e-01, -1.5019e+00,  3.5834e-01, -2.1279e-01,
          2.3306e+00,  1.4161e+00,  2.4351e-01, -2.1421e-01, -2.7766e-02,
          2.7546e-02, -7.9377e-02, -3.4473e-01,  5.7335e-01, -1.2590e+00,
          1.6105e+00, -9.3676e-01],
        [-6.2433e-01,  8.2644e-01,  4.7201e-01, -8.8012e-01, -6.6887e-01,
         -1.1593e-03,  1.4971e+00, -2.0693e-01,  6.2791e-01,  1.5364e+00,
          2.6095e-01,  1.0686e+00, -1.4764e+00,  1.0006e+00, -1.9353e+00,
         -1.2060e-03, -7.0384e-01,  6.8711e-01, -4.4391e-01, -7.8395e-01,
          4.3427e-01,  1.1289e+00, -1.2596e+00, -8.1888e-01,  1.2646e-01,
          8.9882e-01, -1.3012e-01,  2.7741e-01, -1.2035e+00,  4.7955e-01,
         -2.0957e-01, -8.4698e-01],
        [ 3.3236e-01,  1.1823e+00, -3.3562e-01, -7.6194e-01, -1.3284e+00,
          8.9534e-01,  1.2752e+00,  1.4469e-01,  8.3641e-02,  6.2907e-01,
          1.3506e+00, -4.2566e-01, -1.6400e+00, -6.4532e-02,  1.1015e+00,
          1.9658e+00,  1.1006e-01, -2.4870e-01, -1.5018e+00,  4.6098e-01,
         -4.1559e-01,  7.1252e-01,  9.3289e-01, -4.3809e-01,  1.2220e+00,
         -1.8266e+00, -1.0170e+00,  1.1554e-01,  1.2179e+00, -1.1780e-01,
         -7.2509e-01, -5.0853e-01],
        [ 2.9977e-01, -1.1131e+00, -8.8480e-01, -4.1211e-01,  1.2080e+00,
         -8.8792e-01,  1.2779e-01, -1.3828e+00,  2.6215e-01, -1.1376e+00,
         -3.1907e-01, -9.8653e-01,  3.9979e-01,  5.0072e-01,  2.0382e-01,
         -8.8830e-02,  1.7559e+00,  7.3300e-01, -1.4194e+00,  3.2490e-02,
         -8.1676e-01, -7.7620e-01, -9.9112e-01, -1.2408e+00,  7.6755e-01,
          1.1905e+00, -1.0435e+00,  4.6047e-01, -3.2456e-01, -3.1214e-01,
          7.0821e-01,  1.5846e-01],
        [-8.3007e-01, -1.4385e+00, -2.1918e-01,  4.1387e-01, -1.2702e-01,
          1.0021e+00, -1.1373e+00,  4.9997e-01,  4.9927e-01,  1.0158e+00,
          7.3691e-01, -1.2215e+00, -4.2979e-01,  3.8208e-02,  2.1916e+00,
          2.1215e+00,  1.1240e-01, -8.1613e-01, -4.8696e-01, -3.3561e-01,
          7.1134e-02,  4.3115e-01, -8.8147e-01, -1.9288e-01, -9.1921e-01,
         -4.1730e-01,  1.0385e+00, -1.5689e+00, -1.0295e+00,  8.5675e-02,
          4.7107e-01,  2.2609e-01],
        [-1.2470e+00, -1.5637e+00,  8.1947e-01, -2.0275e-01,  2.5254e+00,
          1.5142e+00,  4.2833e-01,  1.3976e+00,  6.8777e-01,  3.4432e-01,
          6.1977e-02, -8.5935e-01, -1.4380e+00,  8.1005e-01, -8.7509e-01,
          2.0168e+00, -4.5833e-01,  7.4470e-01, -6.4323e-01, -2.8841e-01,
         -6.4273e-01, -8.7361e-01,  1.4792e+00,  1.6698e+00, -1.1378e+00,
         -3.0746e-01, -8.7407e-01,  1.6962e-01,  8.0438e-01,  1.8091e+00,
         -1.0718e+00,  3.6392e-01],
        [ 9.5536e-01, -1.6020e+00,  1.6232e-01,  4.6510e-01, -1.1004e-01,
          6.3382e-01, -3.8640e-01,  9.8214e-01,  1.3252e-01, -6.0570e-01,
          2.0525e-01,  5.9508e-01, -6.6105e-01,  1.1829e-01, -4.0372e-01,
          7.7868e-01, -9.9658e-01,  4.9012e-01, -2.6200e-01, -6.2708e-01,
          1.4298e-01, -5.0681e-01, -1.7325e+00,  2.8983e+00,  4.6255e-01,
         -5.3710e-01, -5.5283e-01,  1.6150e+00,  4.3925e-01, -1.6708e-01,
         -5.2516e-01,  4.3296e-01],
        [-2.5215e-01,  1.2538e+00, -2.1665e-01, -1.1396e+00,  1.5154e+00,
         -6.4506e-01,  1.2645e+00,  3.3493e-01, -9.0650e-01, -7.1296e-02,
         -1.5547e+00, -4.1421e-01, -9.9826e-01,  4.0687e-01,  4.0079e-01,
          2.5791e-01, -2.7100e+00, -7.6890e-01,  1.8520e+00,  1.6681e-01,
         -3.2781e-01,  2.2790e+00, -9.2012e-02, -5.0675e-01, -5.7562e-01,
          1.3875e+00, -2.8439e-01,  7.2495e-01,  3.2065e-01, -3.1410e-01,
          4.9694e-03,  9.0254e-01],
        [ 7.9642e-01, -4.2279e-01,  1.8260e+00,  5.8732e-01, -1.3449e+00,
          1.1392e+00,  8.4070e-01, -8.8263e-03,  1.4232e+00,  6.1679e-01,
         -2.5982e-02, -8.7090e-01,  1.3059e-01,  4.8078e-01,  6.0899e-01,
         -6.0427e-01,  3.0297e-01,  6.5467e-01, -1.8380e-01,  2.8704e+00,
          1.9124e+00, -1.3627e+00,  3.9089e-01,  1.5558e+00, -3.2630e-01,
         -6.9791e-01, -1.1379e+00,  6.1226e-01,  1.1041e+00, -1.0916e+00,
         -3.4720e-01,  9.7238e-01],
        [-1.2489e-01,  1.0312e+00, -1.1756e+00,  1.6480e+00,  1.0670e+00,
          9.2722e-01,  1.3367e-01, -1.9771e+00,  1.1646e+00,  9.9364e-01,
          5.2619e-01,  8.9685e-01,  7.0072e-01, -1.0970e+00,  3.8349e-01,
          1.0181e+00,  2.9119e+00,  7.4804e-01,  1.4421e+00, -1.7967e+00,
          1.5439e+00,  6.7696e-01, -7.2158e-01,  6.8592e-02, -8.7379e-01,
         -9.1447e-01, -1.7980e+00,  1.4095e-01, -9.5098e-01,  1.5299e+00,
          1.7181e+00,  1.9206e+00],
        [-2.1800e+00, -1.7646e+00, -1.1181e+00, -1.2133e+00, -5.6431e-01,
         -2.0168e-01,  1.3513e+00, -4.1890e-02,  2.7860e-01, -1.3511e+00,
          5.0413e-01,  1.6231e-01,  6.5335e-01,  1.7070e+00, -1.8347e+00,
          5.1767e-01, -4.2046e-01,  7.1297e-01,  1.0021e+00, -4.4370e-01,
         -1.2189e+00,  1.5508e-02,  5.4296e-01, -5.6134e-01,  9.0714e-02,
          6.0828e-01, -7.5146e-01,  4.5934e-01,  1.6235e+00, -8.1458e-01,
         -2.1655e-01, -1.0423e+00],
        [-1.3305e+00, -3.1988e-01,  1.4995e+00, -6.7099e-01, -8.8950e-01,
          2.3276e-01, -1.4222e+00, -8.0379e-01, -7.7769e-01, -1.5167e+00,
         -3.6641e-01, -2.5536e-01, -5.1761e-01, -7.4928e-01,  1.3237e+00,
         -7.6864e-01, -1.5751e+00, -1.7464e+00, -3.3582e-01,  1.2148e+00,
          5.4201e-01, -1.1899e-01,  1.0978e+00,  1.7993e-01,  1.8395e-01,
         -1.0856e-02, -1.6919e-01,  4.4015e-03, -1.6405e+00, -1.1687e+00,
          2.2663e-01, -4.2059e-01],
        [ 5.4386e-02, -6.9223e-01,  2.8127e-01, -2.2497e+00,  7.1360e-02,
          1.9946e+00, -7.9342e-01, -6.6568e-03,  8.4557e-01,  7.1201e-02,
          2.8093e-01,  3.2892e-01, -1.6714e-01,  1.7622e+00, -2.2192e-01,
          2.4135e-01,  1.2131e-01,  6.5152e-01, -5.4859e-01,  1.2419e+00,
         -2.9496e-01,  8.3722e-01, -9.9121e-01, -3.1067e-01,  9.2723e-01,
         -9.5027e-01,  7.5494e-01, -4.6546e-01,  4.3801e-01, -1.1529e+00,
          6.8511e-01,  3.5816e-01]], device='cuda:0')
tensor([[-3.2427e-01, -1.7006e-01, -5.1784e-01,  1.4792e-01, -2.4477e+00,
          1.1133e+00,  6.3028e-01, -9.0854e-01,  2.7069e-01,  7.0895e-01,
          1.8246e+00,  3.4144e-01, -9.9367e-01,  4.1277e-01, -1.0151e+00,
         -6.6045e-01,  1.1917e+00,  4.3906e-01,  4.7886e-01,  9.4130e-01,
          7.1602e-02,  4.0022e-01,  1.5978e+00, -9.6457e-01,  1.0305e-01,
         -2.2536e+00, -5.3073e-01, -9.6534e-01,  1.7975e+00, -6.5067e-01,
          1.9611e+00,  9.4493e-02],
        [ 2.7516e-02,  7.3633e-01,  1.3789e+00,  2.8599e-01, -1.4145e+00,
          6.5437e-01, -6.4604e-01,  4.9861e-01, -4.9242e-01, -1.8637e+00,
          1.6878e+00, -1.8678e+00,  1.1517e-01, -6.8319e-01,  1.2530e+00,
         -4.6618e-01,  6.5057e-01,  1.4191e+00,  1.7747e+00,  1.3825e+00,
          7.6818e-01, -3.0373e-01, -4.6075e-01, -1.6273e+00,  4.9065e-01,
          9.0433e-01, -1.4113e+00, -1.2456e+00, -4.1511e-01, -4.7460e-01,
          1.1210e+00,  1.2879e+00],
        [-4.6799e-01,  2.1403e-02, -3.9873e-01,  4.8686e-01, -1.8007e+00,
          7.0175e-01, -5.8330e-01, -8.0940e-03, -3.8258e-01, -1.1081e+00,
         -8.9779e-01,  3.9180e-01, -1.7416e+00,  2.1851e+00,  2.9279e-01,
         -7.4932e-01,  1.2082e+00, -6.5711e-01, -1.3072e+00,  5.2144e-01,
          7.0530e-01,  6.4410e-01,  8.7792e-01, -3.5684e+00,  1.4475e+00,
         -1.1409e+00, -1.1449e+00,  4.7123e-01, -7.4304e-01, -6.9124e-01,
          1.4522e+00, -2.7245e-01],
        [ 1.5170e+00,  8.5647e-01,  7.5511e-01,  4.3957e-01,  3.7853e-01,
          1.4735e+00, -7.4345e-01,  1.1832e+00,  1.1823e+00,  7.9968e-01,
          1.5749e+00, -8.0156e-01,  3.3533e-01, -1.1623e+00,  5.3793e-02,
          1.1541e+00, -9.2207e-01,  1.1131e+00, -8.9620e-01,  5.1358e-01,
         -9.0645e-02,  9.1659e-01,  4.1094e-01,  6.4877e-01,  3.6678e-01,
          1.6573e+00, -2.8113e-01,  1.6743e-01,  3.6852e-01, -2.6382e-01,
          2.5530e-01, -6.9861e-01],
        [-1.2863e-01,  8.2408e-01, -3.1233e-01,  9.9790e-01,  1.5658e-01,
          5.6498e-01,  3.5157e-01, -2.0974e-01,  6.1796e-01, -1.5464e+00,
         -4.3649e-01,  1.6398e+00,  1.6132e+00,  1.4697e+00,  4.4919e-01,
          7.9858e-01,  2.9348e-01,  1.0693e-01,  6.9349e-02, -1.2409e+00,
         -1.4566e+00, -6.3048e-01,  5.7559e-01, -1.8715e-01, -6.5692e-01,
          3.2323e+00,  7.7522e-01, -9.5727e-01, -2.8629e-01, -6.9441e-02,
          1.4641e+00, -2.9538e-01],
        [-2.3824e-01, -4.7613e-01,  2.9405e-03, -1.1773e+00,  2.7721e-01,
         -3.4066e-01, -4.4340e-01,  9.5517e-01,  9.1669e-01,  7.5598e-01,
          7.3744e-01, -1.4092e-01,  4.5606e-01, -9.5495e-01,  2.2364e+00,
          2.1213e-01, -7.2268e-01,  1.3246e+00, -2.3757e+00, -7.0821e-01,
          9.1838e-02,  1.4944e+00,  1.0156e+00,  7.9329e-01,  1.2804e+00,
          5.8288e-01, -6.3300e-01, -4.4289e-02,  3.2997e-01,  1.6069e+00,
          1.1236e+00,  1.2455e-01],
        [ 7.4483e-01, -1.4406e-01,  3.5280e-01, -6.9094e-01, -1.0253e+00,
         -2.9193e-01,  1.5711e-02, -1.9420e-01, -1.1345e-01,  4.6832e-01,
          8.4286e-01, -8.1932e-01,  7.7053e-02,  2.0745e+00,  4.1064e-02,
          7.0438e-01, -1.3151e+00, -2.5628e-01,  1.4342e+00,  2.4479e-01,
          3.9072e-01, -1.4156e-01, -1.9380e-01, -1.9158e-01,  1.5028e+00,
          2.0692e-01, -1.7693e+00, -4.2441e-01, -6.9378e-02,  6.2616e-01,
         -7.6921e-01,  1.5072e-01],
        [-1.4275e+00, -8.2244e-01, -9.9713e-01, -1.0381e+00,  1.7127e+00,
         -1.2596e+00, -1.5812e+00,  1.3543e+00,  5.3371e-02, -1.8224e+00,
          6.9716e-01, -2.6272e+00, -1.0479e+00, -1.1852e-01, -8.6008e-01,
          6.5209e-01,  2.1872e-01, -7.5064e-01,  9.3615e-01,  6.7306e-01,
         -3.0481e-01, -3.4947e-01,  4.8286e-01, -1.0821e+00, -1.0925e+00,
          9.9165e-01,  7.0058e-01, -1.2617e+00, -1.8745e-01, -1.5319e+00,
         -1.6955e+00, -9.8588e-01],
        [ 7.4179e-02, -8.2085e-02,  9.2270e-01,  5.0591e-01, -7.6793e-01,
         -1.0105e+00, -1.0996e+00, -1.5324e+00,  2.4188e-01, -1.5376e+00,
         -1.1716e+00, -7.7970e-02,  5.4256e-01, -1.3237e+00,  2.4956e-02,
          7.0391e-01,  1.2843e+00, -1.1843e+00, -2.1704e+00, -1.2853e-01,
          6.2581e-01, -1.7250e+00,  4.4572e-01,  3.4717e-01, -4.1957e-01,
          8.1139e-01,  1.2891e+00,  1.1999e+00, -8.3538e-01,  2.3266e-01,
         -5.2028e-01, -1.5630e+00],
        [ 2.8628e-01, -5.3381e-01, -6.7844e-01,  1.7998e-01, -5.3622e-01,
          5.2698e-01, -9.9395e-01,  4.7802e-01,  7.5599e-02, -3.4534e-01,
         -1.4937e+00, -1.5965e-01, -6.5411e-01,  7.7628e-01, -1.7339e-01,
          3.7521e-01,  1.3142e+00,  3.7047e-01, -6.9487e-01, -4.9640e-02,
         -4.8061e-01,  1.4532e+00,  4.7040e-01,  1.7986e+00, -8.0491e-01,
         -9.0887e-01, -8.8804e-01, -7.6262e-03, -1.0233e+00, -9.0074e-01,
         -1.1569e-01,  1.1247e+00],
        [ 3.2704e-01, -8.7418e-01, -1.2493e+00, -1.6587e+00,  6.3281e-01,
         -1.7288e-01,  1.1940e+00,  1.1771e+00,  1.0936e+00,  4.4623e-01,
          7.7478e-01,  5.2039e-01, -7.2558e-01, -2.5177e-01,  3.1239e+00,
          6.8111e-01, -1.4393e-02,  6.1146e-01,  1.2133e+00,  1.5042e+00,
         -5.6044e-02,  3.9605e-02, -2.2527e-01,  9.5506e-01,  5.9997e-01,
          1.0474e+00, -3.3074e-01, -1.6167e+00, -1.7188e-01, -9.1274e-01,
         -5.8712e-01,  8.4257e-01],
        [-6.9728e-01, -3.0331e-01, -1.2737e+00,  9.2360e-01,  1.9345e+00,
          5.8325e-01,  3.1974e-01, -1.4061e+00, -1.2568e-01, -5.0556e-01,
         -8.2854e-01, -9.0215e-02, -8.9310e-01, -3.4461e-01, -2.0775e+00,
          1.3290e+00,  9.6795e-01,  2.1496e-01,  4.7090e-01, -2.5854e-02,
         -2.1863e-01, -5.2026e-01, -3.5523e-01,  4.8210e-01,  2.1512e-01,
          6.5544e-01, -1.4861e-02, -4.4536e-01, -3.0689e-01, -1.7062e-01,
          7.8332e-01, -1.0047e-01],
        [ 1.4745e+00,  3.9137e-01, -3.4624e-01, -1.3192e+00, -2.4025e+00,
          2.3949e-01, -3.8791e-01,  9.6829e-01,  2.6231e-01, -1.3133e+00,
         -1.6969e-01,  2.0530e+00,  2.4439e-01, -1.1538e+00,  7.6357e-01,
         -2.5050e+00, -4.1001e-04,  1.1732e-02, -1.4663e-01, -5.0031e-01,
         -1.1323e-01,  1.2608e+00,  1.9990e-01, -7.6229e-01,  1.1655e+00,
          3.8639e-01, -2.3142e+00, -6.9722e-01,  9.1333e-01,  1.6692e+00,
          6.3531e-01, -4.6358e-01],
        [ 8.0159e-01, -2.4146e+00,  4.9209e-01,  2.7041e-01,  3.1006e-01,
          2.6563e-01, -1.3647e+00, -4.2824e-01, -1.7522e+00, -9.2518e-01,
         -1.5040e+00, -2.0989e-01,  6.2415e-01, -6.1290e-01, -1.3802e-01,
          1.2357e+00, -8.9699e-01,  8.3060e-01, -1.0628e+00, -1.3372e+00,
         -8.2882e-01,  2.0271e-01, -3.5794e-01,  1.7634e-01,  1.4421e+00,
          4.5853e-01, -2.7542e-01,  8.2129e-01,  5.1834e-01,  8.9840e-01,
          1.6562e+00, -1.5662e+00],
        [ 1.2844e+00,  1.4641e+00, -7.4271e-01,  8.6486e-01,  1.3404e+00,
          7.6486e-01,  7.6703e-01, -1.6442e+00,  1.5979e+00,  5.7554e-01,
         -1.0768e+00,  1.0046e-01, -6.7678e-01,  5.3773e-02,  1.0438e+00,
          5.3739e-02,  9.4169e-01, -5.2135e-01,  8.7623e-01, -1.7563e+00,
         -3.5919e-02,  9.3535e-01,  2.9130e-01, -2.3117e+00,  3.4974e-01,
         -4.6363e-01, -1.8238e+00, -6.6460e-01, -7.8934e-01,  1.3440e+00,
         -9.6335e-02, -3.9090e-01],
        [ 1.8692e-01, -5.7711e-01, -1.8495e+00, -8.4317e-01, -1.5151e+00,
         -8.2026e-01, -1.2459e+00,  7.1418e-01,  1.2914e+00,  2.2160e-01,
         -7.4239e-02, -7.3145e-01,  2.1921e+00, -6.4596e-01,  6.2102e-01,
          1.6956e+00, -2.6688e-01,  6.5857e-01, -1.6292e+00,  3.6993e-01,
         -1.1312e-01, -4.4303e-01,  5.3361e-01, -8.9309e-01, -8.8444e-01,
          1.1476e+00, -3.1505e+00, -2.5768e-01, -3.5901e-01, -1.1979e+00,
          2.0656e-01,  9.5525e-01],
        [-1.0475e+00, -2.7736e-01, -8.7259e-01,  1.3869e+00,  4.1166e-01,
          3.6571e-02,  5.4066e-01, -1.4388e+00,  2.1004e+00, -2.3893e+00,
          8.5997e-01, -1.2071e-01,  7.5493e-01, -1.1963e+00,  4.8194e-01,
         -1.3784e+00, -1.3189e+00,  6.1437e-02,  1.2186e+00, -1.0867e+00,
          9.5531e-01,  9.0030e-01,  2.5218e+00, -9.2371e-02, -1.3805e-02,
         -8.9152e-01, -8.5131e-01,  2.5726e-01,  4.3776e-01, -2.6525e-01,
         -5.9651e-01, -5.4064e-01]], device='cuda:0')
tensor([[-4.7502e-02,  2.1506e+00,  5.7699e-01, -6.7937e-01, -2.1408e+00,
          7.9858e-01, -9.9465e-01, -3.7083e-01, -6.7701e-01, -4.1647e-01,
          1.7829e+00, -5.4622e-01, -4.5844e-01, -1.6891e-01, -2.1959e-01,
          5.5797e-01, -1.7117e+00, -6.1116e-01, -6.1328e-01,  1.9524e+00,
         -7.8679e-01,  1.8560e+00, -8.2270e-01,  3.8330e-02, -1.5332e+00,
         -3.8487e-01, -9.2628e-01, -7.6164e-01,  1.3275e-01,  2.0108e+00,
         -1.9715e-01, -6.3519e-01],
        [ 1.1923e+00,  1.9177e+00, -1.6094e-01,  5.0049e-01,  3.0480e-01,
         -1.3124e-01,  1.5320e+00,  6.0586e-01, -1.3193e+00,  2.9125e-02,
         -5.1252e-02,  8.2134e-01, -1.3047e+00, -2.5791e-01, -8.1948e-01,
         -6.3482e-01, -9.4181e-01,  4.8764e-01, -1.1455e+00, -2.6087e-01,
         -8.2143e-02,  3.6991e-01,  4.3487e-01, -1.8942e-01, -1.6663e-02,
         -1.5981e+00,  6.4219e-01, -1.1030e-01,  2.6027e-01, -1.7303e+00,
          1.7968e+00, -8.3068e-01],
        [-9.1524e-02, -7.4385e-01,  2.1402e-01,  3.2143e-01,  1.4033e+00,
         -1.2871e+00,  5.6311e-01, -1.9321e-01, -1.1495e+00, -2.4897e-01,
         -5.5521e-01, -8.7189e-01, -1.7017e+00, -8.5281e-01,  4.8341e-01,
          5.1613e-01,  1.9580e+00,  3.2213e-01, -1.0383e+00,  6.9302e-01,
          1.4682e+00,  1.5157e-01, -6.6874e-01, -1.2979e+00, -3.4727e-01,
          6.6293e-01,  8.4517e-01,  1.0859e+00, -1.4378e+00, -5.0449e-02,
          8.0533e-01,  5.4123e-01],
        [ 1.0102e+00, -1.8047e+00, -4.0285e-01,  1.0421e+00,  5.5706e-01,
         -1.9751e-01,  1.2719e+00, -1.6420e-02, -4.5432e-01,  9.2606e-01,
          1.6630e+00,  1.9719e+00,  1.8443e+00, -3.6133e-01,  1.7688e-01,
         -9.1570e-01, -3.0571e-01,  3.8481e-01, -1.8083e-01,  4.9281e-01,
          3.1511e-02,  1.1173e+00, -8.0385e-01, -1.2115e-01, -1.4224e-01,
         -2.8312e+00, -6.3980e-01, -9.6469e-01, -1.6344e-01, -1.4142e+00,
         -2.0146e+00, -1.4263e-01],
        [ 9.0374e-01,  1.3242e+00, -4.1538e-01, -1.1029e+00, -9.1230e-01,
          1.1982e+00,  4.6819e-01, -1.4873e-01, -6.3695e-01,  6.8447e-01,
         -5.9221e-01, -1.4919e+00,  5.4089e-02, -5.1151e-01,  8.5216e-01,
         -1.5363e+00,  3.3896e-01, -3.2020e-01, -3.4427e-01, -1.2606e-01,
         -2.1147e-01,  1.0101e+00,  6.4827e-01, -5.7711e-01, -9.1422e-01,
         -2.3283e-01,  2.1084e+00, -7.6301e-01, -1.8934e-01,  4.0848e-01,
          4.2025e-01,  6.5469e-01],
        [ 8.1573e-01, -3.2206e-01, -7.6556e-01, -2.7213e-01, -1.8666e+00,
         -2.3013e-01, -1.2128e+00,  9.7716e-01,  6.7776e-01,  2.2812e+00,
          1.3683e-01,  1.9174e-01,  2.0656e-01,  6.6429e-01, -9.2745e-01,
         -6.2995e-02,  3.5285e-01, -6.8413e-01,  1.5766e-01,  1.6874e-01,
         -8.7853e-01, -1.8088e-01, -3.5707e-01,  3.5495e-02, -1.7335e+00,
         -5.5351e-01,  1.3033e-01,  1.0101e+00, -1.7519e-01, -1.0197e+00,
         -3.6633e-01, -2.2756e+00],
        [ 1.1293e+00, -1.5912e-01,  5.3685e-02, -1.5613e+00, -9.9210e-01,
          3.2084e-01, -3.3285e-01, -6.6757e-01, -6.2334e-01,  1.2754e+00,
          1.1023e+00,  6.2797e-01,  2.8893e-01, -6.0381e-01,  1.1758e+00,
         -1.3350e+00, -3.3691e-01, -1.2256e+00, -5.4760e-01,  7.0703e-01,
          6.1002e-02,  5.9746e-01,  2.7080e-01, -1.8240e-01,  1.8440e+00,
          4.7633e-01, -2.8786e-01,  1.0234e+00, -5.0715e-01, -1.7060e+00,
          2.4741e-02,  1.0654e+00],
        [-6.4499e-02,  1.1854e+00,  9.4926e-03, -3.8583e-01, -5.7902e-01,
         -1.1519e+00,  6.0315e-01, -6.3919e-01, -1.2508e+00,  1.7524e+00,
          2.0479e+00, -4.2917e-01,  2.0334e-01,  2.1225e+00,  1.2143e+00,
          6.7461e-01, -6.7140e-01,  9.1180e-01,  2.1224e-01,  4.2503e-01,
          1.3212e+00, -3.0386e+00,  1.1638e+00, -9.9340e-02, -7.6407e-01,
          1.7863e-01,  1.4296e-01,  4.9115e-01, -9.8230e-01, -1.5414e+00,
         -4.8665e-01,  1.0405e+00],
        [-1.2381e+00,  1.3239e+00,  7.8696e-01,  1.3885e+00, -5.7771e-01,
          2.6207e+00,  2.7847e+00,  4.4336e-01,  1.3681e-01,  1.2549e+00,
          5.0674e-01,  4.6650e-01,  1.3740e+00,  4.4944e-01,  4.2905e-01,
          1.2222e-02,  3.6136e-02,  1.3430e+00, -2.8583e-01,  3.0415e-01,
         -6.4379e-01, -1.4904e+00, -2.0704e+00,  1.9021e+00,  6.7803e-01,
          8.4581e-01, -1.0713e+00,  3.6407e-01, -2.0709e+00,  1.2669e+00,
         -2.3911e-01,  1.3868e+00],
        [-6.9347e-01,  1.8517e+00, -7.8533e-01,  1.0304e+00,  9.8067e-02,
         -2.8431e-01,  2.0647e-02,  9.2306e-01, -1.7976e+00,  8.5157e-01,
          2.0741e+00,  9.7836e-02,  7.3197e-01,  2.0654e+00, -8.1915e-01,
         -1.5080e+00, -3.5963e-01,  8.3318e-01,  1.7826e-01,  9.3485e-01,
         -5.2548e-01,  5.4806e-01,  1.2655e-01, -4.4764e-01, -5.7798e-02,
          1.4045e+00,  8.1543e-01,  1.5427e+00,  1.9568e-01,  1.9562e-01,
         -1.3998e+00,  2.2736e+00],
        [ 5.1357e-01, -1.4518e+00,  1.2382e+00, -1.7910e+00,  5.4028e-01,
          1.0527e+00,  1.4685e-01,  2.2346e-01,  1.3741e+00,  3.9053e-01,
          4.7019e-01,  2.9111e-01,  1.0342e+00,  4.9084e-01,  4.8652e-01,
         -1.0443e+00,  7.7669e-01,  1.3825e+00,  2.9682e-01, -1.7027e-01,
         -5.1343e-01, -3.4495e-01,  3.3754e-01, -6.0154e-01,  3.6973e-01,
         -9.6730e-01, -9.4343e-01,  1.8929e+00, -5.2523e-01,  3.2207e-01,
         -3.4371e+00, -8.1207e-02],
        [-1.0204e-03, -2.0576e+00,  1.7765e+00,  2.4332e-01,  1.6416e-01,
          1.1633e+00,  4.6717e-02,  8.4952e-01, -1.2547e+00, -1.0977e+00,
          9.4899e-01, -3.6958e-01, -6.8953e-01, -5.6470e-01, -9.1109e-01,
          7.7915e-01,  2.8276e-01, -9.4422e-01,  3.2079e-01, -8.3447e-01,
         -1.1659e-01, -3.7748e-01,  7.5096e-01,  4.4686e-01, -7.8900e-01,
         -7.0900e-01,  1.4908e-01, -1.5635e-01,  3.7724e-01,  2.2817e-01,
          2.6704e+00, -1.0969e-01],
        [ 3.8344e-01,  3.8213e-01,  8.1797e-01, -5.4079e-01, -4.4356e-01,
          3.9687e-01,  5.8214e-01, -8.0866e-01,  3.5462e-01, -3.7337e-01,
          6.7954e-01,  7.0446e-01, -1.3503e-01,  1.5824e-01, -3.3247e-01,
         -8.6981e-01,  2.4810e-01, -1.7309e+00,  1.1310e+00, -1.0218e-01,
          1.8497e-01, -1.8463e-01,  2.4178e-01,  7.4388e-01,  1.0260e+00,
         -1.1208e-02, -4.8741e-01, -2.3479e+00,  2.7127e-01,  4.1634e-01,
         -1.0165e+00,  4.5191e-01],
        [-1.3013e+00,  1.2820e+00,  8.1265e-01, -1.2142e+00, -1.7826e+00,
         -6.0991e-01, -1.3419e+00,  1.1011e+00,  1.5691e-01,  1.4316e+00,
         -2.2073e+00, -4.7555e-03,  6.0434e-01, -1.9523e+00, -3.0815e-01,
          9.7969e-01, -1.1330e+00,  1.1504e+00,  1.0643e+00,  1.6369e+00,
         -2.2837e-01,  8.4827e-01,  4.0986e-01,  9.6418e-01, -1.0377e+00,
         -1.5802e+00,  1.5753e-01,  3.7205e-01,  1.0657e+00, -2.4731e+00,
         -1.8177e+00, -4.8913e-01],
        [-6.9910e-01, -1.4492e+00,  5.1757e-01, -8.8449e-02, -1.5222e+00,
         -5.0253e-01, -8.6559e-02, -7.7749e-01, -3.0417e-01,  2.5834e+00,
         -4.3797e-01, -1.9756e+00,  2.1820e-02, -1.8057e-01, -1.5908e+00,
         -1.5305e+00,  6.7920e-01, -1.0964e+00,  9.8998e-01,  6.4268e-01,
          1.4226e-01,  1.3029e+00,  2.7606e-01, -5.5365e-02, -2.0058e+00,
         -1.7455e+00,  2.0354e-01,  8.0559e-01,  9.1736e-01,  6.8210e-02,
          1.0299e+00, -7.7941e-01],
        [ 1.2022e+00,  1.1196e+00,  7.7747e-01,  5.7699e-01,  1.4459e+00,
         -8.6020e-01, -7.7668e-01,  6.7998e-01, -1.1163e-01, -1.4049e+00,
          4.3861e-02, -4.8738e-01,  4.6358e-01, -1.7933e+00,  4.1932e-01,
          2.2330e-01, -7.1857e-01,  1.8815e+00, -5.8392e-01, -1.3839e+00,
         -1.9049e+00,  8.9308e-01,  3.9286e-02, -1.4291e+00,  1.4157e+00,
         -1.1811e+00, -1.6975e-01,  1.1653e+00, -1.8294e+00, -1.3994e+00,
         -1.6360e+00,  8.8845e-01],
        [ 7.9056e-01, -1.1917e-01,  1.1791e+00,  9.4823e-01, -6.6023e-01,
          2.8462e+00, -8.2140e-01, -1.7760e+00, -3.8153e-01,  2.5004e-01,
          5.4604e-01,  1.1637e+00,  8.0933e-01,  1.0169e+00,  1.0687e+00,
          1.1994e+00, -2.4900e-01, -6.1916e-01, -9.0255e-01, -1.3025e+00,
         -4.2958e-01,  1.4365e+00, -9.1577e-01,  1.6238e+00, -4.9619e-01,
          4.1917e-01, -1.0368e+00, -1.2427e+00,  9.4436e-01,  9.7513e-01,
          3.0105e-01, -6.3396e-01]], device='cuda:0')
tensor([[ 0.9815,  0.4126, -0.5491, -0.8618,  0.6663, -2.3278, -1.3565,  1.0209,
         -0.3732,  0.5807,  0.1573, -0.2163, -1.4250, -0.4292, -0.4312, -0.4476,
          0.5393, -0.6065,  1.0439,  0.3742,  1.3194, -0.9354, -0.1253, -0.2111,
          0.2107,  1.3116, -0.5381, -0.2100,  0.7453,  1.4109, -0.1850, -0.5817],
        [-0.6691, -0.4446, -0.4618, -0.0545,  0.8355, -0.6378,  0.6156,  0.5051,
          0.2926, -0.2332,  0.5014,  1.3251,  0.5344, -1.0963, -0.6451,  1.4914,
          0.9295, -1.4295,  0.6246, -0.5960, -0.8809,  1.2154, -0.1274, -0.1373,
         -0.7758, -0.5318,  0.6746,  2.3195, -0.6167,  0.5859, -0.9207,  0.5885],
        [-0.0353, -1.3198,  0.2604,  0.7618,  1.5963, -1.0852, -0.0295,  1.1985,
          0.4406, -0.0713, -0.9276,  0.1870,  0.4409, -0.7045,  0.7740, -1.1220,
         -0.2070, -2.0094,  1.5114,  0.7691,  0.5948,  1.2519, -0.9497,  0.3559,
         -0.4348, -1.6836, -0.4621,  2.1839,  0.2263, -0.8431,  0.2448,  0.0718],
        [ 0.0910,  0.1399,  0.1783,  1.3334, -1.7019, -0.4737,  0.5877, -0.2750,
         -2.0250,  0.4997, -1.6884,  2.5300, -0.4395, -0.3776, -0.6039, -1.8196,
          1.8427, -2.9070,  0.5602, -0.6167, -1.7666, -0.0588, -0.0735, -0.4319,
         -1.4251,  1.5249, -1.2742, -0.1890, -1.3708,  1.4986, -0.1207, -0.0979],
        [ 1.8791,  0.7384,  1.1093, -0.2685,  0.9900,  0.9903,  0.3207,  0.4911,
         -0.1730,  0.6396,  1.6959, -0.6930,  0.2680,  0.5643,  0.1987, -0.3101,
          0.4899,  1.1254, -0.5318, -1.0272,  0.8393, -0.8985,  0.5521,  0.1620,
          0.9692, -2.1346,  0.0212,  0.2573, -0.0569,  0.7153, -0.1699,  0.2781],
        [-0.3748, -0.3975,  0.3219, -0.3305, -1.1244,  1.0322,  0.1210, -0.5334,
         -1.2610, -1.0939,  1.1929, -0.3726,  0.1891,  0.1158, -0.4147, -0.6377,
         -0.3116, -0.1623,  0.5967,  0.3403, -1.0978,  2.1753, -1.2818, -0.4514,
          1.0464,  0.7701, -0.2609,  1.5173,  0.0812, -2.3074,  0.3354, -1.0322],
        [ 0.4291, -1.1880,  1.6692,  1.0388,  0.0955,  0.9306, -1.2057, -0.1607,
         -0.3748,  1.3120, -0.9842,  1.6945,  1.2900, -0.8361, -0.3904,  0.1439,
         -2.7982,  0.0260,  0.6616,  1.2624,  0.5815, -0.0991, -0.3157,  0.2163,
         -0.4406,  0.6966,  1.6150,  0.5006, -0.5867, -0.2580,  0.3556, -0.7349],
        [ 1.0725, -1.9246, -1.5331, -0.4652,  1.1205,  0.7913, -0.8095,  1.2446,
         -1.0103, -0.4944,  0.1638, -0.4226,  1.4057,  0.5946,  0.3183, -0.6657,
         -0.8228,  0.3992, -0.5406, -0.8189,  0.1067, -1.6448,  0.1569,  0.5710,
         -2.4619,  0.4349, -0.0045,  0.0231,  0.1211, -1.6997,  1.1727,  0.3239],
        [ 0.8826,  1.0900, -0.4305,  2.4615,  0.7620,  0.2941,  1.9150,  0.4738,
          2.0429, -0.3205,  1.9259, -0.8025,  0.0848, -0.6392, -1.2167, -0.1814,
         -1.1930,  0.0614,  0.1215, -0.0592,  1.2386, -1.6682,  0.1435,  0.3967,
          0.8020, -0.9408, -1.2517,  0.4114,  0.1087, -0.0364, -0.2856,  0.3135],
        [-0.9755,  1.5696,  1.6045,  2.7738, -0.8547, -0.6074, -2.3534,  1.2386,
         -0.0997,  0.1968,  0.3577, -1.9094, -0.4646, -0.7605,  1.2093,  0.4692,
         -1.7725, -0.0042, -3.0020, -0.6216,  1.3676,  1.1112, -1.2424,  1.4343,
         -1.4307,  1.2287,  1.0058,  0.0573, -0.9600, -0.8167, -0.2534,  0.0625],
        [-0.7781, -0.3575,  0.4913,  0.2805, -0.9075,  0.0754,  0.0301, -0.6564,
          1.3323, -1.5858,  0.2933,  0.5158, -0.4304, -0.3302, -2.0078,  0.6077,
         -0.0601, -1.1250,  0.8143, -0.9499,  0.2956, -0.8819, -1.3609, -0.5215,
          0.4715,  0.0938,  0.7025, -1.0182, -1.4876,  0.0096,  1.6933,  1.2487],
        [ 0.5176, -1.5821,  0.3121, -0.9758,  0.5865,  0.8997, -0.3054, -0.2695,
          0.0457,  1.6810,  0.5829,  1.5239,  0.9560,  0.0723,  0.3036, -0.4916,
         -0.2009, -0.8033,  0.7058,  3.0374,  0.7144, -0.4727,  0.6649,  1.7635,
          1.0028, -0.6637,  0.9180,  0.8881, -1.0821, -1.6250,  0.9032, -0.1153],
        [-0.8317,  0.8345, -0.1943,  1.3418, -1.6056,  1.1421,  1.1083,  0.3089,
          0.8374, -0.0974,  0.8691,  0.4644,  0.7897,  0.2093, -0.3862, -0.2758,
          1.3435,  2.3340,  1.0829,  0.8429, -0.3399,  0.9945,  0.0702,  0.3408,
         -0.1081, -0.4512,  0.3861,  0.8314,  0.3641, -0.8785, -1.8547,  0.7868],
        [-1.3841, -0.5397,  0.2975,  0.3885, -0.5718,  0.1802,  0.5446,  0.4275,
         -0.5934,  0.3580, -2.2541, -1.8745,  1.3165,  0.2059, -1.2583, -0.4887,
          0.8960, -1.4209,  0.9331,  0.9990, -0.9384, -0.1708, -0.2904,  1.7534,
          1.2646, -0.6574, -0.6791, -0.2238,  1.0592,  0.3594,  1.0892,  0.0347],
        [ 0.1361,  0.5387,  1.5038, -0.9985, -0.8799, -0.7301, -0.0534,  0.1476,
          0.0524,  1.1190,  0.3730, -1.2721, -0.8245,  0.4324,  0.1496,  1.3266,
          2.0203,  0.0730,  0.8358,  0.5542, -1.0448, -0.1103, -0.3637,  1.4598,
          0.4673, -0.1949,  1.5144,  0.3311,  0.9007, -0.0508,  1.5378, -0.8455],
        [-0.8665, -1.3789, -0.5212,  1.2284, -0.6450, -0.8410, -0.7005, -0.2869,
          1.4662, -0.1073, -0.1035, -0.5337,  0.0354,  0.0716, -0.9725, -0.8081,
         -1.2080, -0.0477, -0.3377, -1.0601, -1.0296, -0.5188, -1.1771,  0.1923,
         -1.1963,  0.6675,  0.9304, -0.4209,  0.2627,  1.7768,  0.4142,  1.1616],
        [-0.3613,  0.8579,  0.0290,  0.6732, -0.9545, -0.6058, -0.6787, -0.3078,
          0.9454,  0.9339, -1.2355, -0.8495,  0.6173, -0.0171,  0.1669, -0.8481,
          0.6323,  1.4561,  0.6490, -0.6201, -0.8604, -0.8127, -0.5342, -1.6047,
         -2.1389, -1.1352, -0.0594, -0.4345,  0.4829,  0.0034,  0.3608,  0.3239]],
       device='cuda:0')
tensor([[ 3.7423e-01,  7.5179e-01, -7.9079e-01,  6.3007e-01,  6.8009e-01,
         -7.3095e-01,  6.1415e-01,  9.2823e-01,  2.1705e-01, -2.2479e-01,
          6.1930e-01, -6.8339e-01, -1.5306e+00,  2.5310e-01, -4.7473e-01,
         -1.9055e+00,  1.0684e+00, -3.9905e-01, -5.0807e-01,  1.2402e-01,
         -4.0260e-01, -1.9018e+00, -5.3028e-01,  4.2951e-01, -1.3927e+00,
         -7.1379e-01, -1.3082e-01,  1.0217e+00,  2.4566e-02, -1.9452e+00,
         -2.3462e-01, -1.0897e+00],
        [ 2.1348e+00,  1.0215e+00,  1.5609e+00, -7.3843e-01, -5.3370e-01,
          1.1521e+00,  6.2510e-01, -5.4325e-01, -9.1637e-01, -2.5545e+00,
          2.8319e+00, -1.1330e-01,  1.5885e-01, -1.2824e+00, -7.3832e-02,
          2.1406e+00, -3.0503e-01, -9.0913e-01,  5.8984e-01,  6.5156e-01,
          1.1272e-01, -2.3403e+00,  1.9114e+00,  2.3363e+00,  2.7211e-01,
          1.7193e+00, -1.3742e+00,  8.7763e-01,  1.6636e-01,  1.0130e+00,
          1.5481e+00,  9.4443e-01],
        [ 1.1430e+00, -1.7233e+00, -1.7880e-01,  1.0955e+00,  1.6634e+00,
          1.4451e+00, -5.9126e-01,  1.4420e+00,  8.6998e-01, -1.5779e+00,
         -5.3295e-01, -2.1840e-01, -1.6576e+00,  9.3505e-01,  5.2183e-01,
         -1.0685e+00,  1.8437e+00,  1.0614e+00, -3.7997e-01, -2.8514e-01,
         -9.4923e-02,  9.5158e-01,  1.2216e+00, -9.5942e-01,  9.2959e-01,
         -9.6564e-01,  2.7280e-01,  6.1317e-01,  9.4565e-01,  1.7278e+00,
          4.0738e-01,  6.8947e-01],
        [-5.8173e-01,  1.0611e+00,  7.2242e-01, -1.3261e-01,  4.8184e-01,
         -7.7354e-01,  1.3175e-01,  2.2664e+00,  2.4831e-01, -2.1053e+00,
          1.7850e-01, -1.3028e+00, -5.6399e-01, -2.7079e-01,  2.4384e+00,
         -1.4462e+00, -9.5288e-01, -1.4006e-01, -2.0161e+00,  6.0726e-01,
          2.4623e-01,  7.7506e-01,  9.9833e-03,  3.7681e-01,  2.3700e-01,
         -7.5709e-01, -8.1071e-01, -6.2108e-01,  1.3359e-01, -2.3951e+00,
          1.5687e+00,  1.3983e+00],
        [ 4.2508e-01, -2.3088e-01,  4.3033e-01, -3.7757e-01, -1.2706e+00,
         -2.3109e-01, -2.9570e+00,  1.7206e+00,  5.7511e-01,  3.2221e-02,
         -8.4209e-02, -4.2648e-01,  9.2475e-02,  8.9205e-01,  8.2687e-01,
          8.6655e-02,  1.5094e+00, -3.8898e-01,  2.0604e-01, -2.2013e+00,
         -1.8618e-01,  3.2130e-02,  3.7617e-01, -2.3731e-01,  5.6577e-01,
          4.8285e-01, -8.7556e-01,  1.9708e+00,  1.2741e-01,  2.6302e-01,
          6.4230e-01,  1.5960e+00],
        [-4.1879e-01,  2.0879e-01, -8.8192e-01,  7.6684e-01, -8.3222e-01,
         -1.0156e+00, -1.6146e+00,  4.9337e-01, -8.6739e-01, -1.4349e+00,
          9.9444e-02, -7.9530e-01,  2.1515e-01, -6.9854e-01, -7.5916e-01,
         -3.2961e-01,  1.0049e+00,  1.0382e+00, -4.8092e-01, -1.1024e+00,
          1.0801e+00,  1.3712e+00, -4.6191e-01, -5.7042e-02, -1.7740e+00,
         -1.9193e+00, -6.7065e-01,  1.1945e+00,  9.7354e-01,  1.2336e+00,
         -2.8155e-01, -6.6626e-01],
        [-8.4167e-01,  9.2951e-02,  6.1208e-02, -5.4581e-01,  1.0118e+00,
         -1.1889e+00,  1.1946e+00,  1.1747e+00, -9.7506e-01,  7.3441e-02,
         -1.3718e+00,  1.3455e+00, -1.3681e+00,  1.1058e+00, -4.7576e-01,
          1.5109e+00, -1.8740e-01, -1.4064e-01,  6.3601e-01, -1.2159e+00,
         -1.2570e+00, -5.0139e-01, -6.7168e-02,  1.1635e-01,  5.5989e-01,
         -6.1242e-01,  1.8669e+00,  7.0911e-01,  6.4204e-01, -1.7299e-03,
         -1.2366e+00, -8.2756e-01],
        [-4.8793e-01, -2.1111e-01,  4.1947e-01, -8.0025e-01,  1.4627e+00,
         -1.4456e-01,  1.5999e+00, -8.2548e-02, -5.0257e-02,  5.1279e-01,
          5.8085e-01, -5.2442e-01,  4.1093e-02, -9.8018e-01, -1.8329e+00,
         -1.1356e+00, -7.2298e-01, -3.7415e-01, -7.7310e-01, -7.5904e-01,
         -9.7597e-01, -1.3675e+00,  1.6921e-01,  7.2616e-01,  2.1215e-01,
          4.3615e-01,  8.8741e-01, -4.5968e-01, -6.9789e-01,  1.1180e+00,
          4.8144e-01, -1.0490e+00],
        [ 3.8099e-01,  1.4571e+00, -8.8905e-01,  5.3296e-01, -6.6446e-01,
         -6.2899e-01, -1.7802e+00, -5.0672e-01,  1.3753e+00, -1.1008e+00,
         -3.0050e+00, -1.6608e-01,  4.7124e-01,  5.8157e-01, -1.0387e+00,
          2.7602e-01, -6.3820e-01, -1.3896e+00, -1.7688e+00, -3.3906e-01,
          1.2087e-01,  4.0973e-01, -1.0256e+00,  8.1433e-01, -9.5423e-02,
         -2.6522e+00,  8.2769e-01, -5.5183e-01, -8.4175e-01,  6.8820e-01,
          5.8849e-01, -2.0107e+00],
        [ 7.6220e-01,  5.8050e-01, -1.2579e+00,  4.1801e-01,  1.0019e-02,
          3.2389e-02, -2.5104e-01,  2.0488e+00, -7.8997e-01,  1.5857e+00,
         -6.6170e-01,  6.7773e-01, -2.9461e-01, -7.3161e-01,  7.8465e-01,
          1.2460e+00, -1.8012e-01, -3.5724e-01,  1.5640e-01,  9.8817e-01,
          1.3435e+00,  5.3963e-01, -7.6136e-01,  7.3542e-01,  8.5917e-01,
          3.0715e-01, -1.0382e+00, -4.0424e-01,  3.4618e-01,  7.5587e-01,
         -8.8651e-01, -2.2644e-01],
        [ 5.3684e-01, -1.7274e+00, -1.8671e+00,  1.1676e-01,  5.6195e-02,
          3.5440e-01, -2.3240e+00, -1.1348e+00, -5.6857e-01,  2.4409e-01,
          2.4486e-01,  3.7787e-01,  1.0725e+00,  8.3212e-01,  7.3311e-01,
          3.7890e-01, -9.0492e-01,  3.1470e-01, -2.5077e-01, -7.1203e-01,
         -1.4000e-01, -1.3384e+00, -1.5604e-01, -1.0424e+00,  2.5656e-01,
         -1.0779e+00,  2.0205e+00,  1.7579e+00,  7.5027e-01, -9.6395e-01,
         -1.6474e+00, -1.6991e+00],
        [ 9.5559e-01, -4.7613e-01, -7.9259e-01, -7.7156e-01,  1.3166e+00,
         -2.7592e-02,  2.5873e-01, -1.2166e+00,  7.3838e-02,  3.9267e-01,
          9.5234e-01,  9.3763e-01,  4.5226e-01,  5.8501e-01,  2.1200e-01,
          5.8508e-01, -1.0866e+00,  1.3223e+00, -2.4057e+00, -2.1528e-01,
         -4.9748e-01, -7.2808e-01, -1.2922e+00,  2.3463e+00,  1.3067e+00,
         -4.7788e-01, -1.8768e-01, -8.5173e-01,  1.9052e-01,  6.2927e-01,
         -3.1146e-01, -4.2273e-01],
        [ 7.0193e-01,  1.3574e-01, -1.7188e+00,  4.3607e-01,  8.9086e-01,
          3.4421e-01, -9.3914e-01,  1.0354e+00, -8.2867e-01,  2.2081e+00,
          2.9128e-01, -9.9602e-01, -1.3751e+00, -4.9610e-01,  6.4856e-01,
         -3.6367e-01,  1.2862e+00, -8.0308e-01,  3.3945e-01, -2.6917e+00,
          4.9650e-01, -4.1954e-01,  6.9411e-03, -3.5306e-01,  6.3078e-02,
         -6.7645e-01,  3.3762e-01, -5.1415e-01, -6.3818e-01,  1.8168e-01,
          7.2614e-01,  2.6445e-01],
        [-2.3822e-01,  3.6337e-01,  1.9013e-01,  8.4431e-02, -2.9411e-01,
          5.1652e-01, -9.0134e-01,  1.4109e+00,  1.2650e-01, -1.2405e+00,
          1.6322e-01,  1.4785e+00, -1.5733e+00,  3.7251e-01,  2.5417e-01,
          6.6575e-01,  1.0138e+00, -1.7116e-01, -6.8642e-01,  2.0417e-01,
         -6.3311e-01, -8.1546e-01,  2.9049e-02, -6.7975e-01,  3.9131e-01,
          6.8663e-01,  1.0253e+00,  4.6712e-02,  1.4325e-01,  5.6525e-01,
         -1.8023e+00, -2.2900e+00],
        [ 1.6360e+00, -3.2303e-01,  6.3790e-01, -1.6843e-01, -4.4382e-01,
         -6.5325e-01, -2.6222e-01,  2.5803e+00,  6.1395e-01, -8.5497e-01,
         -1.7445e+00,  1.2415e+00,  3.0365e-01, -1.6076e-01, -4.9457e-01,
          8.0212e-01,  8.6359e-01,  2.7017e-02,  3.4965e-01, -1.1274e-01,
          5.8388e-01,  4.9830e-01, -7.5388e-01,  1.0916e+00, -5.8822e-02,
         -7.8878e-01,  2.5720e-01,  1.8172e-01, -1.8181e-01, -1.4777e+00,
         -6.7854e-01,  2.5160e+00],
        [ 9.7442e-01, -1.4482e+00,  1.8440e-01, -8.8983e-01, -1.2265e+00,
         -7.2398e-01, -1.6357e+00, -4.1480e-01,  1.3487e+00, -7.0071e-01,
          4.6183e-01,  4.7331e-02,  1.5206e+00,  1.0463e-01, -9.1941e-01,
          1.1877e-01, -8.1122e-02, -3.4596e-01,  2.5737e-02,  6.6099e-02,
          1.1059e-01, -3.9702e-01, -2.8996e-01,  1.9166e+00,  2.5408e-01,
          1.9030e-01,  9.4220e-01, -7.9455e-01,  2.0116e-02,  9.1827e-01,
          1.5301e+00, -3.9057e-01],
        [ 1.1203e+00,  3.7551e-01,  7.0316e-01, -9.8433e-01, -3.6847e-01,
         -6.2050e-01,  9.8533e-01, -4.7425e-01, -3.1982e-01,  2.4777e-01,
         -6.8521e-01, -1.0339e+00, -4.4133e-01,  9.2041e-01, -1.0122e+00,
         -2.6507e-01,  1.8895e+00, -2.0307e-01, -3.8494e-01, -2.7175e+00,
         -1.4103e+00,  8.0098e-01, -1.3558e-01, -1.1294e+00, -1.0710e-01,
         -5.7748e-01, -7.0655e-01,  9.6789e-01, -1.0958e+00, -7.6655e-01,
          2.4956e+00, -1.0746e+00]], device='cuda:0')
tensor([[-7.9428e-01, -8.6539e-01,  1.5212e+00,  7.6319e-01, -5.8536e-01,
          1.3198e+00, -1.4040e-01, -6.2851e-01, -1.2404e-01, -4.0588e-01,
         -7.0684e-01,  7.5882e-01,  2.8002e-01, -2.7358e-01,  6.6336e-02,
          8.4125e-01, -2.1697e+00, -2.5310e-01, -6.2364e-01,  1.6514e+00,
         -9.9289e-01,  1.7257e+00,  1.7990e+00, -6.0173e-01, -8.1912e-02,
         -1.3738e+00, -1.9681e-02, -2.2093e-01,  1.1385e+00,  7.8429e-01,
          3.4869e-02, -1.0283e+00],
        [ 8.4318e-01, -1.3427e+00, -4.0086e-01, -6.2010e-01,  2.4956e-01,
          3.2094e-01, -4.7486e-01,  5.8870e-02,  3.9391e-02,  1.2092e+00,
         -2.9391e-01, -1.5695e+00,  1.9223e+00, -1.2683e+00, -5.7772e-01,
          1.8458e-01, -2.6593e+00,  3.8871e-01,  1.9976e-01, -2.4041e-01,
         -3.5985e-01,  3.9197e-01,  7.3740e-01,  6.4994e-01,  9.1156e-01,
         -4.5379e-01,  2.7960e-02,  1.7264e-01,  6.3945e-02, -5.8913e-01,
          1.5785e+00,  1.1242e+00],
        [ 8.9507e-01, -1.4190e+00, -4.9826e-01, -6.8357e-01, -7.5219e-01,
         -6.6250e-01, -2.6402e+00,  7.6700e-01, -2.5429e-02,  3.9447e-01,
          1.7110e+00,  1.0092e+00,  8.1712e-01, -1.1997e+00, -9.4920e-01,
          1.0288e+00, -1.6324e+00,  1.4353e+00, -1.1087e+00,  7.4312e-01,
          2.0381e+00, -8.6374e-01, -8.9949e-01, -1.5528e+00, -5.5956e-01,
          7.2913e-02, -7.6648e-01,  1.1611e+00, -1.0820e+00, -6.7029e-01,
         -5.0275e-01, -1.4116e+00],
        [-1.1126e+00,  1.2438e+00,  4.5977e-01,  6.9814e-02,  1.0082e-01,
          1.0215e+00, -3.5003e-01, -1.2268e+00,  8.9467e-01,  1.7775e+00,
          1.4419e-01,  9.6769e-01, -3.0331e+00, -1.0253e+00,  1.1040e+00,
         -1.1631e+00,  1.0391e+00, -4.4584e-01,  9.6636e-01, -1.5543e+00,
          1.0955e+00,  8.8510e-01, -5.3027e-01, -3.3814e-01,  1.2146e+00,
          7.7719e-01,  4.4776e-01,  1.7761e+00, -5.9747e-01, -6.2744e-01,
          1.3902e+00,  7.2307e-01],
        [ 1.2697e+00, -1.0507e+00, -1.3081e-01,  2.0925e+00, -2.1880e+00,
         -9.0909e-01,  3.2073e-01,  5.4556e-01, -1.0289e+00,  1.0028e+00,
          6.7333e-01,  4.3888e-01, -2.4989e-01,  2.3387e-01,  4.6418e-01,
         -7.1595e-01, -1.1334e-01,  9.3856e-02, -1.3219e+00, -6.8647e-01,
          2.1322e-02,  1.2770e+00,  3.8109e-01,  6.3886e-01, -1.1135e+00,
         -9.1270e-01,  7.4029e-01,  2.9537e-02, -1.2665e+00, -3.2418e-01,
         -1.2745e+00,  9.2247e-01],
        [-9.3931e-01, -2.7883e+00,  1.5163e+00,  1.7904e+00,  1.3119e+00,
         -1.4469e+00, -2.2092e-01, -3.2907e-01, -4.8110e-01, -5.7752e-01,
          1.1983e+00, -6.0387e-01,  2.0206e+00, -3.3685e-01,  5.4963e-01,
          6.3475e-01,  4.7747e-01, -3.3394e-01, -1.1558e-01,  1.3174e+00,
          5.2402e-01, -2.3160e-01, -9.7929e-01, -3.7528e-01, -7.1497e-01,
         -5.2475e-01, -6.1379e-01,  7.0927e-01,  9.5878e-01, -4.3029e-01,
          1.5309e+00,  2.0127e-01],
        [-1.0444e+00,  7.3729e-01, -2.0128e+00, -4.9700e-01,  9.1876e-01,
         -4.9052e-01,  1.8108e+00,  1.6256e+00,  7.4749e-01, -1.3749e+00,
          3.2724e-01, -9.0449e-01,  6.5001e-01, -5.3275e-01, -9.6934e-01,
         -4.5086e-01, -5.8621e-01,  1.4551e+00, -3.5859e-01,  1.5880e-01,
          4.1353e-01,  1.5171e+00,  9.2618e-01,  2.2269e-02, -9.4969e-01,
          1.0843e+00,  1.5590e-01, -6.4325e-01,  6.1199e-01, -8.2250e-01,
          7.6951e-01, -3.8590e-02],
        [ 2.5817e-01, -8.7318e-01, -1.0833e+00, -8.2297e-01, -5.0053e-01,
         -3.6158e-01,  4.0474e-01,  2.1052e+00, -1.1441e-01, -3.2993e-01,
          8.2431e-01, -1.2671e+00, -3.1144e-02,  1.3620e+00,  9.0634e-01,
          8.8664e-01,  1.5416e+00, -8.0538e-01, -3.3095e-01, -6.3647e-01,
         -2.0156e-01,  3.3486e-01, -8.4070e-01,  8.0455e-01,  2.5774e-01,
          2.3128e-01,  2.2997e+00, -1.0820e+00, -9.8378e-01, -4.6406e-02,
         -1.4293e+00,  3.4909e-01],
        [-4.2272e-01, -9.3281e-01, -4.4211e-01,  7.5937e-01,  9.5692e-01,
         -6.4603e-01,  4.4020e-01,  8.6844e-02, -6.6143e-01,  1.6607e+00,
         -2.7819e-01, -2.6465e-01,  4.1128e-01,  6.0772e-01,  8.7626e-01,
         -2.4666e+00,  1.0740e-01, -1.4464e+00, -3.9426e-02,  2.9603e-01,
         -2.5381e-01, -2.7434e-01,  2.3524e-02,  1.4506e+00,  1.0534e+00,
         -8.3197e-01,  3.4478e-01,  9.6369e-01,  1.9869e-01, -6.8513e-01,
         -4.3434e-01,  7.2718e-01],
        [-5.9164e-01, -3.9706e-01, -5.8680e-02,  4.5087e-01,  2.3815e+00,
         -2.1509e-02, -4.3101e-01,  1.5501e+00, -6.8096e-01,  1.0954e-02,
         -4.3053e-02, -7.5423e-01, -9.9807e-01,  6.9533e-01, -1.3581e+00,
         -4.1287e-01, -5.0391e-01, -8.1997e-01, -3.7880e-01,  2.9424e-01,
         -1.1458e+00,  8.2559e-02,  1.0741e+00, -2.0623e-01,  2.2538e+00,
         -2.8803e-01,  2.4598e+00, -2.7286e-01,  7.6034e-01,  7.0591e-01,
         -2.6890e-01,  5.7041e-01],
        [-8.1714e-01,  1.3799e+00,  8.9429e-01, -6.5051e-01, -1.4497e-01,
         -1.9034e-01,  4.4781e-01, -4.3521e-01, -5.5842e-01,  1.7431e-01,
          1.1661e+00, -2.3022e-01, -5.0813e-01, -2.0208e+00,  1.7356e+00,
          1.1016e-01, -1.8299e+00,  5.0079e-01,  3.3091e-01, -6.3447e-01,
         -3.2701e-01,  6.5485e-01,  9.1166e-01, -1.3726e+00, -1.0672e+00,
          7.1041e-01,  3.3593e-01,  2.8046e-01, -7.7331e-01, -1.8738e+00,
         -2.9157e-01, -1.1517e+00],
        [-1.4557e+00, -5.7732e-01, -9.6214e-01, -1.6182e+00,  7.5068e-01,
          1.3790e+00, -3.0020e-01, -2.1792e+00,  4.8559e-02,  4.2755e-01,
          2.2971e-01, -6.3397e-01, -4.6306e-01,  9.7563e-01, -8.1895e-01,
          5.2153e-01, -2.1086e-01,  1.0078e+00, -1.2526e+00,  4.9874e-01,
         -1.0858e+00, -1.1598e+00,  3.0854e-01,  1.2845e-01, -1.5760e+00,
         -1.9725e+00, -2.7680e-01, -1.0855e-01,  5.9114e-01,  6.4662e-01,
         -1.2027e+00, -1.3279e+00],
        [ 2.1440e-01, -1.3621e+00,  9.4150e-01, -5.4736e-01, -9.2086e-01,
         -6.9607e-02,  5.4021e-01, -1.6220e-01,  5.5499e-01,  2.5826e+00,
         -4.1859e-01,  3.9593e-01, -1.9524e-01,  2.4974e+00,  1.4555e+00,
         -9.4335e-02,  5.4281e-01,  1.3650e+00,  2.9433e-01,  1.0973e+00,
          4.2259e-01, -1.7606e+00, -3.7537e-01, -9.1761e-01,  1.8287e+00,
          1.9477e+00,  5.8911e-01, -1.0824e+00,  3.1140e-02,  8.9799e-01,
         -4.6575e-01, -1.0430e+00],
        [-4.0869e-01, -2.3914e-01,  7.7843e-01,  1.3515e+00, -1.3925e-01,
          4.9968e-02, -6.4155e-02,  9.7520e-01,  9.0624e-01,  1.0325e+00,
         -1.0271e-01,  1.1841e+00,  1.8875e-01,  6.5295e-01, -1.2756e+00,
          4.8274e-01, -8.5662e-01,  3.4678e-01, -1.6291e-01, -3.9005e-01,
         -1.7943e-01,  1.2615e+00,  7.1495e-01,  9.8033e-01, -9.9311e-01,
         -4.1121e-02,  7.2184e-01, -3.2895e-01,  1.0187e+00, -1.2804e+00,
          5.6362e-01, -1.1042e+00],
        [ 3.4770e-01,  3.1130e-02,  1.0646e+00,  1.8301e-03, -1.1584e+00,
         -9.9731e-01,  7.5425e-01, -3.0917e-01, -8.9277e-01, -9.6000e-01,
          8.2862e-01,  1.4736e-02, -5.2714e-01,  2.3112e-01, -9.9150e-01,
          9.6328e-01, -2.0723e+00,  1.6905e+00,  7.9247e-01, -7.8673e-01,
         -5.2764e-01, -7.1577e-01, -6.7018e-02, -6.5779e-01,  1.7823e-01,
          8.9147e-01,  7.1500e-01,  1.8566e+00, -5.2068e-01, -1.0931e-01,
          8.9119e-01,  1.5290e+00],
        [ 4.7107e-01,  6.3586e-01, -1.3442e-02,  3.3118e-01,  1.0249e-01,
         -3.2101e-01,  7.1211e-01, -1.5007e+00, -7.3000e-01, -6.0386e-01,
         -6.6396e-01,  1.6757e-01,  1.3023e+00,  1.1240e+00, -6.4862e-01,
         -9.5537e-01, -8.0428e-01, -4.8593e-01, -1.3266e+00,  6.9651e-01,
          1.3157e+00, -7.6681e-01, -2.0820e-01, -7.8795e-01, -5.3549e-02,
         -1.0839e+00,  1.8168e-01, -3.6074e-01,  2.0690e+00, -8.9990e-02,
          1.2792e+00,  5.0253e-02],
        [ 2.0222e-01, -3.6135e-01, -8.3310e-01, -7.3367e-01, -1.6500e+00,
          1.5004e+00, -6.4231e-02,  7.0720e-01,  1.3256e+00,  5.3932e-01,
         -3.9567e-01,  9.0989e-01, -1.9692e-01, -4.6047e-01,  4.0646e-01,
         -1.2388e-01, -9.7944e-01,  2.1413e-01, -2.4779e-01,  1.9785e+00,
          6.9313e-01, -1.5414e+00,  4.3914e-01, -9.0318e-01,  1.6063e+00,
         -1.6823e+00, -1.2830e+00, -1.8984e-01,  4.6803e-01, -1.2856e+00,
          4.6016e-01, -6.2297e-02]], device='cuda:0')
tensor([[ 6.0952e-01, -3.8603e-01, -3.1411e-02, -2.0873e+00, -5.3949e-01,
          2.4562e-01, -7.8882e-01,  5.3479e-01, -3.2926e-01, -3.2479e-01,
          2.2971e+00, -1.5696e+00, -1.0179e+00, -1.6139e+00, -1.7095e+00,
          9.5185e-01, -1.2415e+00, -8.0705e-01, -1.5310e+00, -4.2999e-01,
         -4.4785e-01, -6.5145e-01,  3.0271e-01,  1.7647e+00,  1.3615e-01,
          1.4621e+00, -6.8667e-01, -9.2014e-01, -7.0003e-02, -1.8095e-01,
         -9.4588e-01, -7.0349e-01],
        [ 5.9044e-01,  1.1361e+00,  1.3391e+00, -6.2094e-01,  1.6088e-02,
         -1.1615e-01,  3.8177e-01,  1.1747e-01, -5.9717e-01, -2.7498e-02,
         -9.7406e-01,  3.9231e-01,  1.2899e+00, -3.9330e-01,  1.3917e+00,
          1.0443e+00,  3.8581e-01, -1.0368e+00, -3.5226e-01,  5.6165e-01,
         -6.0862e-01,  2.5698e-01, -1.0195e+00, -1.1467e+00, -1.2029e+00,
          5.3663e-01,  9.1905e-03,  2.2449e+00, -7.8165e-01, -8.3872e-01,
          1.3295e+00,  2.7023e+00],
        [-4.3195e-01,  5.1121e-02, -1.4923e+00,  5.6213e-01, -1.2243e-01,
         -6.4353e-01, -3.4381e-01,  1.8280e+00,  3.2947e-02,  2.2299e+00,
         -9.0010e-02,  4.8245e-01, -2.8110e+00,  4.3365e-01,  1.5375e-01,
         -1.1206e+00,  6.9870e-02, -1.5759e+00,  2.7839e-02,  1.5202e-01,
         -8.0499e-01, -3.9039e-01, -7.6957e-01, -8.7281e-01,  3.9650e-01,
          2.7538e-01, -5.0517e-01,  1.1608e+00, -1.0717e+00,  1.8020e-01,
          4.8105e-01,  4.9237e-01],
        [-3.2073e-01,  1.4413e+00,  1.1819e+00,  1.4487e+00,  9.3228e-02,
          1.0294e+00, -4.3508e-03, -3.6946e-01,  1.7238e+00,  2.4710e-01,
          1.3337e+00,  1.3719e+00, -9.1197e-01,  6.4361e-01,  5.5671e-01,
         -1.7674e+00,  1.2305e+00,  3.4324e-01, -5.7693e-02, -6.0192e-01,
         -5.4271e-01,  1.0821e+00,  1.3993e+00,  2.9509e-01, -1.4341e+00,
         -6.2031e-01,  9.3170e-01, -9.9756e-01, -1.1584e+00, -3.2518e-01,
          1.2182e-01, -1.5207e+00],
        [ 6.3209e-01,  5.4360e-01,  3.5401e-01, -1.2029e+00, -6.0398e-01,
         -8.0296e-01, -3.7573e-01, -1.1482e+00,  6.0328e-01,  3.0894e-01,
         -1.7362e+00, -4.2672e-01, -9.6936e-01, -7.4696e-01,  1.3529e+00,
          3.4472e-01,  2.0807e+00, -1.3233e-01, -1.9432e+00,  5.8815e-01,
          5.1108e-02, -1.1876e-01, -1.2594e+00,  2.1307e+00,  6.9194e-01,
         -4.9590e-01,  6.1893e-01,  1.1064e+00,  1.7324e+00, -1.6537e-01,
          4.7319e-01,  1.5934e+00],
        [ 2.1249e+00, -6.4800e-02,  3.4761e-01,  2.3282e-01,  1.0141e+00,
          2.2130e-01,  1.7295e+00, -1.7035e+00, -9.2381e-01, -8.4184e-01,
         -8.8823e-01,  4.1313e-01,  3.1178e-01, -6.5587e-01, -2.7547e-01,
          1.4811e+00, -9.5672e-01, -1.4791e+00, -4.1789e-01, -3.8634e-01,
         -1.5140e+00, -9.2459e-01,  5.9020e-01,  8.9791e-01,  1.8951e+00,
         -2.7902e+00,  3.5561e-01, -9.6427e-01,  1.0298e+00, -4.1422e-01,
          3.6670e-01, -1.5210e+00],
        [-1.7677e+00,  4.0080e-01,  8.8961e-01,  3.9497e-01,  7.2842e-01,
          5.1992e-01, -3.4788e-01,  4.9054e-01, -2.0655e+00,  1.8697e+00,
         -1.0922e+00, -2.5952e-01, -2.1398e-01, -3.7729e-01,  2.0119e-01,
          8.2883e-01, -1.0468e+00, -5.2643e-01, -6.1749e-01, -8.2860e-01,
          1.4665e+00, -1.5768e+00,  1.5293e+00,  3.1835e-01,  8.3545e-03,
         -1.7798e+00,  1.8168e+00, -1.6239e-02, -1.4143e+00,  1.0270e-01,
         -5.0339e-01, -1.1746e+00],
        [-1.7900e-01,  2.1313e+00,  1.0313e+00,  3.5700e-01, -1.3026e+00,
          1.6164e+00, -4.6693e-01,  3.5592e-01,  3.6875e-01, -1.0641e+00,
         -1.5012e+00, -3.7723e-01,  9.0729e-01, -1.4996e+00, -5.2091e-01,
         -4.8268e-01, -6.8417e-01, -4.1251e-01, -4.4497e-01,  1.2448e+00,
         -1.3418e-01,  1.3338e+00,  5.8245e-01,  6.5507e-01,  2.5532e-01,
          5.4325e-01,  6.6371e-01,  5.7932e-01, -1.3371e+00, -7.6655e-01,
          5.1619e-01, -1.2877e-01],
        [-1.4416e-01, -2.6288e+00, -2.1246e+00, -8.0751e-02,  4.4014e-02,
         -5.9211e-01,  2.5559e-01, -5.3141e-01,  5.4870e-01, -5.6758e-01,
          1.2791e+00, -1.0617e-01, -6.4328e-01, -5.4839e-01, -1.4537e-01,
          1.8887e+00, -2.4736e+00, -5.4858e-01,  7.1860e-01, -1.4466e+00,
          1.4743e-01,  1.4188e-01, -1.1526e-01,  1.2618e-01, -1.7029e+00,
         -1.9723e-01,  1.6315e+00, -1.3906e+00, -1.0275e-01,  1.7363e-01,
          6.1181e-01, -5.6107e-01],
        [ 6.3906e-01, -4.4069e-01,  6.3701e-01,  7.5184e-01,  1.0544e+00,
          1.8232e+00, -1.5258e+00,  5.4724e-01,  1.1164e-01, -3.4775e-01,
          5.0061e-01,  5.4603e-01, -2.1786e-01,  1.8550e+00,  8.1279e-01,
          3.0120e-01, -1.9039e+00,  1.4940e+00, -5.9659e-01,  1.2143e-01,
          3.5977e-01, -4.1011e-01, -1.2007e+00, -3.2962e-02, -5.7301e-01,
         -1.3480e-01,  8.6501e-01, -1.2334e+00,  1.1846e+00, -6.6223e-01,
         -7.2295e-01,  7.7434e-01],
        [ 5.3160e-01,  4.1961e-01,  5.8127e-01,  8.2648e-01,  1.0209e+00,
          1.2319e+00,  8.5652e-01, -3.0541e-01,  1.0325e+00,  1.4103e-01,
          2.1603e-01, -7.6157e-01, -6.0222e-01, -7.4629e-02,  2.3970e-01,
         -2.3647e+00, -9.7398e-02,  2.4152e-01,  4.3406e-01, -1.2253e+00,
         -1.9031e+00, -4.3878e-01,  1.5080e+00, -1.0414e+00,  7.6863e-01,
          2.8666e-01, -1.6624e+00, -6.9328e-01, -3.2849e-01, -8.5015e-01,
         -5.9601e-01,  3.2295e-01],
        [ 2.0045e+00, -8.3032e-01,  1.8786e+00, -1.7013e-01, -1.3229e+00,
         -4.7732e-01, -9.8415e-01, -1.2204e+00,  5.3711e-01, -4.2803e-01,
          9.4926e-02, -1.2783e+00, -4.6332e-01, -1.3687e+00,  1.0886e+00,
          7.6452e-01, -8.4799e-01, -1.8781e-01,  1.3523e+00,  4.3554e-01,
         -5.1686e-01,  6.9452e-01, -4.9451e-01,  3.0663e-01,  1.6343e-01,
          3.1503e-01, -2.2774e-05,  1.5364e+00,  3.1660e+00,  2.0540e+00,
          8.0192e-01, -1.0041e+00],
        [ 7.2213e-01,  7.9856e-01,  1.0788e+00,  1.1388e+00, -3.4054e-02,
          9.2196e-01,  1.7992e-01, -1.2150e+00,  1.1149e+00,  6.6732e-01,
          4.9346e-01,  1.6135e+00, -7.3385e-01,  8.5965e-01,  1.7940e+00,
         -2.3992e-01,  3.5353e-01,  6.2260e-01,  3.5409e-01, -1.4968e+00,
         -7.6055e-01,  3.0548e-01,  1.7501e+00,  6.8175e-01,  4.5542e-01,
         -6.2581e-01,  1.5158e+00,  1.5398e+00,  2.0612e-01, -5.3453e-01,
         -4.5231e-01, -1.4414e-01],
        [-8.3505e-01,  9.9473e-01,  3.9253e-01,  7.5111e-01, -2.1848e+00,
          3.7665e-01, -1.0950e+00, -5.9434e-01,  4.3485e-01,  2.0765e-01,
          6.4216e-01,  8.1328e-01, -2.1603e+00,  2.2451e-01, -1.6354e+00,
          9.0758e-03, -1.5102e+00, -2.6044e-02, -8.5166e-01, -1.9689e+00,
          5.1006e-01, -1.5064e+00,  2.7938e-01,  9.9494e-01, -9.1814e-02,
          8.0134e-01,  2.5341e-01, -7.6615e-01, -3.4214e-01, -1.5832e+00,
         -5.5387e-01, -2.7158e-01],
        [-1.4676e+00,  4.2028e-01, -1.4932e+00, -3.3664e-01, -1.4971e+00,
          3.0819e-01,  4.7011e-01,  7.3241e-01,  1.1423e+00,  3.7189e-01,
          1.0458e+00,  1.3035e+00, -8.1184e-01,  3.3758e-01, -3.7490e-01,
         -3.0212e+00,  1.2268e+00, -5.3555e-01, -6.8245e-01, -1.5182e-01,
         -1.9050e-01,  1.0639e+00, -1.7162e-01,  2.9401e-02, -1.0678e-01,
          7.7281e-01, -2.4533e-01,  4.3777e-01,  2.3714e-01,  3.2356e-01,
          4.6728e-01,  2.1854e+00],
        [-2.4380e-01, -2.2546e-01, -7.6864e-02, -1.2162e+00,  6.9244e-01,
          1.4833e+00,  1.5748e+00, -3.5168e-01,  4.8938e-01,  1.0202e-01,
         -1.4567e+00, -4.6127e-01,  2.5666e+00,  5.2735e-01,  2.8665e-02,
          1.5018e+00, -1.0583e+00, -5.4428e-01,  1.6883e+00, -4.9752e-01,
          2.2332e+00,  1.2037e+00,  5.3470e-01, -1.4360e+00,  2.7367e-01,
          5.9060e-01, -6.2759e-01, -1.1928e+00, -3.4876e-03, -9.8212e-01,
         -7.0836e-01,  8.8842e-01],
        [-5.5478e-01,  5.7249e-02,  1.0450e+00, -9.6337e-01, -8.7236e-01,
          5.0485e-01,  1.0677e-01, -6.6476e-01, -1.0849e+00, -1.0613e+00,
          2.7011e-01,  1.0424e+00,  9.6655e-01, -7.8583e-02, -3.2260e-01,
         -7.8638e-01, -5.6342e-01, -8.7951e-01, -6.7772e-01,  1.1104e+00,
         -5.7168e-01, -5.4050e-01,  6.5495e-01,  1.0223e-01,  4.0337e-01,
         -1.9567e-01, -1.7940e+00, -9.9965e-01,  6.1351e-01, -8.3058e-01,
          5.0976e-01, -7.1532e-01]], device='cuda:0')
tensor([[-1.2465e+00,  1.3196e+00, -7.7606e-01,  3.9350e-01,  1.4473e+00,
         -9.5783e-01, -6.7657e-01, -6.5357e-01,  1.0044e-01, -9.5493e-01,
         -1.7007e-01, -1.8765e+00,  4.7608e-03, -3.0655e-01,  1.3366e+00,
          5.6023e-01,  1.1871e+00,  1.3410e-01,  1.4661e+00, -2.2320e-01,
          9.5691e-01, -9.8825e-01, -9.5679e-01,  1.4765e+00,  1.4053e+00,
          2.4762e-02, -3.7827e-01,  1.3550e+00,  6.8924e-02, -5.2132e-01,
          3.4711e-01,  7.1034e-01],
        [ 1.9289e+00,  5.3720e-02,  4.3112e-02,  2.5367e-01, -2.1125e+00,
          5.0924e-01, -1.3841e+00, -1.6326e+00, -2.4280e-01, -1.8743e-01,
         -1.8416e+00, -8.8178e-01, -1.5119e+00, -7.0308e-01,  5.5212e-01,
         -6.4247e-01,  7.4575e-01,  6.2069e-01,  1.7180e+00,  2.0337e+00,
         -2.6710e-01,  4.2577e-01,  9.5697e-01, -2.8069e-01,  9.2348e-01,
          8.4970e-01, -1.9068e+00,  3.9540e-01,  4.6046e-02,  8.6522e-01,
         -1.1126e+00,  1.1784e+00],
        [-5.2495e-01,  3.0902e-02,  7.6638e-01, -1.3724e+00, -4.5350e-01,
          3.3209e-01, -2.2438e+00, -9.9941e-01,  5.0319e-01,  5.8403e-01,
          9.9621e-02,  2.3972e-01,  1.2753e+00, -9.2763e-02,  2.3672e-01,
          8.7746e-01, -3.0491e-01, -5.5950e-01, -6.3122e-01,  9.3406e-01,
         -1.0280e+00, -5.7021e-01, -8.5607e-01, -1.5952e-02,  1.3716e+00,
         -1.8270e-01, -2.1543e-02, -2.3337e-01, -1.7704e+00,  4.1914e-01,
         -1.7288e+00, -1.4147e+00],
        [ 3.7063e-01, -8.6482e-01,  1.0686e+00,  3.8440e-01, -6.9054e-01,
         -7.7128e-02,  9.1729e-01, -6.1413e-01, -1.5340e+00, -4.0806e-01,
         -4.5400e-01, -1.8647e+00, -2.7901e+00,  6.7868e-01,  3.1916e+00,
          1.3146e+00,  4.4968e-01,  1.0910e+00,  7.2265e-01,  4.1047e-01,
         -2.2290e+00, -6.8227e-01, -1.1482e+00,  3.0494e-01, -4.9830e-01,
         -1.1170e+00, -6.0212e-01, -4.6503e-02, -6.9865e-01,  7.5168e-01,
          1.7792e-01, -2.9141e-02],
        [-1.2835e+00,  6.0851e-01, -1.0528e+00, -5.7311e-01, -6.9676e-01,
         -2.2371e-01,  9.8723e-02, -6.4514e-01, -1.5864e+00, -1.5384e+00,
          6.1369e-02,  3.8213e-01,  1.4781e-01,  1.8302e-01, -8.1161e-01,
         -2.4969e-01,  1.0468e+00,  9.5064e-01,  1.9873e+00, -3.1122e-02,
          9.7364e-01, -1.3535e-02, -9.7725e-01,  1.3641e-01, -2.3094e-01,
          2.3768e-01, -1.6974e+00,  2.6570e+00, -7.8684e-01, -9.7645e-02,
         -2.5224e+00, -9.8246e-02],
        [ 1.0474e+00, -4.3052e-01,  1.0959e+00,  1.0209e+00, -9.6650e-01,
         -9.6530e-01,  1.2571e+00, -1.9058e+00, -1.6111e-01,  3.4511e-01,
         -6.1740e-01,  1.0887e-03,  6.5318e-01,  1.0676e+00, -9.8942e-02,
          1.4587e-01,  8.3340e-01,  2.2721e+00, -2.9751e-01, -1.2798e+00,
         -1.2259e-02, -7.3933e-01,  1.8506e-01,  1.0431e+00, -8.6260e-01,
          1.3743e+00, -1.5107e+00,  1.4429e+00,  4.5617e-01, -7.6015e-01,
         -2.6796e-01,  1.6203e+00],
        [ 3.6721e-01, -1.7110e+00,  7.8567e-01, -5.4495e-01,  5.0404e-01,
          6.7244e-01, -1.1830e-01,  7.7922e-01,  5.4206e-01, -1.0862e+00,
         -1.1765e-02,  7.0025e-01, -8.5548e-01,  1.6902e+00,  2.0736e+00,
          1.1220e-02,  4.3047e-01,  3.6404e-01,  1.5631e+00,  1.4887e+00,
          2.0596e+00, -1.7394e-01, -1.2738e+00,  1.2628e+00,  7.3731e-02,
          1.5956e+00,  3.5300e-01, -1.0008e-01, -1.3845e-01, -1.0254e+00,
         -7.6798e-01, -3.9053e-01],
        [ 9.6936e-01,  9.0824e-01, -5.6401e-01,  1.2977e+00,  9.4666e-01,
         -3.1269e-01, -3.7824e-01,  1.4890e+00,  7.9376e-01,  4.5407e-01,
         -9.3500e-01, -1.3081e+00,  1.1459e-01,  9.5418e-01,  2.5292e-01,
         -1.0207e+00,  5.2536e-01,  3.6853e-01, -3.9385e-01,  7.6093e-01,
         -8.9505e-01, -1.8273e+00,  1.5085e+00, -1.3088e+00,  1.8913e+00,
          1.4002e+00,  3.4758e-02,  2.5916e-01,  4.7360e-01,  4.9123e-01,
         -1.3524e+00,  2.1998e+00],
        [ 6.0313e-01, -2.7309e-01, -1.8812e+00, -1.0888e+00,  1.3173e-01,
          1.0492e+00,  6.1771e-01, -1.5192e+00, -1.6790e+00,  6.6037e-01,
          4.2566e-01, -2.9575e-01,  7.3080e-01, -1.1995e+00, -1.7305e+00,
          6.4065e-01,  1.9582e-01, -2.1343e-01,  1.6566e-01, -1.0055e+00,
         -1.4702e-02, -1.4322e+00,  3.8879e-01, -2.8029e-01,  1.7689e+00,
         -9.1389e-01, -1.0948e+00,  1.8045e+00, -1.1122e-01,  3.0814e-02,
         -2.2896e+00, -3.1401e-01],
        [-1.0690e+00, -1.0962e+00,  8.6160e-01, -4.1825e-01,  1.2348e+00,
         -5.9030e-01,  9.9011e-01,  1.7568e+00, -3.1471e-01,  8.3179e-01,
         -2.3046e-01,  1.1644e+00, -1.2284e+00, -7.9202e-01, -7.3542e-01,
          2.0380e-01, -1.3787e+00,  6.1295e-01, -1.8709e+00, -1.7185e+00,
          3.5139e-01, -1.9996e+00, -3.1479e+00, -1.4503e-01, -7.3260e-01,
          2.1885e-01, -5.4918e-01,  8.7133e-02, -2.2606e+00,  1.8639e+00,
         -1.7883e+00, -2.2376e-01],
        [-6.1800e-01,  1.1437e+00, -5.6201e-01,  3.1821e-01,  3.4506e-01,
         -6.7405e-02, -7.8933e-03,  2.3990e-01, -2.7586e-01, -1.7640e-01,
         -2.9904e+00, -1.2508e+00, -6.0443e-01, -1.5644e-01, -5.3928e-01,
         -1.8618e+00,  1.4281e+00,  5.4894e-01,  2.3554e-01,  3.4315e-01,
         -9.7859e-01, -3.4543e-01,  8.0332e-01, -2.9378e-01,  1.6157e+00,
          5.1047e-01, -1.7117e-01, -4.1156e-01, -1.9487e+00,  2.3624e-01,
         -1.0019e+00, -4.6900e-01],
        [ 1.5302e+00, -1.2507e+00, -1.4094e+00, -1.0436e+00,  1.2655e+00,
          3.1981e+00, -1.3995e+00,  1.6625e-01,  3.1432e-01, -6.7765e-01,
          6.3234e-01,  1.0437e+00,  2.5981e+00,  1.4410e+00,  1.7587e+00,
          1.9505e+00, -1.3909e+00, -7.8447e-01, -4.6571e-01, -1.0011e+00,
          1.0385e-01,  3.2769e-01,  1.3356e+00,  1.1525e+00, -7.2586e-01,
          3.3898e-01, -1.4150e+00,  5.2886e-01,  1.1598e+00,  1.7376e+00,
          7.3687e-01, -5.7022e-01],
        [-3.9617e-01, -7.7341e-02, -9.3964e-01,  4.0267e-01, -1.0765e+00,
         -4.8907e-02,  7.4880e-01, -1.0189e+00, -6.6173e-02,  2.1436e+00,
          1.3596e+00, -3.5812e-01,  7.3499e-01, -1.2521e+00,  5.6061e-01,
         -2.0103e-01, -1.3888e+00,  1.3817e+00,  3.2852e-01,  6.9480e-01,
         -5.7703e-01,  4.1927e-01, -3.2123e-01,  6.2907e-01, -1.6316e-01,
         -2.0098e+00, -1.1796e+00, -8.6725e-01,  2.2747e-01,  1.0560e+00,
          4.0486e-01,  1.5906e-01],
        [-1.2057e+00,  5.5412e-01,  5.4233e-01,  6.1582e-02,  8.3015e-01,
         -1.5624e+00, -7.5001e-01,  1.6488e-02, -6.9113e-02, -1.0994e-01,
         -8.3060e-01, -4.6678e-01, -4.7275e-02, -3.4526e-02, -9.8901e-01,
         -1.1416e+00, -2.9862e-01,  1.0232e+00, -1.6217e+00,  1.0916e-01,
          3.6498e-01,  4.5262e-01, -7.8399e-01, -1.9291e+00, -3.9047e-02,
         -1.3500e+00, -3.1714e-01,  1.0165e-01,  1.6336e+00,  1.6200e+00,
         -5.4410e-01,  1.1883e+00],
        [-1.5883e+00, -4.9769e-01, -7.8015e-01,  5.4159e-01, -5.5529e-01,
          3.8038e-01, -3.9341e-01,  1.4877e+00, -3.7879e-01, -3.5097e-02,
          5.9046e-01, -7.7346e-01,  9.7320e-01, -9.0912e-02, -2.0448e-02,
          1.1993e+00,  1.9793e+00, -2.8309e-01, -3.0081e-01,  3.2279e-01,
         -9.8924e-02,  4.8003e-01,  2.2594e-01,  2.1284e+00,  9.3917e-01,
         -1.6207e+00,  2.5013e+00,  3.1570e-01, -7.6545e-01,  3.1544e-01,
          1.5087e+00,  4.5183e-01],
        [-1.2820e+00, -1.2525e+00, -5.2575e-01, -1.3718e+00,  1.1909e+00,
         -8.8154e-03, -2.1060e+00,  1.4757e+00, -1.0003e+00,  2.1833e+00,
         -4.7652e-01, -6.5424e-01,  4.9494e-01, -1.5250e+00, -5.6845e-01,
         -1.4445e+00,  6.2445e-01, -1.9481e+00,  6.5823e-01, -8.9583e-01,
         -5.1043e-01,  5.8696e-01, -4.9562e-02, -5.2787e-01,  2.3202e+00,
         -1.1708e+00,  1.5518e+00, -9.2241e-01,  1.0230e+00,  9.9566e-01,
          1.5043e-01,  2.0917e+00],
        [ 1.1240e+00, -5.6362e-01,  1.3801e+00, -2.8378e-01, -5.9023e-01,
         -1.5880e+00,  1.1279e+00, -1.4643e+00, -1.0335e+00, -1.1624e-01,
          6.9381e-01, -8.6223e-01,  1.8410e-01, -9.6733e-01, -2.9753e-01,
          4.5917e-02,  1.8045e+00,  1.0430e+00,  1.5447e+00, -7.4551e-01,
         -1.5758e+00, -1.0821e+00, -1.7604e+00,  1.1537e+00, -2.2821e-01,
          1.4244e-01,  1.0058e+00,  1.2887e+00, -3.8531e-01,  5.7364e-01,
          5.8408e-01,  8.7324e-01]], device='cuda:0')
100%|##########| 32/32 [00:00<00:00, 106.82it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A[[ 1.41649116e-02  1.37666753e-02  2.28059944e-04  3.87974866e-02
  -3.18135344e-03  4.19518095e-04 -2.09083874e-02  1.75545830e-02
  -1.21592367e-02  2.61170347e-03 -1.04362378e-02 -8.02103151e-03
   3.67503017e-02 -8.37116851e-04  7.69434730e-03  1.10814869e-02
   2.75046732e-02 -7.10085873e-03  2.14860495e-02  1.43167004e-02
  -1.22631304e-02  7.49648456e-03  7.18550105e-03 -9.48645547e-03
  -6.07692450e-03 -9.45778470e-03  6.20486587e-02 -2.15578917e-03
   4.69287066e-03 -9.69099253e-03  1.42018441e-02 -2.99805589e-02]
 [ 1.43574979e-02  1.43986624e-02  6.42309897e-04  3.68087478e-02
  -2.63287779e-03 -5.16056549e-04 -2.00699866e-02  1.62556618e-02
  -1.18117016e-02  2.91091669e-03 -1.00337705e-02 -7.70245912e-03
   3.60309482e-02 -1.48962112e-03  9.89864208e-03  1.17568457e-02
   2.70470399e-02 -7.05600344e-03  2.10090559e-02  1.40609518e-02
  -1.19558461e-02  7.74199190e-03  7.43121700e-03 -9.46229510e-03
  -5.31021319e-03 -9.08405706e-03  6.20955005e-02 -2.56505818e-03
   4.49920166e-03 -1.08828079e-02  1.59299262e-02 -2.75574960e-02]
 [ 1.48480944e-02  1.49674015e-02  9.70064430e-04  3.84230241e-02
  -3.55962850e-03  5.42057212e-04 -1.99827626e-02  1.74336862e-02
  -1.14194565e-02  3.63706145e-03 -1.00518391e-02 -8.31775554e-03
   3.64312455e-02 -1.24087289e-03  8.32211040e-03  1.10135591e-02
   2.69976351e-02 -6.99593034e-03  2.17383932e-02  1.41217960e-02
  -1.23966355e-02  7.29519874e-03  7.38386670e-03 -1.00104464e-02
  -6.64065918e-03 -9.93627496e-03  6.13293834e-02 -2.07707752e-03
   4.29965602e-03 -9.43791680e-03  1.51610449e-02 -2.83574145e-02]
 [ 1.43751493e-02  1.52056329e-02  4.33325768e-04  3.69654074e-02
  -3.32515314e-03 -3.98115953e-04 -2.00883206e-02  1.71171371e-02
  -1.11506786e-02  3.58037348e-03 -9.98570956e-03 -8.16101208e-03
   3.60048115e-02 -1.98998116e-03  8.58405046e-03  1.15850857e-02
   2.69241743e-02 -7.34043401e-03  2.08552349e-02  1.46172335e-02
  -1.22761633e-02  7.77197070e-03  8.12686607e-03 -9.35996417e-03
  -6.41882885e-03 -9.07853805e-03  6.12202249e-02 -2.46380293e-03
   4.44716727e-03 -9.81565472e-03  1.54827610e-02 -2.61832699e-02]
 [ 1.46272508e-02  1.31555535e-02  9.24084336e-04  3.95121537e-02
  -4.09501325e-03 -1.86829129e-04 -2.08187792e-02  1.72274821e-02
  -1.18552372e-02  2.68330588e-03 -1.02770431e-02 -7.81722739e-03
   3.65393385e-02 -1.62285450e-03  8.19522794e-03  1.05058625e-02
   2.70223971e-02 -6.23685494e-03  1.98541805e-02  1.51519990e-02
  -1.25081297e-02  6.76797144e-03  7.24132825e-03 -9.34515148e-03
  -7.09927781e-03 -9.69790667e-03  6.21829145e-02 -2.87690805e-03
   3.96542810e-03 -9.70429834e-03  1.43636325e-02 -2.78505944e-02]
 [ 1.46404970e-02  1.41636301e-02  9.02924454e-04  3.80767100e-02
  -3.04369675e-03  7.02322810e-04 -1.99162140e-02  1.70587972e-02
  -1.23870075e-02  3.21760774e-03 -1.01595074e-02 -8.14294908e-03
   3.62136737e-02 -1.04487746e-03  8.77318531e-03  1.14016905e-02
   2.71626897e-02 -7.24480767e-03  2.13300269e-02  1.40472334e-02
  -1.19245294e-02  6.88529154e-03  7.35936314e-03 -9.15218331e-03
  -6.52962504e-03 -1.03229061e-02  6.18484281e-02 -1.74836162e-03
   4.32889024e-03 -1.01563334e-02  1.49211995e-02 -2.80154478e-02]
 [ 1.46578876e-02  1.39722424e-02  7.91141065e-04  3.76365557e-02
  -2.91083357e-03  3.43387364e-04 -1.95987355e-02  1.69635005e-02
  -1.16469823e-02  3.94542981e-03 -9.85302217e-03 -7.97074661e-03
   3.66922915e-02 -1.12746248e-03  8.31451174e-03  1.12870801e-02
   2.75811329e-02 -6.78367633e-03  2.14393884e-02  1.43286120e-02
  -1.20090749e-02  7.54875923e-03  7.81322829e-03 -9.67860688e-03
  -6.24910789e-03 -9.76533070e-03  6.17401451e-02 -1.71171012e-03
   4.46537696e-03 -1.07815592e-02  1.51819540e-02 -2.79350281e-02]
 [ 1.45344762e-02  1.41725233e-02  7.28296814e-04  3.79817449e-02
  -2.11665174e-03 -4.09936765e-04 -1.95023026e-02  1.75594222e-02
  -1.16560897e-02  4.26229369e-03 -1.11805527e-02 -7.90566020e-03
   3.55411470e-02 -1.59786444e-03  7.75904115e-03  1.32512720e-02
   2.66639069e-02 -7.94344954e-03  2.24490501e-02  1.37408525e-02
  -1.21927084e-02  7.58030871e-03  7.08133355e-03 -9.64974053e-03
  -6.84095733e-03 -1.09863710e-02  6.09000809e-02 -2.95950938e-03
   5.15218079e-03 -9.74152517e-03  1.66649651e-02 -2.90546715e-02]
 [ 1.51183000e-02  1.45979133e-02  2.10182043e-04  3.81104313e-02
  -3.14687565e-03 -1.78409042e-04 -2.07754653e-02  1.84210576e-02
  -1.20316427e-02  3.50472750e-03 -9.93759558e-03 -8.41054320e-03
   3.68602499e-02 -1.04959984e-03  7.95605872e-03  1.19654294e-02
   2.73790471e-02 -6.85732905e-03  2.12804768e-02  1.51046971e-02
  -1.17419958e-02  7.62901455e-03  7.42104324e-03 -9.58221592e-03
  -7.24528264e-03 -9.93681885e-03  6.14735372e-02 -1.83768594e-03
   4.34848759e-03 -9.65017080e-03  1.46921575e-02 -2.82709040e-02]
 [ 1.45405438e-02  1.43645545e-02  8.80578533e-04  3.73847447e-02
  -2.99642701e-03  3.68518289e-04 -1.99918654e-02  1.72825195e-02
  -1.15128839e-02  4.26673098e-03 -1.09192459e-02 -7.29848864e-03
   3.61715369e-02 -1.34127773e-03  7.82792363e-03  1.23667838e-02
   2.66728643e-02 -7.95288011e-03  2.29522195e-02  1.41483638e-02
  -1.26541294e-02  7.47133652e-03  8.30573868e-03 -9.36690252e-03
  -6.32160576e-03 -9.56041180e-03  6.19451217e-02 -2.24691071e-03
   4.67164861e-03 -1.02933059e-02  1.50700640e-02 -2.71690637e-02]
 [ 1.47427805e-02  1.45301009e-02  1.00182160e-03  3.68157402e-02
  -3.30189802e-03 -6.29259739e-05 -1.98593196e-02  1.68917738e-02
  -1.16077447e-02  2.90275086e-03 -9.79584921e-03 -7.40868272e-03
   3.61612104e-02 -1.08828256e-03  9.19078570e-03  1.08375577e-02
   2.73642149e-02 -6.52916171e-03  2.13090926e-02  1.37535874e-02
  -1.31482184e-02  7.29646487e-03  8.07672925e-03 -8.57549068e-03
  -4.99424106e-03 -8.52573290e-03  6.24127276e-02 -8.51147866e-04
   4.60707350e-03 -1.15676457e-02  1.54997632e-02 -2.79863533e-02]
 [ 1.42798573e-02  1.42622059e-02  9.89950495e-04  3.64741012e-02
  -3.57776997e-03 -2.69822776e-04 -2.09260583e-02  1.78379081e-02
  -1.27043771e-02  1.83991436e-03 -1.08478926e-02 -7.05306698e-03
   3.62505540e-02 -1.25042873e-03  7.45907612e-03  1.19342264e-02
   2.75189299e-02 -6.84247166e-03  2.10408103e-02  1.43283755e-02
  -1.33517385e-02  7.52577558e-03  7.71787763e-03 -8.79546721e-03
  -5.01542352e-03 -7.58937281e-03  6.49446994e-02 -1.72113511e-03
   4.86177206e-03 -1.09560573e-02  1.46904681e-02 -2.77500562e-02]
 [ 1.45287355e-02  1.26969693e-02  6.04365021e-04  3.85540575e-02
  -2.55797384e-03  2.48605385e-04 -2.06061602e-02  1.75110511e-02
  -1.09480629e-02  2.30995659e-03 -1.09658483e-02 -7.88163207e-03
   3.63039263e-02 -1.02636393e-03  8.40603001e-03  1.21233435e-02
   2.52504312e-02 -7.56109785e-03  2.18617022e-02  1.39487423e-02
  -1.23756984e-02  6.63658790e-03  7.20613031e-03 -8.47575255e-03
  -6.50852639e-03 -9.45765059e-03  6.37108311e-02 -2.37660250e-03
   4.50898567e-03 -1.04657374e-02  1.59987323e-02 -2.55612060e-02]
 [ 1.48284547e-02  1.35144573e-02  6.83876686e-04  3.89281884e-02
  -3.32135707e-03  3.11029144e-04 -2.00501047e-02  1.76117904e-02
  -1.17072295e-02  4.06061579e-03 -1.05341263e-02 -7.63208419e-03
   3.56828868e-02 -1.47619168e-03  8.39694683e-03  1.12243574e-02
   2.68752985e-02 -7.61816883e-03  2.16929186e-02  1.40816569e-02
  -1.24135893e-02  6.56324020e-03  7.56681431e-03 -9.05916374e-03
  -6.83716638e-03 -1.10825775e-02  6.14096299e-02 -2.02733814e-03
   4.93248133e-03 -9.84476693e-03  1.48123261e-02 -2.84170322e-02]
 [ 1.47739165e-02  1.39483027e-02  5.58419852e-04  3.81797627e-02
  -3.72956507e-03 -7.08624721e-05 -1.96880605e-02  1.73173696e-02
  -1.16056707e-02  3.60875065e-03 -1.02421595e-02 -7.59111624e-03
   3.64296213e-02 -1.51781505e-03  8.12587794e-03  1.12806875e-02
   2.75399033e-02 -6.30473578e-03  2.07508244e-02  1.45895118e-02
  -1.33830654e-02  7.08943559e-03  8.54341872e-03 -8.53763148e-03
  -6.43052161e-03 -9.31553543e-03  6.14462011e-02 -2.00890866e-03
   4.54811938e-03 -1.08908201e-02  1.52704073e-02 -2.83177458e-02]
 [ 1.45050827e-02  1.47897666e-02  1.97677873e-04  3.82091515e-02
  -4.15554503e-03  3.40329949e-04 -2.04888098e-02  1.69642158e-02
  -1.21193277e-02  3.38574965e-03 -1.02488250e-02 -8.18732753e-03
   3.60219106e-02 -1.38076697e-03  8.58712476e-03  1.12456065e-02
   2.64161639e-02 -7.08367396e-03  2.12349109e-02  1.39425592e-02
  -1.25184581e-02  6.95015164e-03  7.85541348e-03 -8.78586993e-03
  -6.60057785e-03 -9.21013765e-03  6.16047643e-02 -1.99240027e-03
   4.46959538e-03 -9.90170892e-03  1.46350022e-02 -2.78273672e-02]
 [-1.85593307e-01 -1.99711114e-01 -3.28549415e-01  1.59734535e+00
  -4.21823263e-01 -1.82318956e-01 -8.02791238e-01  1.35985601e+00
  -3.47541481e-01 -1.58695132e-01 -2.60374963e-01 -3.70871931e-01
   2.70528483e+00 -1.00133643e-01  6.16350591e-01 -2.54055113e-01
   3.15860868e+00 -5.54431021e-01  2.02059412e+00 -2.55201936e-01
  -5.89289293e-02 -4.31717113e-02  1.00164056e+00 -4.65963066e-01
  -1.54170215e-01 -2.67133832e-01  2.58813000e+00 -1.45697370e-01
   6.77630398e-03 -3.74792457e-01  1.72774732e+00 -9.71416116e-01]]
  0%|          | 0/32 [00:00<?, ?it/s]
  0%|          | 0/1 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 165, in vis
    misc.save_npys(wlatents, pattern_of("latents-w", step, "npy"), verbose, idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 63, in save_npys
    save_npy(npy, path % (offset + i))
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 53, in save_npy
    mat = mat.cpu().numpy()
AttributeError: 'numpy.ndarray' object has no attribute 'cpu'
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2293.26it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 10264.43it/s]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 170, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2099.81it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 6002.85it/s]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 177, in vis
    save_images(soft_maps, pattern_of("softmaps", step, "png"), idx)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 238, in save_images
    save_img_grid(imgs, clean_filename(path % offset), drange, grid_size)
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 164, in save_img_grid
    to_pil(create_img_grid(imgs, grid_size), drange).save(filename) # .cpu().numpy()
  File "/home/quoniam/Work/TileGAN/gan/training/misc.py", line 140, in to_pil
    img = PIL.Image.fromarray(img, fmt)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/PIL/Image.py", line 3103, in fromarray
    raise ValueError(msg)
ValueError: Too many dimensions: 3 > 2.
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 1992.28it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 6012.80it/s]
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 171, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2238.34it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8559.80it/s]
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 172, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2317.26it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8355.71it/s]
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 172, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2270.68it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8573.47it/s]
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 172, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2253.68it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8587.74it/s]
[]
[]
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 172, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 6616.27it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8539.65it/s]
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
[[0.72, -0.25760000000000005, -0.32000000000000006], [0.6575999999999997, 0.72, -0.32000000000000006], [-0.32000000000000006, 0.72, -0.25760000000000005], [-0.32000000000000006, 0.6575999999999997, 0.72], [-0.25760000000000005, -0.32000000000000006, 0.72], [0.72, -0.32000000000000006, 0.6575999999999997]]
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 175, in vis
    soft_maps = np.sum(pallete * np.expand_dims(soft_maps, axis = 2), axis = 1)
ValueError: operands could not be broadcast together with shapes (6,3,1,1) (32,16,1,256,256) 
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2200.54it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8510.95it/s]
[]
[]
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 172, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2332.40it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8419.66it/s]
[]
[]
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 172, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2213.32it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8524.47it/s]
6
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
[[0.72, -0.25760000000000005, -0.32000000000000006], [0.6575999999999997, 0.72, -0.32000000000000006], [-0.32000000000000006, 0.72, -0.25760000000000005], [-0.32000000000000006, 0.6575999999999997, 0.72], [-0.25760000000000005, -0.32000000000000006, 0.72], [0.72, -0.32000000000000006, 0.6575999999999997]]
6
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
  0%|          | 0/1 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 175, in vis
    soft_maps = np.sum(pallete * np.expand_dims(soft_maps, axis = 2), axis = 1)
ValueError: operands could not be broadcast together with shapes (6,3,1,1) (32,16,1,256,256) 
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2573.09it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8534.77it/s]
0
[]
[]
0
[]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 172, in vis
    pallete = np.expand_dims(misc.get_colors(k - 1), axis = [2, 3])
  File "<__array_function__ internals>", line 6, in expand_dims
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in normalize_axis_tuple
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  File "/home/quoniam/miniconda/envs/ganformer/lib/python3.7/site-packages/numpy/core/numeric.py", line 1385, in <listcomp>
    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
numpy.AxisError: axis 3 is out of bounds for array of dimension 3
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2346.59it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8035.55it/s]
6
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
[[0.72, -0.25760000000000005, -0.32000000000000006], [0.6575999999999997, 0.72, -0.32000000000000006], [-0.32000000000000006, 0.72, -0.25760000000000005], [-0.32000000000000006, 0.6575999999999997, 0.72], [-0.25760000000000005, -0.32000000000000006, 0.72], [0.72, -0.32000000000000006, 0.6575999999999997]]
6
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
  0%|          | 0/1 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 175, in vis
    soft_maps = np.sum(pallete * np.expand_dims(soft_maps, axis = 2), axis = 1)
ValueError: operands could not be broadcast together with shapes (6,3,1,1) (32,16,1,256,256) 
Loading training set...
Num images: 999
Image shape: [3, 256, 256]
Label shape: [0]
Resuming from results/exp-000/network-snapshot-002136.pkl
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                                   Parameters  Buffers  Output shape        Datatype
---                                         ---         ---      ---                 ---     
mapping.global_mlp.l0.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l0                               -           -        [4, 32]             float32 
mapping.global_mlp.l1.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l1                               -           -        [4, 32]             float32 
mapping.global_mlp.l2.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l2                               -           -        [4, 32]             float32 
mapping.global_mlp.l3.fc0                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3.fc1                           1056        -        [4, 32]             float32 
mapping.global_mlp.l3                               -           -        [4, 32]             float32 
mapping.global_mlp.out_layer                        1056        -        [4, 32]             float32 
mapping.global_mlp                                  -           -        [4, 1, 32]          float32 
mapping.mlp.sa0.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa0.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa0.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa0.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa0.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa0:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa0:1                                   -           -        [64, 32]            float32 
mapping.mlp.l0.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l0.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l0                                      -           -        [64, 32]            float32 
mapping.mlp.sa1.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa1.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa1.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa1.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa1.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa1:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa1:1                                   -           -        [64, 32]            float32 
mapping.mlp.l1.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l1.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l1                                      -           -        [64, 32]            float32 
mapping.mlp.sa2.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa2.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa2.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa2.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa2.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa2:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa2:1                                   -           -        [64, 32]            float32 
mapping.mlp.l2.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l2.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l2                                      -           -        [64, 32]            float32 
mapping.mlp.sa3.to_queries                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_keys                             1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_values                           1056        -        [64, 32]            float32 
mapping.mlp.sa3.from_pos_map                        1056        -        [64, 32]            float32 
mapping.mlp.sa3.to_pos_map                          1056        -        [64, 32]            float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.att_dp                              -           -        [4, 1, 1, 16]       float32 
mapping.mlp.sa3.to_gate_attention                   -           -        [4, 1, 16, 16]      float32 
mapping.mlp.sa3.modulation                          1056        -        [64, 32]            float32 
mapping.mlp.sa3:0                                   -           -        [64, 32]            float32 
mapping.mlp.sa3:1                                   -           -        [64, 32]            float32 
mapping.mlp.l3.fc0                                  1056        -        [64, 32]            float32 
mapping.mlp.l3.fc1                                  1056        -        [64, 32]            float32 
mapping.mlp.l3                                      -           -        [64, 32]            float32 
mapping.mlp.out_layer                               1056        -        [64, 32]            float32 
mapping.mlp                                         -           -        [4, 16, 32]         float32 
mapping                                             -           32       [4, 17, 15, 32]     float32 
synthesis.b4.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b4.conv1.transformer.to_queries           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.from_pos_map         16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b4.conv1.transformer.to_gate_attention    -           -        [4, 1, 16, 16]      float32 
synthesis.b4.conv1.transformer.modulation           262656      -        [64, 512]           float32 
synthesis.b4.conv1.transformer:0                    17408       -        [4, 16, 512]        float32 
synthesis.b4.conv1.transformer:1                    -           -        [4, 16, 512]        float32 
synthesis.b4.conv1.biasAct                          512         -        [4, 512, 4, 4]      float32 
synthesis.b4.conv1:0                                2359297     544      [4, 512, 4, 4]      float32 
synthesis.b4.conv1:1                                -           -        [4, 512, 4, 4]      float32 
synthesis.b4                                        8192        16       [4, 512, 4, 4]      float32 
synthesis.b8.skip.biasAct                           -           -        [4, 512, 8, 8]      float32 
synthesis.b8.skip                                   262144      16       [4, 512, 8, 8]      float32 
synthesis.b8.conv0.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv0.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv0.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv0.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv0.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv0.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv0.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv0.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv0:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv0:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1.affine                           16896       -        [4, 512]            float32 
synthesis.b8.conv1.transformer.to_queries           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_keys              16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.to_values            16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.from_pos_map         16896       -        [256, 512]          float32 
synthesis.b8.conv1.transformer.to_pos_map           16896       -        [64, 512]           float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.att_dp               -           -        [4, 1, 1, 16]       float32 
synthesis.b8.conv1.transformer.to_gate_attention    -           -        [4, 1, 64, 16]      float32 
synthesis.b8.conv1.transformer.modulation           262656      -        [256, 512]          float32 
synthesis.b8.conv1.transformer:0                    17408       -        [4, 64, 512]        float32 
synthesis.b8.conv1.transformer:1                    -           -        [4, 64, 512]        float32 
synthesis.b8.conv1.biasAct                          512         -        [4, 512, 8, 8]      float32 
synthesis.b8.conv1:0                                2359297     2128     [4, 512, 8, 8]      float32 
synthesis.b8.conv1:1                                -           -        [4, 512, 8, 8]      float32 
synthesis.b8                                        -           16       [4, 512, 8, 8]      float32 
synthesis.b16.skip.biasAct                          -           -        [4, 512, 16, 16]    float32 
synthesis.b16.skip                                  262144      16       [4, 512, 16, 16]    float32 
synthesis.b16.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv0.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv0.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv0.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv0.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv0.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv0.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv0:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv0:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b16.conv1.transformer.to_queries          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.from_pos_map        16896       -        [1024, 512]         float32 
synthesis.b16.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b16.conv1.transformer.to_gate_attention   -           -        [4, 1, 256, 16]     float32 
synthesis.b16.conv1.transformer.modulation          262656      -        [1024, 512]         float32 
synthesis.b16.conv1.transformer:0                   17408       -        [4, 256, 512]       float32 
synthesis.b16.conv1.transformer:1                   -           -        [4, 256, 512]       float32 
synthesis.b16.conv1.biasAct                         512         -        [4, 512, 16, 16]    float32 
synthesis.b16.conv1:0                               2359297     8464     [4, 512, 16, 16]    float32 
synthesis.b16.conv1:1                               -           -        [4, 512, 16, 16]    float32 
synthesis.b16                                       -           16       [4, 512, 16, 16]    float32 
synthesis.b32.skip.biasAct                          -           -        [4, 512, 32, 32]    float32 
synthesis.b32.skip                                  262144      16       [4, 512, 32, 32]    float32 
synthesis.b32.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv0.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv0.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv0.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv0.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv0.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv0.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv0:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv0:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b32.conv1.transformer.to_queries          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.from_pos_map        16896       -        [4096, 512]         float32 
synthesis.b32.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b32.conv1.transformer.to_gate_attention   -           -        [4, 1, 1024, 16]    float32 
synthesis.b32.conv1.transformer.modulation          262656      -        [4096, 512]         float32 
synthesis.b32.conv1.transformer:0                   17408       -        [4, 1024, 512]      float32 
synthesis.b32.conv1.transformer:1                   -           -        [4, 1024, 512]      float32 
synthesis.b32.conv1.biasAct                         512         -        [4, 512, 32, 32]    float32 
synthesis.b32.conv1:0                               2359297     33808    [4, 512, 32, 32]    float32 
synthesis.b32.conv1:1                               -           -        [4, 512, 32, 32]    float32 
synthesis.b32                                       -           16       [4, 512, 32, 32]    float32 
synthesis.b64.skip.biasAct                          -           -        [4, 512, 64, 64]    float32 
synthesis.b64.skip                                  262144      16       [4, 512, 64, 64]    float32 
synthesis.b64.conv0.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv0.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv0.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv0.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv0.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv0.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv0.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv0.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv0:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv0:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1.affine                          16896       -        [4, 512]            float32 
synthesis.b64.conv1.transformer.to_queries          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_keys             16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.to_values           16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.from_pos_map        16896       -        [16384, 512]        float32 
synthesis.b64.conv1.transformer.to_pos_map          16896       -        [64, 512]           float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.att_dp              -           -        [4, 1, 1, 16]       float32 
synthesis.b64.conv1.transformer.to_gate_attention   -           -        [4, 1, 4096, 16]    float32 
synthesis.b64.conv1.transformer.modulation          262656      -        [16384, 512]        float32 
synthesis.b64.conv1.transformer:0                   17408       -        [4, 4096, 512]      float32 
synthesis.b64.conv1.transformer:1                   -           -        [4, 4096, 512]      float32 
synthesis.b64.conv1.biasAct                         512         -        [4, 512, 64, 64]    float32 
synthesis.b64.conv1:0                               2359297     135184   [4, 512, 64, 64]    float32 
synthesis.b64.conv1:1                               -           -        [4, 512, 64, 64]    float32 
synthesis.b64                                       -           16       [4, 512, 64, 64]    float32 
synthesis.b128.skip.biasAct                         -           -        [4, 256, 128, 128]  float32 
synthesis.b128.skip                                 131072      16       [4, 256, 128, 128]  float32 
synthesis.b128.conv0.affine                         16896       -        [4, 512]            float32 
synthesis.b128.conv0.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv0.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv0.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv0.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv0.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv0.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv0.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv0:0                              1179649     540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv0:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1.affine                         8448        -        [4, 256]            float32 
synthesis.b128.conv1.transformer.to_queries         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_keys            8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.to_values          8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.from_pos_map       8448        -        [65536, 256]        float32 
synthesis.b128.conv1.transformer.to_pos_map         8448        -        [64, 256]           float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.att_dp             -           -        [4, 1, 1, 16]       float32 
synthesis.b128.conv1.transformer.to_gate_attention  -           -        [4, 1, 16384, 16]   float32 
synthesis.b128.conv1.transformer.modulation         65792       -        [65536, 256]        float32 
synthesis.b128.conv1.transformer:0                  8704        -        [4, 16384, 256]     float32 
synthesis.b128.conv1.transformer:1                  -           -        [4, 16384, 256]     float32 
synthesis.b128.conv1.biasAct                        256         -        [4, 256, 128, 128]  float32 
synthesis.b128.conv1:0                              589825      540688   [4, 256, 128, 128]  float32 
synthesis.b128.conv1:1                              -           -        [4, 256, 128, 128]  float32 
synthesis.b128                                      -           16       [4, 256, 128, 128]  float32 
synthesis.b256.skip.biasAct                         -           -        [4, 128, 256, 256]  float32 
synthesis.b256.skip                                 32768       16       [4, 128, 256, 256]  float32 
synthesis.b256.conv0.affine                         8448        -        [4, 256]            float32 
synthesis.b256.conv0.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv0                                294913      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv1.affine                         4224        -        [4, 128]            float32 
synthesis.b256.conv1.biasAct                        128         -        [4, 128, 256, 256]  float32 
synthesis.b256.conv1                                147457      65552    [4, 128, 256, 256]  float32 
synthesis.b256.conv_last.affine                     4224        -        [4, 128]            float32 
synthesis.b256.conv_last                            147456      16       [4, 128, 256, 256]  float32 
synthesis.b256.torgb.affine                         4224        -        [4, 128]            float32 
synthesis.b256.torgb.biasAct                        3           -        [4, 3, 256, 256]    float32 
synthesis.b256.torgb                                384         -        [4, 3, 256, 256]    float32 
synthesis.b256:0                                    -           16       [4, 128, 256, 256]  float32 
synthesis.b256:1                                    -           -        [4, 128, 256, 256]  float32 
synthesis:0                                         -           -        [4, 3, 256, 256]    float32 
synthesis:1                                         -           -        [4, 3, 256, 256]    float32 
<top-level>                                         512         -        [4, 3, 256, 256]    float32 
---                                         ---         ---      ---                 ---     
Total                                       30903632    1572448  -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---           ---         ---      ---                 ---     
b256.fromrgb.biasAct  128         -        [4, 128, 256, 256]  float32 
b256.fromrgb          384         16       [4, 128, 256, 256]  float32 
b256.skip.biasAct     -           -        [4, 256, 128, 128]  float32 
b256.skip             32768       16       [4, 256, 128, 128]  float32 
b256.conv0.biasAct    128         -        [4, 128, 256, 256]  float32 
b256.conv0            147456      16       [4, 128, 256, 256]  float32 
b256.conv1.biasAct    256         -        [4, 256, 128, 128]  float32 
b256.conv1            294912      16       [4, 256, 128, 128]  float32 
b256                  -           16       [4, 256, 128, 128]  float32 
b128.skip.biasAct     -           -        [4, 512, 64, 64]    float32 
b128.skip             131072      16       [4, 512, 64, 64]    float32 
b128.conv0.biasAct    256         -        [4, 256, 128, 128]  float32 
b128.conv0            589824      16       [4, 256, 128, 128]  float32 
b128.conv1.biasAct    512         -        [4, 512, 64, 64]    float32 
b128.conv1            1179648     16       [4, 512, 64, 64]    float32 
b128                  -           16       [4, 512, 64, 64]    float32 
b64.skip.biasAct      -           -        [4, 512, 32, 32]    float32 
b64.skip              262144      16       [4, 512, 32, 32]    float32 
b64.conv0.biasAct     512         -        [4, 512, 64, 64]    float32 
b64.conv0             2359296     16       [4, 512, 64, 64]    float32 
b64.conv1.biasAct     512         -        [4, 512, 32, 32]    float32 
b64.conv1             2359296     16       [4, 512, 32, 32]    float32 
b64                   -           16       [4, 512, 32, 32]    float32 
b32.skip.biasAct      -           -        [4, 512, 16, 16]    float32 
b32.skip              262144      16       [4, 512, 16, 16]    float32 
b32.conv0.biasAct     512         -        [4, 512, 32, 32]    float32 
b32.conv0             2359296     16       [4, 512, 32, 32]    float32 
b32.conv1.biasAct     512         -        [4, 512, 16, 16]    float32 
b32.conv1             2359296     16       [4, 512, 16, 16]    float32 
b32                   -           16       [4, 512, 16, 16]    float32 
b16.skip.biasAct      -           -        [4, 512, 8, 8]      float32 
b16.skip              262144      16       [4, 512, 8, 8]      float32 
b16.conv0.biasAct     512         -        [4, 512, 16, 16]    float32 
b16.conv0             2359296     16       [4, 512, 16, 16]    float32 
b16.conv1.biasAct     512         -        [4, 512, 8, 8]      float32 
b16.conv1             2359296     16       [4, 512, 8, 8]      float32 
b16                   -           16       [4, 512, 8, 8]      float32 
b8.skip.biasAct       -           -        [4, 512, 4, 4]      float32 
b8.skip               262144      16       [4, 512, 4, 4]      float32 
b8.conv0.biasAct      512         -        [4, 512, 8, 8]      float32 
b8.conv0              2359296     16       [4, 512, 8, 8]      float32 
b8.conv1.biasAct      512         -        [4, 512, 4, 4]      float32 
b8.conv1              2359296     16       [4, 512, 4, 4]      float32 
b8                    -           16       [4, 512, 4, 4]      float32 
b4.mbstd              -           -        [4, 513, 4, 4]      float32 
b4.conv.biasAct       512         -        [4, 512, 4, 4]      float32 
b4.conv               2363904     16       [4, 512, 4, 4]      float32 
b4.fc                 4194816     -        [4, 512]            float32 
b4.out                513         -        [4, 1]              float32 
---           ---         ---      ---                 ---     
Total         28864129    416      -                   -       

Produce visualizations...
Running network and saving samples...
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 2189.17it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A100%|##########| 32/32 [00:00<00:00, 8396.48it/s]
6
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
[[0.72, -0.25760000000000005, -0.32000000000000006], [0.6575999999999997, 0.72, -0.32000000000000006], [-0.32000000000000006, 0.72, -0.25760000000000005], [-0.32000000000000006, 0.6575999999999997, 0.72], [-0.25760000000000005, -0.32000000000000006, 0.72], [0.72, -0.32000000000000006, 0.6575999999999997]]
6
[(0.86, 0.3712, 0.33999999999999997), (0.8287999999999999, 0.86, 0.33999999999999997), (0.33999999999999997, 0.86, 0.3712), (0.33999999999999997, 0.8287999999999999, 0.86), (0.3712, 0.33999999999999997, 0.86), (0.86, 0.33999999999999997, 0.8287999999999999)]
  0%|          | 0/1 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "run_network.py", line 598, in <module>
    main()
  File "run_network.py", line 594, in main
    launch_processes(config)
  File "run_network.py", line 406, in launch_processes
    subprocess_fn(rank = 0, args = config, temp_dir = temp_dir)
  File "run_network.py", line 394, in subprocess_fn
    training_loop.training_loop(rank = rank, **args)
  File "/home/quoniam/Work/TileGAN/gan/training/training_loop.py", line 361, in training_loop
    truncation_psi = truncation_psi, **vis_args)
  File "/home/quoniam/Work/TileGAN/gan/training/visualize.py", line 175, in vis
    soft_maps = np.sum(pallete * np.expand_dims(soft_maps, axis = 2), axis = 1)
ValueError: operands could not be broadcast together with shapes (6,3,1,1,1) (32,16,1,256,256) 
